
vkey2 <- function (map, title = NA, side = 2, stretch = 1.4, x, y, 
		wh)
{
	opar <- par(xpd = NA)
	on.exit(par(opar))
	n <- length(map$breaks) + 1
	dy <- strheight("A")
	aspect <- diff(grconvertX(1:2, from = "inches"))/diff(grconvertY(1:2,
					from = "inches"))
	dx <- dy * aspect
	if (missing(wh)) {
		
		wh <- 1:(n-1)
		
	}
	labs <- format(map$breaks[wh])
	maxlabwidth <- max(strwidth(labs))
	if (missing(x)) {
		x <- grconvertX(1, from = "nfc") - (2 * dx)
		if (side == 4)
			x <- x - maxlabwidth - dx
	}
	else {
		if (is.list(x)) {
			y <- x$y
			x <- x$x
		}
	}
	if (missing(y))
		y <- par("usr")[3] + dy
	ybord <- y + ((0:(n - 1)) * dy * stretch)
	rect(x, ybord[-n], x + dx, ybord[-1], col = map$colors, border = NA)
	if (side == 4) {
		xtext <- x + dx
		text(x = x, y = ybord[n] + (1.5 * dy), title, adj = c(0,
						0))
	}
	if (side == 2) {
		xtext <- x
		text(x = x + dx, y = ybord[n] + (1.5 * dy), title, adj = c(1,
						0))
	}
	text(x = xtext, y = ybord[wh] + 0.5 * dy, labels = labs, pos = side)
}

multiplot <- function(..., plotlist=NULL, file, cols=1, layout=NULL) {
	require(grid)
	
	# Make a list from the ... arguments and plotlist
	plots <- c(list(...), plotlist)
	
	numPlots = length(plots)
	
	# If layout is NULL, then use 'cols' to determine layout
	if (is.null(layout)) {
		# Make the panel
		# ncol: Number of columns of plots
		# nrow: Number of rows needed, calculated from # of cols
		layout <- matrix(seq(1, cols * ceiling(numPlots/cols)),
				ncol = cols, nrow = ceiling(numPlots/cols), byrow=TRUE)
	}
	
	if (numPlots==1) {
		print(plots[[1]])
		
	} else {
		# Set up the page
		grid.newpage()
		pushViewport(viewport(layout = grid.layout(nrow(layout), ncol(layout))))
		
		# Make each plot, in the correct location
		for (i in 1:numPlots) {
			# Get the i,j matrix positions of the regions that contain this subplot
			matchidx <- as.data.frame(which(layout == i, arr.ind = TRUE))
			
			print(plots[[i]], vp = viewport(layout.pos.row = matchidx$row,
							layout.pos.col = matchidx$col))
		}
	}
}


heatmap.3 <- function(x,
		Rowv = TRUE, Colv = if (symm) "Rowv" else TRUE,
		distfun = dist,
		hclustfun = hclust,
		dendrogram = c("both","row", "column", "none"),
		symm = FALSE,
		scale = c("none","row", "column"),
		na.rm = TRUE,
		revC = identical(Colv,"Rowv"),
		add.expr,
		breaks,
		symbreaks = max(x < 0, na.rm = TRUE) || scale != "none",
		col = "heat.colors",
		colsep,
		rowsep,
		sepcolor = "white",
		sepwidth = c(0.05, 0.05),
		cellnote,
		notecex = 1,
		notecol = "cyan",
		na.color = par("bg"),
		trace = c("none", "column","row", "both"),
		tracecol = "cyan",
		hline = median(breaks),
		vline = median(breaks),
		linecol = tracecol,
		margins = c(5,5),
		ColSideColors = NULL,
		RowSideColors = NULL,
		side.height.fraction=0.3,
		cexRow = 0.2 + 1/log10(nr),
		cexCol = 0.2 + 1/log10(nc),
		labRow = NULL,
		labCol = NULL,
		key = TRUE,
		keysize = 1.5,
		density.info = c("none", "histogram", "density"),
		denscol = tracecol,
		symkey = max(x < 0, na.rm = TRUE) || symbreaks,
		densadj = 0.25,
		main = NULL,
		xlab = NULL,
		ylab = NULL,
		lmat = NULL,
		lhei = NULL,
		lwid = NULL,
		NumColSideColors = 1,
		NumRowSideColors = 1,
		KeyValueName="Value",...){
	
	invalid <- function (x) {
		if (missing(x) || is.null(x) || length(x) == 0)
			return(TRUE)
		if (is.list(x))
			return(all(sapply(x, invalid)))
		else if (is.vector(x))
			return(all(is.na(x)))
		else return(FALSE)
	}
	
	x <- as.matrix(x)
	scale01 <- function(x, low = min(x), high = max(x)) {
		x <- (x - low)/(high - low)
		x
	}
	retval <- list()
	scale <- if (symm && missing(scale))
				"none"
			else match.arg(scale)
	dendrogram <- match.arg(dendrogram)
	trace <- match.arg(trace)
	density.info <- match.arg(density.info)
	if (length(col) == 1 && is.character(col))
		col <- get(col, mode = "function")
	if (!missing(breaks) && (scale != "none"))
		warning("Using scale=\"row\" or scale=\"column\" when breaks are",
				"specified can produce unpredictable results.", "Please consider using only one or the other.")
	if (is.null(Rowv) || is.na(Rowv))
		Rowv <- FALSE
	if (is.null(Colv) || is.na(Colv))
		Colv <- FALSE
	else if (Colv == "Rowv" && !isTRUE(Rowv))
		Colv <- FALSE
	if (length(di <- dim(x)) != 2 || !is.numeric(x))
		stop("`x' must be a numeric matrix")
	nr <- di[1]
	nc <- di[2]
	if (nr <= 1 || nc <= 1)
		stop("`x' must have at least 2 rows and 2 columns")
	if (!is.numeric(margins) || length(margins) != 2)
		stop("`margins' must be a numeric vector of length 2")
	if (missing(cellnote))
		cellnote <- matrix("", ncol = ncol(x), nrow = nrow(x))
	if (!inherits(Rowv, "dendrogram")) {
		if (((!isTRUE(Rowv)) || (is.null(Rowv))) && (dendrogram %in%
					c("both", "row"))) {
			if (is.logical(Colv) && (Colv))
				dendrogram <- "column"
			else dedrogram <- "none"
			warning("Discrepancy: Rowv is FALSE, while dendrogram is `",
					dendrogram, "'. Omitting row dendogram.")
		}
	}
	if (!inherits(Colv, "dendrogram")) {
		if (((!isTRUE(Colv)) || (is.null(Colv))) && (dendrogram %in%
					c("both", "column"))) {
			if (is.logical(Rowv) && (Rowv))
				dendrogram <- "row"
			else dendrogram <- "none"
			warning("Discrepancy: Colv is FALSE, while dendrogram is `",
					dendrogram, "'. Omitting column dendogram.")
		}
	}
	if (inherits(Rowv, "dendrogram")) {
		ddr <- Rowv
		rowInd <- order.dendrogram(ddr)
	}
	else if (is.integer(Rowv)) {
		hcr <- hclustfun(distfun(x))
		ddr <- as.dendrogram(hcr)
		ddr <- reorder(ddr, Rowv)
		rowInd <- order.dendrogram(ddr)
		if (nr != length(rowInd))
			stop("row dendrogram ordering gave index of wrong length")
	}
	else if (isTRUE(Rowv)) {
		Rowv <- rowMeans(x, na.rm = na.rm)
		hcr <- hclustfun(distfun(x))
		ddr <- as.dendrogram(hcr)
		ddr <- reorder(ddr, Rowv)
		rowInd <- order.dendrogram(ddr)
		if (nr != length(rowInd))
			stop("row dendrogram ordering gave index of wrong length")
	}
	else {
		rowInd <- nr:1
	}
	if (inherits(Colv, "dendrogram")) {
		ddc <- Colv
		colInd <- order.dendrogram(ddc)
	}
	else if (identical(Colv, "Rowv")) {
		if (nr != nc)
			stop("Colv = \"Rowv\" but nrow(x) != ncol(x)")
		if (exists("ddr")) {
			ddc <- ddr
			colInd <- order.dendrogram(ddc)
		}
		else colInd <- rowInd
	}
	else if (is.integer(Colv)) {
		hcc <- hclustfun(distfun(if (symm)
									x
								else t(x)))
		ddc <- as.dendrogram(hcc)
		ddc <- reorder(ddc, Colv)
		colInd <- order.dendrogram(ddc)
		if (nc != length(colInd))
			stop("column dendrogram ordering gave index of wrong length")
	}
	else if (isTRUE(Colv)) {
		Colv <- colMeans(x, na.rm = na.rm)
		hcc <- hclustfun(distfun(if (symm)
									x
								else t(x)))
		ddc <- as.dendrogram(hcc)
		ddc <- reorder(ddc, Colv)
		colInd <- order.dendrogram(ddc)
		if (nc != length(colInd))
			stop("column dendrogram ordering gave index of wrong length")
	}
	else {
		colInd <- 1:nc
	}
	retval$rowInd <- rowInd
	retval$colInd <- colInd
	retval$call <- match.call()
	x <- x[rowInd, colInd]
	x.unscaled <- x
	cellnote <- cellnote[rowInd, colInd]
	if (is.null(labRow))
		labRow <- if (is.null(rownames(x)))
					(1:nr)[rowInd]
				else rownames(x)
	else labRow <- labRow[rowInd]
	if (is.null(labCol))
		labCol <- if (is.null(colnames(x)))
					(1:nc)[colInd]
				else colnames(x)
	else labCol <- labCol[colInd]
	if (scale == "row") {
		retval$rowMeans <- rm <- rowMeans(x, na.rm = na.rm)
		x <- sweep(x, 1, rm)
		retval$rowSDs <- sx <- apply(x, 1, sd, na.rm = na.rm)
		x <- sweep(x, 1, sx, "/")
	}
	else if (scale == "column") {
		retval$colMeans <- rm <- colMeans(x, na.rm = na.rm)
		x <- sweep(x, 2, rm)
		retval$colSDs <- sx <- apply(x, 2, sd, na.rm = na.rm)
		x <- sweep(x, 2, sx, "/")
	}
	if (missing(breaks) || is.null(breaks) || length(breaks) < 1) {
		if (missing(col) || is.function(col))
			breaks <- 16
		else breaks <- length(col) + 1
	}
	if (length(breaks) == 1) {
		if (!symbreaks)
			breaks <- seq(min(x, na.rm = na.rm), max(x, na.rm = na.rm),
					length = breaks)
		else {
			extreme <- max(abs(x), na.rm = TRUE)
			breaks <- seq(-extreme, extreme, length = breaks)
		}
	}
	nbr <- length(breaks)
	ncol <- length(breaks) - 1
	if (class(col) == "function")
		col <- col(ncol)
	min.breaks <- min(breaks)
	max.breaks <- max(breaks)
	x[x < min.breaks] <- min.breaks
	x[x > max.breaks] <- max.breaks
	if (missing(lhei) || is.null(lhei))
		lhei <- c(keysize, 4)
	if (missing(lwid) || is.null(lwid))
		lwid <- c(keysize, 4)
	if (missing(lmat) || is.null(lmat)) {
		lmat <- rbind(4:3, 2:1)
		
		if (!is.null(ColSideColors)) {
			#if (!is.matrix(ColSideColors))
			#stop("'ColSideColors' must be a matrix")
			if (!is.character(ColSideColors) || nrow(ColSideColors) != nc)
				stop("'ColSideColors' must be a matrix of nrow(x) rows")
			lmat <- rbind(lmat[1, ] + 1, c(NA, 1), lmat[2, ] + 1)
			#lhei <- c(lhei[1], 0.2, lhei[2])
			lhei=c(lhei[1], side.height.fraction*NumColSideColors, lhei[2])
		}
		
		if (!is.null(RowSideColors)) {
			#if (!is.matrix(RowSideColors))
			#stop("'RowSideColors' must be a matrix")
			if (!is.character(RowSideColors) || ncol(RowSideColors) != nr)
				stop("'RowSideColors' must be a matrix of ncol(x) columns")
			lmat <- cbind(lmat[, 1] + 1, c(rep(NA, nrow(lmat) - 1), 1), lmat[,2] + 1)
			#lwid <- c(lwid[1], 0.2, lwid[2])
			lwid <- c(lwid[1], side.height.fraction*NumRowSideColors, lwid[2])
		}
		lmat[is.na(lmat)] <- 0
	}
	
	if (length(lhei) != nrow(lmat))
		stop("lhei must have length = nrow(lmat) = ", nrow(lmat))
	if (length(lwid) != ncol(lmat))
		stop("lwid must have length = ncol(lmat) =", ncol(lmat))
	op <- par(no.readonly = TRUE)
	on.exit(par(op))
	
	layout(lmat, widths = lwid, heights = lhei, respect = FALSE)
	
	if (!is.null(RowSideColors)) {
		if (!is.matrix(RowSideColors)){
			par(mar = c(margins[1], 0, 0, 0.5))
			image(rbind(1:nr), col = RowSideColors[rowInd], axes = FALSE)
			box()
		} else {
			par(mar = c(margins[1], 0, 0, 0.5))
			rsc = t(RowSideColors[,rowInd, drop=F])
			rsc.colors = matrix()
			rsc.names = names(table(rsc))
			rsc.i = 1
			for (rsc.name in rsc.names) {
				rsc.colors[rsc.i] = rsc.name
				rsc[rsc == rsc.name] = rsc.i
				rsc.i = rsc.i + 1
			}
			rsc = matrix(as.numeric(rsc), nrow = dim(rsc)[1])
			image(t(rsc), col = as.vector(rsc.colors), axes = FALSE)
			
			if (length(rownames(RowSideColors)) > 0) {
				axis(1, 0:(dim(rsc)[2] - 1)/(dim(rsc)[2] - 1), rownames(RowSideColors), las = 2, tick = FALSE)
			}
			box()
		}
	}
	
	if (!is.null(ColSideColors)) {
		
		if (!is.matrix(ColSideColors)){
			par(mar = c(0.5, 0, 0, margins[2]))
			image(cbind(1:nc), col = ColSideColors[colInd], axes = FALSE)
			box()
		} else {
			par(mar = c(0.5, 0, 0, margins[2]))
			csc = ColSideColors[colInd, , drop=F]
			csc.colors = matrix()
			csc.names = names(table(csc))
			csc.i = 1
			for (csc.name in csc.names) {
				csc.colors[csc.i] = csc.name
				csc[csc == csc.name] = csc.i
				csc.i = csc.i + 1
			}
			csc = matrix(as.numeric(csc), nrow = dim(csc)[1])
			image(csc, col = as.vector(csc.colors), axes = FALSE)
			if (length(colnames(ColSideColors)) > 0) {
				axis(2, 0:(dim(csc)[2] - 1)/max(1,(dim(csc)[2] - 1)), colnames(ColSideColors), las = 2, tick = FALSE)
			}
			box()
		}
	}
	
	par(mar = c(margins[1], 0, 0, margins[2]))
	x <- t(x)
	cellnote <- t(cellnote)
	if (revC) {
		iy <- nr:1
		if (exists("ddr"))
			ddr <- rev(ddr)
		x <- x[, iy]
		cellnote <- cellnote[, iy]
	}
	else iy <- 1:nr
	image(1:nc, 1:nr, x, xlim = 0.5 + c(0, nc), ylim = 0.5 + c(0, nr), axes = FALSE, xlab = "", ylab = "", col = col, breaks = breaks, ...)
	retval$carpet <- x
	if (exists("ddr"))
		retval$rowDendrogram <- ddr
	if (exists("ddc"))
		retval$colDendrogram <- ddc
	retval$breaks <- breaks
	retval$col <- col
	if (!invalid(na.color) & any(is.na(x))) { # load library(gplots)
		mmat <- ifelse(is.na(x), 1, NA)
		image(1:nc, 1:nr, mmat, axes = FALSE, xlab = "", ylab = "",
				col = na.color, add = TRUE)
	}
	axis(1, 1:nc, labels = labCol, las = 2, line = -0.5, tick = 0,
			cex.axis = cexCol)
	if (!is.null(xlab))
		mtext(xlab, side = 1, line = margins[1] - 1.25)
	axis(4, iy, labels = labRow, las = 2, line = -0.5, tick = 0,
			cex.axis = cexRow)
	if (!is.null(ylab))
		mtext(ylab, side = 4, line = margins[2] - 1.25)
	if (!missing(add.expr))
		eval(substitute(add.expr))
	if (!missing(colsep))
		for (csep in colsep) rect(xleft = csep + 0.5, ybottom = 0, xright = csep + 0.5 + sepwidth[1], ytop = ncol(x) + 1, lty = 1, lwd = 1, col = sepcolor, border = sepcolor)
	if (!missing(rowsep))
		for (rsep in rowsep) rect(xleft = 0, ybottom = (ncol(x) + 1 - rsep) - 0.5, xright = nrow(x) + 1, ytop = (ncol(x) + 1 - rsep) - 0.5 - sepwidth[2], lty = 1, lwd = 1, col = sepcolor, border = sepcolor)
	min.scale <- min(breaks)
	max.scale <- max(breaks)
	x.scaled <- scale01(t(x), min.scale, max.scale)
	if (trace %in% c("both", "column")) {
		retval$vline <- vline
		vline.vals <- scale01(vline, min.scale, max.scale)
		for (i in colInd) {
			if (!is.null(vline)) {
				abline(v = i - 0.5 + vline.vals, col = linecol,
						lty = 2)
			}
			xv <- rep(i, nrow(x.scaled)) + x.scaled[, i] - 0.5
			xv <- c(xv[1], xv)
			yv <- 1:length(xv) - 0.5
			lines(x = xv, y = yv, lwd = 1, col = tracecol, type = "s")
		}
	}
	if (trace %in% c("both", "row")) {
		retval$hline <- hline
		hline.vals <- scale01(hline, min.scale, max.scale)
		for (i in rowInd) {
			if (!is.null(hline)) {
				abline(h = i + hline, col = linecol, lty = 2)
			}
			yv <- rep(i, ncol(x.scaled)) + x.scaled[i, ] - 0.5
			yv <- rev(c(yv[1], yv))
			xv <- length(yv):1 - 0.5
			lines(x = xv, y = yv, lwd = 1, col = tracecol, type = "s")
		}
	}
	if (!missing(cellnote))
		text(x = c(row(cellnote)), y = c(col(cellnote)), labels = c(cellnote),
				col = notecol, cex = notecex)
	par(mar = c(margins[1], 0, 0, 0))
	if (dendrogram %in% c("both", "row")) {
		plot(ddr, horiz = TRUE, axes = FALSE, yaxs = "i", leaflab = "none")
	}
	else plot.new()
	par(mar = c(0, 0, if (!is.null(main)) 5 else 0, margins[2]))
	if (dendrogram %in% c("both", "column")) {
		plot(ddc, axes = FALSE, xaxs = "i", leaflab = "none")
	}
	else plot.new()
	if (!is.null(main))
		title(main, cex.main = 1.5 * op[["cex.main"]])
	if (key) {
		par(mar = c(5, 4, 2, 1), cex = 0.75)
		tmpbreaks <- breaks
		if (symkey) {
			max.raw <- max(abs(c(x, breaks)), na.rm = TRUE)
			min.raw <- -max.raw
			tmpbreaks[1] <- -max(abs(x), na.rm = TRUE)
			tmpbreaks[length(tmpbreaks)] <- max(abs(x), na.rm = TRUE)
		}
		else {
			min.raw <- min(x, na.rm = TRUE)
			max.raw <- max(x, na.rm = TRUE)
		}
		
		z <- seq(min.raw, max.raw, length = length(col))
		image(z = matrix(z, ncol = 1), col = col, breaks = tmpbreaks,
				xaxt = "n", yaxt = "n")
		par(usr = c(0, 1, 0, 1))
		lv <- pretty(breaks)
		xv <- scale01(as.numeric(lv), min.raw, max.raw)
		axis(1, at = xv, labels = lv)
		if (scale == "row")
			mtext(side = 1, "Row Z-Score", line = 2)
		else if (scale == "column")
			mtext(side = 1, "Column Z-Score", line = 2)
		else mtext(side = 1, KeyValueName, line = 2)
		if (density.info == "density") {
			dens <- density(x, adjust = densadj, na.rm = TRUE)
			omit <- dens$x < min(breaks) | dens$x > max(breaks)
			dens$x <- dens$x[-omit]
			dens$y <- dens$y[-omit]
			dens$x <- scale01(dens$x, min.raw, max.raw)
			lines(dens$x, dens$y/max(dens$y) * 0.95, col = denscol,
					lwd = 1)
			axis(2, at = pretty(dens$y)/max(dens$y) * 0.95, pretty(dens$y))
			title("Color Key\nand Density Plot")
			par(cex = 0.5)
			mtext(side = 2, "Density", line = 2)
		}
		else if (density.info == "histogram") {
			h <- hist(x, plot = FALSE, breaks = breaks)
			hx <- scale01(breaks, min.raw, max.raw)
			hy <- c(h$counts, h$counts[length(h$counts)])
			lines(hx, hy/max(hy) * 0.95, lwd = 1, type = "s",
					col = denscol)
			axis(2, at = pretty(hy)/max(hy) * 0.95, pretty(hy))
			title("Color Key\nand Histogram")
			par(cex = 0.5)
			mtext(side = 2, "Count", line = 2)
		}
		else title("Color Key")
	}
	else plot.new()
	retval$colorTable <- data.frame(low = retval$breaks[-length(retval$breaks)],
			high = retval$breaks[-1], color = retval$col)
	invisible(retval)
}

load_package <- function (package.names=c('MASS', 'ggbiplot', 'ape', 'vegan', 'pscl', 'glmmADMB', 'aod', 'nlme', 'MiRKAT', 'matrixStats', 
				'gplots', 'scales', 'ggplot2', 'GUniFrac', 'rpart', 'qvalue', 'DESeq2', 'lme4',
				'phangorn', 'phyloseq', 'RColorBrewer', 'squash', 'rhdf5', 'biom', 'reshape', 'randomForest', 'Boruta', 'ade4', 'Daim', 'rlocal')) {
	for (package.name in package.names) {
		require(package.name, character.only=T)
	}
}

getPermuteMatrixBlock <- function(permutations, strata) {
	strata <- factor(strata)
	strata <- factor(as.numeric(strata))
	res <- sapply(1:permutations, function(i) {
				strata1 <- strata
				levels(strata1) <- sample(levels(strata1))
				order(as.numeric(as.character(strata1)))
			})
	t(res)
}

# adonis2: permutate the covariate instead of data matrix - validated
# The variable of interest should be put at the last; Only p values of variable of interest will be reported
# Currently it can only be applied to subject-specific variable (nonvarying within subject) but covariates are allowed to vary
# Need to improve the speed
adonis2 <- function (formula, data = NULL, permutations = 999, method = "bray", 
		strata = NULL, block.perm = TRUE, contr.unordered = "contr.sum", contr.ordered = "contr.poly", 
		...) 
{
	TOL <- 1e-07
	Terms <- terms(formula, data = data, keep.order=TRUE)
	lhs <- formula[[2]]
	lhs <- eval(lhs, data, parent.frame())
	formula[[2]] <- NULL
	rhs.frame <- model.frame(formula, data, drop.unused.levels = TRUE)
	op.c <- options()$contrasts
	options(contrasts = c(contr.unordered, contr.ordered))
	rhs <- model.matrix(formula, rhs.frame)
	options(contrasts = op.c)
	grps <- attr(rhs, "assign")
	qrhs <- qr(rhs)
	rhs <- rhs[, qrhs$pivot, drop = FALSE]
	rhs <- rhs[, 1:qrhs$rank, drop = FALSE]
	grps <- grps[qrhs$pivot][1:qrhs$rank]
	u.grps <- unique(grps)
	nterms <- length(u.grps) - 1
	st <- ifelse(nterms == 1, 2, nterms)
	H.s <- lapply(st:(nterms+1), function(j) {
				Xj <- rhs[, grps %in% u.grps[1:j]]
				qrX <- qr(Xj, tol = TOL)
				Q <- qr.Q(qrX)
				tcrossprod(Q[, 1:qrX$rank])
			})
	if (inherits(lhs, "dist")) {
		if (any(lhs < -TOL)) 
			stop("dissimilarities must be non-negative")
		dmat <- as.matrix(lhs^2)
	}
	else {
		dist.lhs <- as.matrix(vegdist(lhs, method = method, ...))
		dmat <- dist.lhs^2
	}
	n <- nrow(dmat)
	G <- -sweep(dmat, 1, rowMeans(dmat))/2
	SS.Exp.comb <- sapply(H.s, function(hat) sum(G * t(hat)))
	if (nterms == 1) {
		SS.Exp.each <- SS.Exp.comb
	} else {
		SS.Exp.each <- SS.Exp.comb[2] - SS.Exp.comb[1]
	}
	
	H.snterm <- H.s[[length(H.s)]]
	tIH.snterm <- t(diag(n) - H.snterm)
	
#	if (length(H.s) > 1) {
#		H.s[[2]] <- H.s[[2]] - H.s[[1]]
#	}
	
	SS.Res <- sum(G * tIH.snterm)
	df.Exp <- sum(grps == u.grps[length(u.grps)])
	df.Res <- n - qrhs$rank
	
	if (inherits(lhs, "dist")) {
		beta.sites <- qr.coef(qrhs, as.matrix(lhs))
		beta.spp <- NULL
	}
	else {
		beta.sites <- qr.coef(qrhs, dist.lhs)
		beta.spp <- qr.coef(qrhs, as.matrix(lhs))
	}
	colnames(beta.spp) <- colnames(lhs)
	colnames(beta.sites) <- rownames(lhs)
	
	F.Mod <- (SS.Exp.each/df.Exp)/(SS.Res/df.Res)
	
	f.test <- function(tH, G, df.Exp, df.Res, tIH.snterm) {
		(sum(G * tH)/df.Exp)/(sum(G * tIH.snterm)/df.Res)
	}
	
	rhs.1 <- rhs[, grps %in% u.grps[1:nterms], drop=F]
	rhs.2 <- rhs[, grps %in% u.grps[(nterms+1)], drop=F]	
	
	if (missing(strata)) strata <- NULL
	
	if (block.perm == FALSE) {
		permute.ind <- vegan:::getPermuteMatrix(permutations, n, strata = strata)
	} else {
		if (is.null(strata)) stop('Block permutation requires strata!\n')
		strata.u <- unique(strata)
		reorder.ind <- unlist(lapply(strata.u, function(x) which(strata == x)))
		expand.ind <- rep(1:length(strata.u), sapply(strata.u, function(x) sum(strata == x)))
		rhs.2.u <- rhs.2[sapply(strata.u, function(x) which(strata == x)[1]), , drop=F]
	}
	
	# To be checked and validated. 
	f.perms <- 
			sapply(1:permutations, function(i) {
						if (block.perm == FALSE) {
							rhs.2 <- rhs[permute.ind[i, ], grps %in% u.grps[(nterms+1)], drop=F]	
						} else {
							rhs.2[reorder.ind, ] <- rhs.2.u[sample(nrow(rhs.2.u)), , drop=F][expand.ind, , drop=F]
						}		
						Xj <- cbind(rhs.1, rhs.2)
						qrX <- qr(Xj, tol = TOL)
						Q <- qr.Q(qrX)
						tH.snterm <- t(tcrossprod(Q[, 1:qrX$rank]))
						tIH.snterm <- diag(n) - tH.snterm
						
						if (nterms > 1) {
							tH.snterm <- tH.snterm - t(H.s[[1]])
						}							
						f.test(tH.snterm, G, df.Exp, df.Res, 
								tIH.snterm)
					}
			)
	
	f.perms <- round(f.perms, 12)
	F.Mod <- round(F.Mod, 12)
	SumsOfSqs = c(SS.Exp.each, SS.Res, SS.Exp.comb[length(SS.Exp.comb)] + SS.Res)
	tab <- data.frame(Df = c(df.Exp, df.Res, n - 1), SumsOfSqs = SumsOfSqs, 
			MeanSqs = c(SS.Exp.each/df.Exp, SS.Res/df.Res, NA), F.Model = c(F.Mod, 
					NA, NA), R2 = SumsOfSqs/SumsOfSqs[length(SumsOfSqs)], 
			P = c((sum(f.perms >= F.Mod) + 1)/(permutations + 
								1), NA, NA))
	rownames(tab) <- c(attr(attr(rhs.frame, "terms"), "term.labels")[u.grps[length(u.grps)]], 
			"Residuals", "Total")
	colnames(tab)[ncol(tab)] <- "Pr(>F)"
	attr(tab, "heading") <- "Terms added sequentially (first to last)\n"
	class(tab) <- c("anova", class(tab))
	out <- list(aov.tab = tab, call = match.call(), coefficients = beta.spp, 
			coef.sites = beta.sites, f.perms = as.matrix(f.perms), model.matrix = rhs, 
			terms = Terms)
	class(out) <- "adonis"
	out
}

######################################
# New: 2018_03_09
set_colour_theme <- function (type = 'stata', pal = palette(RColorBrewer::brewer.pal(5, "Set1"))) {
	library(ggthemes) # Load
	if (type == 'stata') {
		scale_colour_discrete <<- function(...) scale_color_stata()
		scale_fill_discrete <<- function(...) scale_fill_stata()
	} 
	if (type == 'economist') {
		scale_colour_discrete <<- function(...) scale_color_economist()
		scale_fill_discrete <<- function(...) scale_fill_economist()
	}
	if (type == 'wsj') {
		scale_colour_discrete <<- function(...) scale_color_wsj()
		scale_fill_discrete <- function(...) scale_fill_wsj()
	}
	if (type == 'hc') {
		scale_colour_discrete <<- function(...) scale_color_hc()
		scale_fill_discrete <<- function(...) scale_fill_hc()
	}
	if (type == 'default') {
		scale_fill_discrete <<-  ggplot2::scale_fill_discrete
		scale_colour_discrete <<- ggplot2::scale_colour_discrete
	}
	if (type ==  'cb') {
		cbPalette <- c("#999999", "#E69F00", "#56B4E9", "#009E73", "#F0E442", "#0072B2", "#D55E00", "#CC79A7")
	
		scale_fill_discrete <<- function(...) scale_fill_manual(values=cbPalette)
		scale_colour_discrete <<- function(...) scale_colour_manual(values=cbPalette)
	}
	if (type ==  'cbb') {

		cbbPalette <- c("#000000", "#E69F00", "#56B4E9", "#009E73", "#F0E442", "#0072B2", "#D55E00", "#CC79A7")
		scale_fill_discrete <<- function(...) scale_fill_manual(values=cbbPalette)
		scale_colour_discrete <<- function(...) scale_colour_manual(values=cbbPalette)
	}
	
	if (type == 'customize') {
		scale_fill_discrete <<- function(...) scale_fill_manual(values=pal)
		scale_colour_discrete <<- function(...) scale_colour_manual(values=pal)
	}

}

########################################
# This generates the matrix columns-wise
# From JnPaulson
generate_matrix <- function(x){
	indptr  = x$sample$matrix$indptr+1
	indices = x$sample$matrix$indices+1
	data    = x$sample$matrix$data
	nr = length(x$observation$ids)
	
	counts = sapply(2:length(indptr),function(i){
				x = rep(0,nr)
				seq = indptr[i-1]:(indptr[i]-1)
				x[indices[seq]] = data[seq]
				x
			})
	rownames(counts) = x$observation$ids
	colnames(counts) = x$sample$ids
	# I wish this next line wasn't necessary
	lapply(1:nrow(counts),function(i){
				counts[i,]
			})
}
generate_metadata <- function(x){
	metadata = x$metadata
	metadata = lapply(1:length(x$ids),function(i){
				id_metadata = lapply(metadata,function(j){
							if(length(dim(j))>1){ as.vector(j[,i,drop=FALSE]) }
							else{ j[i] }
						})
				list(id = x$ids[i],metadata=id_metadata)
			})
	return(metadata)
}
namedList <- function(...) {
	L <- list(...)
	snm <- sapply(substitute(list(...)),deparse)[-1]
	if (is.null(nm <- names(L))) nm <- snm
	if (any(nonames <- nm=="")) nm[nonames] <- snm[nonames]
	setNames(L,nm)
}

read_hdf5_biom <- function(file_input){
	x = h5read(file_input,"/",read.attributes = TRUE)
	data = generate_matrix(x)
	rows = generate_metadata(x$observation)
	columns = generate_metadata(x$sample)
	shape = c(length(data),length(data[[1]])) # dim(data)
	
	# Experimental -- need to actually load these from file
	id = attr(x,"id")
	vs = attr(x,"format-version")
	format = sprintf("Biological Observation Matrix %s.%s",vs[1],vs[2])
	format_url = attr(x,"format-url")
	type = "OTU table"
	#type=attr(x,"type")
	generated_by = attr(x,"generated-by")
	date = attr(x,"creation-date")
	matrix_type = "dense"
	matrix_element_type = "int"
	
	namedList(id,format,format_url,type,generated_by,date,matrix_type,matrix_element_type,
			rows,columns,shape,data)
}
############################################
# comm are otu counts, row: otus, column samples
# intersect.no: Pairwise ratio calculated on pairs with at least 'intersect.no' common taxa; 
# Rev: 2016_12_12 add prevalence filter, which is not necessary
# Rev: 2017_02_07 
GMPR.old <- function (comm, intersect.no=4, prev.filter=0.0) {
	comm <- comm[rowMeans(comm != 0) >= prev.filter, ]
	
	ind.vec <- numeric(ncol(comm))
	res <- sapply(1:ncol(comm),  function(i) {
				x <- comm[, i]
				pr <- sapply(1:ncol(comm),  function(j) {
							y <- comm[, j]
							ind <- x != 0 & y != 0
							if (sum(ind) >= intersect.no) {
								res <- median(x[ind] / y[ind])
							} else {
								res <- NA
							}
						})
				if (sum(is.na(pr)) != 0) ind.vec[i] <<- 1
				exp(mean(log(pr[!is.na(pr)])))
			}
	
	)
	if (sum(ind.vec)) warnings(paste0('Sample ', paste(which(ind.vec!=0), collapse=' '), ' do not have at least ', 
						intersect.no, ' common taxa with some of the other samples. '))
	if (sum(is.nan(res))) {
		ind <- is.nan(res)
		res[ind] <- 1
		warning(paste0('Sample ', paste(which(ind), collapse=' '), ' do not have at least ', intersect.no, ' common taxa for any of the other samples. ',
						'For these samples, we force the size factors to be 1! ', 
						'You may consider removing these samples since they are very different from other samples!\n'))
	}
	cat('Finished!')
	res
}

# New: 2017_02_07
GMPR <- function (comm, intersect.no=4, ct.min=2, trace=FALSE) {
	# Computes the GMPR size factor
	#
	# Args:
	#   comm: a matrix of counts, row - features (OTUs, genes, etc) , column - sample
	#   intersect.no: the minimum number of shared features between sample pair, where the ratio is calculated
	#   ct.min: the minimum number of counts required to calculate ratios ct.min = 5 has better results
	
	#
	# Returns:
	#   a list that contains:
	#      gmprï¼š the GMPR size factors for all samples; Samples with distinct sets of features will be output as NA.
	#      nss:   number of samples with significant sharing (> intersect.no) including itself
	
	# mask counts < ct.min
	comm[comm < ct.min] <- 0
	
	if (is.null(colnames(comm))) {
		colnames(comm) <- paste0('S', 1:ncol(comm))
	}
	
	if(trace) cat('Begin GMPR size factor calculation ...\n')
	
	comm.no <- numeric(ncol(comm))
	gmpr <- sapply(1:ncol(comm),  function(i) {		
				if (i %% 50 == 0) {
					if(trace) cat(i, '\n')
				}
				x <- comm[, i]
				# Compute the pairwise ratio
				pr <- x / comm
				# Handling of the NA, NaN, Inf
				pr[is.nan(pr) | !is.finite(pr) | pr == 0] <- NA
				# Counting the number of non-NA, NaN, Inf
				incl.no <- colSums(!is.na(pr))		
				# Calculate the median of PR
				pr.median <- colMedians(pr, na.rm=TRUE)
				# Record the number of samples used for calculating the GMPR
				comm.no[i] <<- sum(incl.no >= intersect.no)
				# Geometric mean of PR median
				if (comm.no[i] > 1) {
					return(exp(mean(log(pr.median[incl.no >= intersect.no]))))
				} else {
					return(NA)
				}
			}
	)
	
	if (sum(is.na(gmpr))) {
		warning(paste0('The following samples\n ', paste(colnames(comm)[is.na(gmpr)], collapse='\n'), 
						'\ndo not share at least ', intersect.no, ' common taxa with the rest samples! ',
						'For these samples, their size factors are set to be NA! \n', 
						'You may consider removing these samples since they are potentially outliers or negative controls!\n',
						'You may also consider decreasing the minimum number of intersecting taxa and rerun the procedure!\n'))
	}
	
	if(trace) cat('Completed!\n')
	if(trace) cat('Please watch for the samples with limited sharing with other samples based on NSS! They may be outliers! \n')
	attr(gmpr, 'NSS') <- comm.no
	# Rev: 2017_09_07
    gmpr <- gmpr * median(colSums(comm))
	names(gmpr) <- colnames(comm)
	return(gmpr)
}


# Rev: 2016_10_25
uniquefy_taxa_names <- function (data.obj) {
	for (level in names(data.obj$abund.list)) {
		obj <- data.obj$abund.list[[level]]
#		rownames(obj) <- gsub('unclassified', paste0('Unclassified', substr(level, 1, 1)), rownames(obj))
#		rownames(obj) <- gsub('unassigned', paste0('Unclassified', substr(level, 1, 1)), rownames(obj))
		rownames(obj) <- paste0(rownames(obj), substr(level, 1, 1))
		data.obj$abund.list[[level]] <- obj
	}
#	suffix <- c('K', 'P', 'C', 'O', 'F', 'G', 'S')
#	for (i in 1:ncol(data.obj$otu.name)) {
#		data.obj$otu.name[, i] <- paste0(data.obj$otu.name[, i], suffix[i])
#	}
	return(data.obj)
}

# New: 2018_02_24
dereplicate <- function (names) {
	names <- factor(names)
	ord <- order(order(names))
	tab <- table(names)
	suffix <- unlist(sapply(tab, function (x) {
				if (x == 1) {
					return('')
				} else {
					return(paste0('_', 1:x))
				}
			}))

	as.character(paste0(names, suffix[ord]))

}

# Rev: 2016_09_22 Add load.map
# Rev: 2016_12_12 Reogranize rarefy, normalize, winsorize
load_data <- function (otu.file, map.file, tree.file=NULL,  load.map=TRUE, parseFunction=parse_taxonomy_greengenes, version='Old', 
		 species=TRUE, filter.no=1, rep.seq=NULL,
		 rff=FALSE, dep=NULL,
	     norm='TSS', level='OTU', intersect.no=4,
		 winsor=FALSE, winsor.qt=0.97,
		 ko.file=NULL, cog.file=NULL, ko.ann.file=NULL,
		 meta.sep='\t', quote="\"", comment="",
		 read.gg=FALSE,  seed=1234, ...) {
	# ko and cog file are not rarefied	
	# filter.no: filter the OTUs with read support less than filter.no (default is filtering singleton); singleton will not be filtered after rarefaction
	# winsorization and GMPR should be further studied. Current default is false and GMPR is on the genus level
	act.seq <- NULL
	max.nchar <- 6
	set.seed(seed)
	if (load.map == TRUE) {
		cat("Load meta file...\n")
		if (grepl("csv$", map.file)) {
			meta.dat <- read.csv(map.file, header=T, check.names=F, row.names=1, comment=comment, quote=quote, ...)
		} else {
			meta.dat <- read.table(map.file, header=T, check.names=F, row.names=1, comment=comment, sep=meta.sep, quote=quote, ...)
		}
	} else {
		meta.dat <- NULL
	}
	
	# Load Tree
	if (!is.null(tree.file)) {
		cat("Load tree file ...\n")
		if (read.gg == F) {
			tree.12 <- read.tree(tree.file)
		} else {
			tree.12 <- read_tree_greengenes(tree.file)
		}
		
		if (is.rooted(tree.12) == F) {
			tree.12 <- midpoint(tree.12)
		}
		
	} else {
		tree.12 <- NULL
	}
	
	cat("Load OTU file...\n")  # Rewrite load new biom file, rev:2016-06-20
	if (version != 'New') {
		biom.obj <-  import_biom(otu.file, parseFunction = parseFunction)  
		
		otu.tab.12 <- otu_table(biom.obj)@.Data
		otu.ind <- rowSums(otu.tab.12) > filter.no  # change otu.tab.12 != 0, rev:2016-06-20
		otu.tab.12 <- otu.tab.12[otu.ind, ]
		# OTU names
		otu.name.full <- as.matrix(biom.obj@tax_table[, c('Kingdom', 'Phylum', 'Class', 'Order', 'Family', 'Genus', 'Species')])
		otu.name.full <- otu.name.full[otu.ind, ]
		
		otu.name.12 <- otu.name.full[, c('Kingdom', 'Phylum', 'Class', 'Order', 'Family', 'Genus', 'Species')]
		otu.name.12[is.na(otu.name.12) | otu.name.12 %in% c('', 'NA')] <- 'unclassified'
		otu.name.12 <- otu.name.12@.Data
		
		otu.name.12[, ] <- gsub('\\[', '', otu.name.12)
		otu.name.12[, ] <- gsub('\\]', '', otu.name.12)
		
		otu.name.12[, ] <- gsub('_unclassified', '', otu.name.12)
		
		otu.name.full <- otu.name.full@.Data
	} else {
		temp <-  read_hdf5_biom(otu.file)
#		otu.file <- paste0(otu.file, '.old')
#		write_biom(temp, otu.file) 
#		biom.obj <- import_biom(otu.file, parseFunction = parseFunction)  
		otu.tab.12 <- matrix(unlist(temp$data), byrow=T, nrow=temp$shape[1], ncol=temp$shape[2])
	
		otu.ids <- sapply(temp$rows, function(x) x[['id']])
		sam.ids <- sapply(temp$columns, function(x) x[['id']])
		
#		res <- t(sapply(temp$rows, function(i) {
#					i$metadata$taxonomy
#				}))
#		rownames(res) <- otu.ids 
	
		# From phyloseq: to be double checked!! Checked!
		if (all(sapply(sapply(temp$rows, function(i) {
									i$metadata
								}), is.null))) {
			otu.name.full <- NULL
		} else {
			taxlist = lapply(temp$rows, function(i) {
						parseFunction(i$metadata$taxonomy)
					})
			names(taxlist) = sapply(temp$rows, function(i) {
						i$id
					})
			otu.name.full = build_tax_table(taxlist)
		}

		# Rev: 2017_04_18
		otu.name.full <- otu.name.full@.Data
		
		rownames(otu.tab.12) <- otu.ids
		colnames(otu.tab.12) <- sam.ids
		
		otu.ind <- rowSums(otu.tab.12) > filter.no  # change otu.tab.12 != 0, rev:2016-06-20
		otu.tab.12 <- otu.tab.12[otu.ind, ]	
		otu.name.full <- otu.name.full[otu.ind, ]
		otu.name.12 <- otu.name.full[, c('Kingdom', 'Phylum', 'Class', 'Order', 'Family', 'Genus', 'Species')]
		otu.name.12[is.na(otu.name.12) | otu.name.12 %in% c('', 'NA')] <- 'unclassified'
		otu.name.12[, ] <- gsub('\\[', '', otu.name.12)
		otu.name.12[, ] <- gsub('\\]', '', otu.name.12)
	}
	
	if (rff == TRUE) {
		cat('Rarefaction ...\n')
		if (is.null(dep)) {
			otu.tab.12 <- t(Rarefy(t(otu.tab.12))$otu.tab.rff)
		} else {
			otu.tab.12 <- t(Rarefy(t(otu.tab.12), dep)$otu.tab.rff)
		}	
		dep <- colSums(otu.tab.12)[1]
		cat("Depth ", dep, '\n')
		# Remove empty OTUs
		otu.ind <- rowSums(otu.tab.12) > 0  # rev:2016-06-28
		otu.tab.12 <- otu.tab.12[otu.ind, ]	
		otu.name.12 <- otu.name.12[otu.ind, ]
		otu.name.full <- otu.name.full[otu.ind, ]
		act.seq <- paste0(act.seq, 'R')
	} else {
		rff <- FALSE
		dep <- NULL
	}

	# Load mapping file
	if (load.map == TRUE) {
		samIDs <- intersect(rownames(meta.dat), colnames(otu.tab.12))
		if (length(samIDs) == 0) {
			stop('Sample names in the meta file and biom are completely different?\n')
		} 
		if (length(samIDs) < length(colnames(otu.tab.12)) | length(samIDs) < length(rownames(meta.dat))) {
			warning('Sample names in the meta file and biom differ! May be due to rarefaction?\n')
		}
		meta.dat <- meta.dat[samIDs, ]
		otu.tab.12 <- otu.tab.12[, samIDs]
	} else {
		samIDs <- colnames(otu.tab.12)
	}

   # Create abundance list
    cat("Create taxa abundance list ...\n")
	abund.list.12 <- list()
	hierachs <- c('Phylum', 'Class', 'Order', 'Family', 'Genus')
	for (hierach in hierachs) {	
		if (hierach != 'Phylum') {
			single.names <- otu.name.12[, hierach]
		#	single.names[grepl('unclassified', single.names, ignore.case=T)] <- paste0('Unclassified',substr(hierach, 1, 1))
			tax.family <- paste(otu.name.12[, 'Phylum'], single.names, sep=";")
			tax.family[grepl('unclassified', tax.family, ignore.case=T)] <- paste0('Unclassified_', hierach)
		} else {
			tax.family <- otu.name.12[, 'Phylum']
			tax.family[grepl('unclassified', tax.family, ignore.case=T)] <- 'Unclassified_Phylum'
		}
		family <- aggregate(otu.tab.12, by=list(tax.family), FUN=sum)
		rownames(family) <- family[, 1]
		family <- as.matrix(family[, -1])
		abund.list.12[[hierach]] <- family
	}
	
	if (species) {
		abund.list.12[['Species']] <- otu.tab.12
		rownames(abund.list.12[['Species']]) <- paste0("A", substr(rownames(otu.tab.12), 1, max.nchar), ":", otu.name.12[, 'Phylum'], ";", otu.name.12[, 'Genus'])
	}
	
    cat('Normalize (size factor) ...\n')
	if (rff == TRUE) {
		cat('For rarefied data, the size factor for samples can still be different!\n')
	}
		
	if (level == 'OTU') {
		data <- otu.tab.12
	} else {
		if (level %in% names(abund.list.12)) {
			data <- abund.list.12[[level]]
		} else {
			data <- otu.tab.12
			level <-'OTU'
			warning('No or wrong level specified! OTU level will be used!\n')
		}
	}
	
	if (norm == 'GMPR') {
		sf <- GMPR(data, intersect.no=intersect.no)
		warning('GMPR is only suitable for samples from the same body location!\n')
		norm <- 'GMPR'
		names(sf) <- colnames(data)
		act.seq <- paste0(act.seq, 'N')
	} else {
		if (norm == 'TSS') {
			sf <- colSums(data)
			norm <- 'TSS'
			act.seq <- paste0(act.seq, 'N')
		} else {
			warning('Normalization method not specified or unknown! TSS is used!\n')
			sf <- colSums(data)
			norm <- 'TSS'
			act.seq <- paste0(act.seq, 'N')
		}
		
	}

	if (winsor == TRUE) {
		act.seq <- paste0(act.seq, 'W')
		if (rff == TRUE) {
			warning('Winsorization after rarefaction will make the data have different total numbers!\n')
		}
		cat('Winsorize ...\n')
		if (is.null(winsor.qt)) {
			winsor.qt <- 0.97
		}
		# Addressing the outlier (97% percent) or at least one outlier
		abund.list.12 <- sapply(abund.list.12, function(genus) {
					genus.p <- t(t(genus) / sf)
					genus.p <- apply(genus.p, 1, function(x) {
								cutoff <- quantile(x, winsor.qt)
								x[x >= cutoff] <- cutoff
								x
							}
					)
					# column/row switch
					genus.w <- t(round(genus.p * sf))
				})
		# OTU table
		otu.tab.12.p <- t(t(otu.tab.12) / sf)
		otu.tab.12.p <- apply(otu.tab.12.p, 1, function(x) {
					cutoff <- quantile(x, winsor.qt)
					x[x >= cutoff] <- cutoff
					x
				}
		)
		# column/row switch
		otu.tab.12 <- t(round(otu.tab.12.p * sf))
	} else {
		winsor <- FALSE
		winsor.qt <- NULL
	}

	# Rarefaction/Normalizing factors are not calculated for functional data
    # Rev: 2017_01_19 the sample IDs for functional data are not ordered! Potential Danger! augment with NA
	if (!is.null(ko.file)) {
		
		cat("Load kegg file...\n")
		ko <- read_biom(ko.file)
		ko.dat <- as.matrix(biom_data(ko))
		
		if (sum(!(samIDs %in% colnames(ko.dat))) != 0) {
			missingIDs <- setdiff(samIDs, colnames(ko.dat))
			aug.mat <- matrix(NA, nrow(ko.dat), length(missingIDs))
			colnames(aug.mat) <- missingIDs
			rownames(aug.mat) <- rownames(ko.dat)
			ko.dat <- cbind(ko.dat, aug.mat) 
		}	
		
		ko.dat <- ko.dat[, samIDs]
		# Rarefaction?
	  
	    if (is.null(ko.ann.file)) {
			# Old - back compatability
			ko.ann <- observation_metadata(ko)
			ko.ann <- cbind(KEGG_Pathways1=sapply(ko.ann, function(x) x['KEGG_Pathways1']), 
					KEGG_Pathways2=sapply(ko.ann, function(x) x['KEGG_Pathways2']), 
					KEGG_Pathways3=sapply(ko.ann, function(x) x['KEGG_Pathways3']))
			rownames(ko.ann) <- rownames(ko.dat)		
			ko.ann[is.na(ko.ann)] <- 'Unclassified'
			
			hierachs <- c("KEGG_Pathways1", "KEGG_Pathways2", "KEGG_Pathways3")
			for (hierach in hierachs) {	
				tax.family <- ko.ann[, hierach]
				family <- aggregate(ko.dat, by=list(tax.family), FUN=sum)
				rownames(family) <- family[, 1]
				family <- as.matrix(family[, -1])
				abund.list.12[[hierach]] <- family
			}
		} else {
			# New
			load(ko.ann.file)
			#
			kos <- rownames(ko.dat)
			abund.list.12[["KEGG_Pathways3"]] <- NULL
			kos.id <- NULL
			for (ko.item in names(kegg.map)) {
				kos.common <- intersect(kos, kegg.map[[ko.item]])
				if (length(kos.common) != 0) {
					abund.list.12[["KEGG_Pathways3"]] <- rbind(abund.list.12[["KEGG_Pathways3"]], colSums(ko.dat[kos.common, , drop=F]))
					kos.id <- c(kos.id, ko.item)
				}
			}
			rownames(abund.list.12[["KEGG_Pathways3"]]) <- kos.id
			
			abund.list.12[["KEGG_Metabolism"]] <- abund.list.12[["KEGG_Pathways3"]][intersect(kos.id, unlist(kegg.ann[['Metabolism']])), ]
			rownames(abund.list.12[["KEGG_Metabolism"]]) <- paste0('M', rownames(abund.list.12[["KEGG_Metabolism"]])) 
			
			abund.list.12[["KEGG_Defense"]] <- NULL
			kos.id <- NULL
			for (ko.item in names(defense.map)) {
				kos.common <- intersect(kos, defense.map[[ko.item]])
				if (length(kos.common) != 0) {
					abund.list.12[["KEGG_Defense"]] <- rbind(abund.list.12[["KEGG_Defense"]], colSums(ko.dat[kos.common, , drop=F]))
					kos.id <- c(kos.id, ko.item)
				}
			}
			rownames(abund.list.12[["KEGG_Defense"]]) <- kos.id
			
			abund.list.12[["KEGG_Toxin"]] <- NULL
			kos.id <- NULL
			for (ko.item in names(toxin.map)) {
				kos.common <- intersect(kos, toxin.map[[ko.item]])
				if (length(kos.common) != 0) {
					abund.list.12[["KEGG_Toxin"]] <- rbind(abund.list.12[["KEGG_Toxin"]], colSums(ko.dat[kos.common, , drop=F]))
					kos.id <- c(kos.id, ko.item)
				}
			}
			rownames(abund.list.12[["KEGG_Toxin"]]) <- kos.id
		}
	
	}
	
	if (!is.null(cog.file)) {
		cat("Load cog file...\n")
		cog <- read_biom(cog.file)
		cog.dat <- as.matrix(biom_data(cog))
		
		if (sum(!(samIDs %in% colnames(cog.dat ))) != 0) {
			missingIDs <- setdiff(samIDs, colnames(cog.dat ))
			aug.mat <- matrix(NA, nrow(cog.dat), length(missingIDs))
			colnames(aug.mat) <- missingIDs
			rownames(aug.mat) <- rownames(cog.dat)
			cog.dat  <- cbind(cog.dat, aug.mat) 
		}	
		
		cog.dat <- cog.dat[, samIDs]
		
		# rarefaction?
		cog.ann <- observation_metadata(cog)
		hierachs <- c("COG_Category1", "COG_Category2")
		for (hierach in hierachs) {	
			tax.family <- sapply(cog.ann, function(x) x[hierach])
			family <- aggregate(cog.dat, by=list(tax.family), FUN=sum)
			rownames(family) <- family[, 1]
			family <- as.matrix(family[, -1])
			abund.list.12[[hierach]] <- family
		}
	}
		
	# Drop tree tips
    if (!is.null(tree.12)) {
		absent <- tree.12$tip.label[!(tree.12$tip.label %in% rownames(otu.tab.12))]
		if (length(absent) != 0) {
			tree.12 <- drop.tip(tree.12, absent)
			warning("The tree has OTUs not in the OTU table!")
		}
	}

	data.obj <- list(otu.tab=otu.tab.12, abund.list=abund.list.12, meta.dat=meta.dat, tree=tree.12,
			otu.name=otu.name.12, otu.name.full=otu.name.full, 
			size.factor=sf, norm.method=norm, norm.level=level, 
			winsor=winsor, winsor.qt=winsor.qt,
			rff=rff, rff.dep=dep, act.seq=act.seq,
			call=match.call())
}


# 2020_01_16: convert phyloseq object to our object
convert_phyloseq_obj <- function (phylo.obj, species = TRUE) {
	
	otu.tab <- otu_table(phylo.obj)@.Data
	meta.dat <- data.frame(sample_data(phylo.obj))
	otu.name <- tax_table(phylo.obj)@.Data
	tree <- phy_tree(phylo.obj)
	if(!is.rooted(tree)) {
		cat('Root the tree by midpointing ... \n')
		tree <- midpoint(tree)
	} 
	
	ind <- rowSums(otu.tab) > 0
	if (sum(!ind) != 0) {
		cat('Remove ', sum(!ind), ' OTUs with all 0s! \n')
		otu.tab <- otu.tab[ind, ] 
		otu.name <- otu.name[ind, ]
	}
	
	absent <- tree$tip.label[!(tree$tip.label %in% rownames(otu.tab))]
	if (length(absent) != 0) {
		cat('Drop OTUs not in the OTU table ...\n')
		tree <- drop.tip(tree, absent)
	}
	
	
	if (sum(rownames(otu.name) != rownames(otu.tab)) != 0) stop('Inconsistent OTU names!\n')
	if (sum(rownames(meta.dat) != colnames(otu.tab)) != 0) stop('Inconsistent sample names!\n')
	
	
# Create abundance list
	cat("Create taxa abundance list ...\n")
	abund.list <- list()
	hierachs <- c('Phylum', 'Class', 'Order', 'Family', 'Genus')
	for (hierach in hierachs) {	
		if (hierach != 'Phylum') {
			single.names <- otu.name[, hierach]
			#	single.names[grepl('unclassified', single.names, ignore.case=T)] <- paste0('Unclassified',substr(hierach, 1, 1))
			tax.family <- paste(otu.name[, 'Phylum'], single.names, sep=";")
			tax.family[grepl('unclassified', tax.family, ignore.case = T)] <- paste0('Unclassified_', hierach)
		} else {
			tax.family <- otu.name[, 'Phylum']
			tax.family[grepl('unclassified', tax.family, ignore.case = T)] <- 'Unclassified_Phylum'
		}
		family <- aggregate(otu.tab, by = list(tax.family), FUN = sum)
		rownames(family) <- family[, 1]
		family <- as.matrix(family[, -1])
		abund.list[[hierach]] <- family
	}
	
	if (species) {
		abund.list[['Species']] <- otu.tab
		rownames(abund.list[['Species']]) <- paste0("OTU", rownames(otu.tab), ":", otu.name[, 'Phylum'], ";", otu.name[, 'Genus'])
	}
	cat('Completed!\n')
	data.obj <- list(otu.tab = otu.tab, abund.list = abund.list, meta.dat = meta.dat, tree = tree,
			otu.name = otu.name, otu.name.full = otu.name, call=match.call())
	return(data.obj)
}


# New: 2016_12_12, separate rarafaction and load data
# Functional data will not be rarefied
rarefy_data <- function (data.obj, dep=NULL) {
	otu.tab.12 <- data.obj$otu.tab
	otu.name.12 <- data.obj$otu.name
	otu.name.full <- data.obj$otu.name.full
#	abund.list.12 <- data.obj$abund.list
	siz.factor <- data.obj$size.factor
	meta.dat <- data.obj$meta.dat
	
	cat('Rarefaction ...\n')
	if (is.null(dep)) {
		otu.tab.12 <- t(Rarefy(t(otu.tab.12))$otu.tab.rff)
	} else {
		otu.tab.12 <- t(Rarefy(t(otu.tab.12), dep)$otu.tab.rff)
	}	
	dep <- colSums(otu.tab.12)[1]
	cat("Depth ", dep, '\n')
	# Remove empty OTUs
	otu.ind <- rowSums(otu.tab.12) > 0  # rev:2016-06-28
	otu.tab.12 <- otu.tab.12[otu.ind, ]	
	otu.name.12 <- otu.name.12[otu.ind, ]
	otu.name.full <- otu.name.full[otu.ind, ]
	
	samIDs <- intersect(rownames(meta.dat), colnames(otu.tab.12))

	if (length(samIDs) < nrow(meta.dat)) {
		warning('Some samples were lost during rarefaction!\n')
	}
	
	meta.dat <- meta.dat[samIDs, ]
	otu.tab.12 <- otu.tab.12[, samIDs]
	
	data.obj$meta.dat <- meta.dat  # Rev: 2017_01_19
	data.obj$otu.tab <- otu.tab.12
	data.obj$otu.name <- otu.name.12
	data.obj$otu.name.full <- otu.name.full
#	data.obj$abund.list <- abund.list.12
	data.obj$rff <- TRUE
	data.obj$rff.depth <- dep
	cat('After rarefaction, the size factor is automatically set to be the rarefaction depth!\n')
	data.obj$norm.method <- 'TSS'
	data.obj$norm.level <- 'OTU'
	data.obj$size.factor <- colSums(otu.tab.12)
	
	# Futher subset if it contains functional data
    data.obj <- subset_data(data.obj, samIDs)
	data.obj$act.seq <- paste0(data.obj$act.seq, 'R')
	
	cat("Recreate taxa abundance list ...\n")
	data.obj <- aggregate_by_taxonomy(data.obj)

	return(data.obj)
}

# New: 2018_08_22, rarefaction by strata
# Functional data will not be rarefied
rarefy_data_strata <- function (data.obj, strata1, strata2) {
	otu.tab.12 <- data.obj$otu.tab
	otu.name.12 <- data.obj$otu.name
	otu.name.full <- data.obj$otu.name.full
#	abund.list.12 <- data.obj$abund.list
	siz.factor <- data.obj$size.factor
	meta.dat <- data.obj$meta.dat
	
	cat('Rarefaction by strata ...\n')
	strata1 <- data.obj$meta.dat[, strata1]
	strata2 <- data.obj$meta.dat[, strata2]
	
	strata <- factor(paste(strata1, strata2))
	slevels <- levels(strata)
	
	for (slevel in slevels) {
		ind <- which(strata == slevel)
		if (length(ind) >= 2) {
			otu.tab.12[, ind] <- t(Rarefy(t(otu.tab.12[, ind]))$otu.tab.rff)
		}
	}

	# Remove empty OTUs
	otu.ind <- rowSums(otu.tab.12) > 0  # rev:2016-06-28
	otu.tab.12 <- otu.tab.12[otu.ind, ]	
	otu.name.12 <- otu.name.12[otu.ind, ]
	otu.name.full <- otu.name.full[otu.ind, ]
	
	samIDs <- intersect(rownames(meta.dat), colnames(otu.tab.12))
	
	if (length(samIDs) < nrow(meta.dat)) {
		warning('Some samples were lost during rarefaction!\n')
	}
	
	meta.dat <- meta.dat[samIDs, ]
	otu.tab.12 <- otu.tab.12[, samIDs]
	
	data.obj$meta.dat <- meta.dat  # Rev: 2017_01_19
	data.obj$otu.tab <- otu.tab.12
	data.obj$otu.name <- otu.name.12
	data.obj$otu.name.full <- otu.name.full
#	data.obj$abund.list <- abund.list.12
	data.obj$rff <- TRUE
	data.obj$rff.depth <- dep
	cat('After rarefaction, the size factor is automatically set to be the rarefaction depth!\n')
	data.obj$norm.method <- 'TSS'
	data.obj$norm.level <- 'OTU'
	data.obj$size.factor <- colSums(otu.tab.12)
	
	# Futher subset if it contains functional data
	data.obj <- subset_data(data.obj, samIDs)
	data.obj$act.seq <- paste0(data.obj$act.seq, 'R')

	cat("Recreate taxa abundance list ...\n")
    data.obj <- aggregate_by_taxonomy(data.obj)
	return(data.obj)
}

# New: 2017_04_18
# Rev: 2020_02_20 'species'
remove_otu <- function (data.obj, ind) {

	data.obj$otu.tab <- data.obj$otu.tab[ind, ]
	data.obj$otu.name <- data.obj$otu.name[ind, ]
	data.obj$otu.name.full <- data.obj$otu.name.full[ind, ]
	
# Re-create Abundance 
#	otu.name <- data.obj$otu.name
#	otu.tab <- data.obj$otu.tab
#	abund.list <- list()
#
#	for (hierach in setdiff(hierachs, 'Species')) {	
#		if (hierach != 'Phylum') {
#			single.names <- otu.name[, hierach]
#			#	single.names[grepl('unclassified', single.names, ignore.case=T)] <- paste0('Unclassified',substr(hierach, 1, 1))
#			tax.family <- paste(otu.name[, 'Phylum'], single.names, sep=";")
#			tax.family[grepl('unclassified', tax.family, ignore.case=T)] <- paste0('Unclassified_', hierach)
#		} else {
#			tax.family <- otu.name[, 'Phylum']
#			tax.family[grepl('unclassified', tax.family, ignore.case=T)] <- 'Unclassified_Phylum'
#		}
#		family <- aggregate(otu.tab, by=list(tax.family), FUN=sum)
#		rownames(family) <- family[, 1]
#		family <- as.matrix(family[, -1])
#		abund.list[[hierach]] <- family
#	}
#	
#	if ('Species' %in% hierachs) {
#		abund.list[['Species']] <- otu.tab
#		rownames(abund.list[['Species']]) <- paste0("OTU", substr(rownames(otu.tab), 1, max.nchar), ":", otu.name[, 'Phylum'], ";", otu.name[, 'Genus'])
#	}
#	data.obj$abund.list <- abund.list
	
	data.obj <- aggregate_by_taxonomy(data.obj, species = 'Species' %in% names(data.obj$abund.list))
	
	return(data.obj)
}

# New: 2017_10_17
update_name <- update_sample_name <- function (data.obj, new.name) {
	
	if (length(new.name) != nrow(data.obj$meta.dat)) stop('The number of sample do not agree!\n')
	if (length(new.name) != length(unique(new.name))) stop ('The new names have duplicates!\n')
	
	rownames(data.obj$meta.dat) <- new.name
	data.obj$abund.list <- lapply(data.obj$abund.list, function (x) {colnames(x) <- new.name; x})
	colnames(data.obj$otu.tab) <- new.name
    if(!is.null(data.obj$size.factor))  names(data.obj$size.factor) <- new.name
	
	return(data.obj)
}

# Rev: 2016_09_22
update_data <- update_meta_data <- function (data.obj, map.file, meta.sep='\t', quote="\"", comment="", ...) {
	cat("Load meta file...\n")
	if (is.character(map.file)) {
		if (grepl("csv$", map.file)) {
			meta.dat <- read.csv(map.file, header=T, check.names=F, row.names=1, comment=comment, quote=quote, ...)
		} else {
			meta.dat <- read.table(map.file, header=T, check.names=F, row.names=1, comment=comment, sep=meta.sep, quote=quote, ...)
		}
	} else {
		meta.dat <- map.file
	}
    
	data.obj$meta.dat <- meta.dat
	
	samIDs <- intersect(rownames(meta.dat), colnames(data.obj$otu.tab))
	if (length(samIDs) == 0)  stop('Sample names in the meta file and biom file differ?\n')
    data.obj <- subset_data(data.obj, samIDs)
	return(data.obj)
}

# When the otu.name has detailed species level inofrmation
aggregate_by_taxonomy <- function (data.obj, species = TRUE) {
	
	max.nchar <- 4

	hierachs <- c('Phylum', 'Class', 'Order', 'Family', 'Genus')
	otu.name.12 <- data.obj$otu.name
	otu.name.12[is.na(otu.name.12) | otu.name.12 %in% c('', 'NA')] <- 'unclassified'
	otu.tab.12 <- data.obj$otu.tab
	
	abund.list.12 <- list()
	for (hierach in hierachs) {	
		if (!(hierach %in% c('Phylum'))) {
			single.names <- otu.name.12[, hierach]
			#	single.names[grepl('unclassified', single.names, ignore.case=T)] <- paste0('Unclassified',substr(hierach, 1, 1))
			tax.family <- paste(otu.name.12[, 'Phylum'], single.names, sep=";")
			tax.family[grepl('unclassified', tax.family, ignore.case=T)] <- paste0('Unclassified_', hierach)
		} else {
			tax.family <- otu.name.12[, hierach]
			tax.family[grepl('unclassified', tax.family, ignore.case=T)] <- paste0('Unclassified_', hierach)
		}
		family <- aggregate(otu.tab.12, by=list(tax.family), FUN=sum)
		rownames(family) <- family[, 1]
		family <- as.matrix(family[, -1])
		abund.list.12[[hierach]] <- family
	}
	
	if (species) {
		abund.list.12[['Species']] <- otu.tab.12
		hierachs <- c(hierachs, 'Species')
		rownames(abund.list.12[['Species']]) <- paste0('A', substr(rownames(otu.tab.12), 1, max.nchar), ":", otu.name.12[, 'Phylum'], ";", otu.name.12[, 'Genus'])
	}
	
	# still keep other levels
	if (is.null(data.obj$abund.list)) {
		data.obj$abund.list <- list()
	}
	for (hierach in hierachs) {
		data.obj$abund.list[[hierach]] <- abund.list.12[[hierach]]
	}
	
	return(data.obj)
}

# When the otu.name has detailed species level inofrmation
aggregate_by_taxonomy2 <- function (data.obj, species = TRUE) {
	if (!species) {
		hierachs <- c('Phylum', 'Class', 'Order', 'Family', 'Genus')
	} else {
		hierachs <- c('Phylum', 'Class', 'Order', 'Family', 'Genus', 'Species')
	}
	
	otu.name.12 <- data.obj$otu.name
	otu.name.12[is.na(otu.name.12) | otu.name.12 %in% c('', 'NA')] <- 'unclassified'
	otu.tab.12 <- data.obj$otu.tab
	
	abund.list.12 <- list()
	for (hierach in hierachs) {	
		if (!(hierach %in% c('Phylum', 'Species'))) {
			single.names <- otu.name.12[, hierach]
			#	single.names[grepl('unclassified', single.names, ignore.case=T)] <- paste0('Unclassified',substr(hierach, 1, 1))
			tax.family <- paste(otu.name.12[, 'Phylum'], single.names, sep=";")
			tax.family[grepl('unclassified', tax.family, ignore.case=T)] <- paste0('Unclassified_', hierach)
		} else {
			tax.family <- otu.name.12[, hierach]
			tax.family[grepl('unclassified', tax.family, ignore.case=T)] <- paste0('Unclassified_', hierach)
		}
		family <- aggregate(otu.tab.12, by=list(tax.family), FUN=sum)
		rownames(family) <- family[, 1]
		family <- as.matrix(family[, -1])
		abund.list.12[[hierach]] <- family
	}
	# still keep other levels
	if (is.null(data.obj$abund.list)) {
		data.obj$abund.list <- list()
	}
	for (hierach in hierachs) {
		data.obj$abund.list[[hierach]] <- abund.list.12[[hierach]]
	}
	
	return(data.obj)
}

# New: 2017_02_16  aggregate data
# New: 2017_11_02  add more variable
aggregate_data <- function (data.obj, subject, strata = NULL) {
	cat('Aggregate data by a factor ...\n')
	subject <- (data.obj$meta.dat[,  subject])
	
	if (!is.null(strata)) {
		grp <- (data.obj$meta.dat[,  strata])
	}

	data.obj.new <- list()
	abund.list<- list()
	for (name in names(data.obj$abund.list)) {
		abund <- data.obj$abund.list[[name]]
		if (is.null(strata)) {
			obj <- aggregate(t(abund), by=list(subject), sum)
			abund.list[[name]] <- t(as.matrix(obj[, -1]))
			colnames(abund.list[[name]]) <- obj[, 1]
		} else {
			obj <- aggregate(t(abund), by=list(subject, grp), sum)
			abund.list[[name]] <- t(as.matrix(obj[, -(1:2)]))
			colnames(abund.list[[name]]) <- paste(obj[, 1], obj[, 2], sep="_")
		}
	}
	data.obj.new$abund.list <- abund.list
	
	abund <- data.obj$otu.tab
	if (is.null(strata)) {
		obj <- aggregate(t(abund), by=list(subject), sum)
		otu.tab <- t(as.matrix(obj[, -1]))
		colnames(otu.tab) <- obj[, 1]
	} else {
		obj <- aggregate(t(abund), by=list(subject, grp), sum)
		otu.tab <- t(as.matrix(obj[, -(1:2)]))
		colnames(otu.tab) <- paste(obj[, 1], obj[, 2], sep="_")
	}

	data.obj.new$otu.tab <- otu.tab
	
	data.obj.new$tree <- data.obj$tree
	data.obj.new$otu.name <- data.obj$otu.name
	data.obj.new$otu.name.full <- data.obj$otu.name.full
	
	if (is.null(strata)) {
		unique.ct <- aggregate(data.obj$meta.dat, by=list(subject), function(x) {
					length(unique(x))
				})
		
		unique.ct <- as.matrix(unique.ct[, -1])
		ind <- colSums(unique.ct) == nlevels(factor(subject))
		
		meta.dat <- aggregate(data.obj$meta.dat, by=list(subject), function(x) {
					x[1]
				})
		rownames(meta.dat) <- meta.dat[, 1]
		meta.dat <- meta.dat[, -1]
		meta.dat <- meta.dat[, ind]
	} else {
		unique.ct <- aggregate(data.obj$meta.dat, by=list(subject, grp), function(x) {
					length(unique(x))
				})
		
		unique.ct <- as.matrix(unique.ct[, -(1:2)])
		ind <- colSums(unique.ct) == nrow(unique.ct)
		
		meta.dat <- aggregate(data.obj$meta.dat, by=list(subject, grp), function(x) {
					x[1]
				})
		rownames(meta.dat) <- paste(meta.dat[, 1], meta.dat[, 2], sep="_")
		meta.dat <- meta.dat[, -(1:2)]
		meta.dat <- meta.dat[, ind]
	}

	data.obj.new$meta.dat <- meta.dat
	data.obj.new$winsor <- data.obj$winsor
	data.obj.new$winsor.qt <- data.obj$winsor.qt
	data.obj.new$rff <- data.obj$rff
	data.obj.new$act.seq <- paste0(data.obj$act.seq, 'A')

	cat('Finished!\n')
	return(data.obj.new)
}

# New: 2017_06_01 Remove reads belonging to specific taxa
remove_taxa <- function (data.obj, taxa.level='Genus', taxa.names) {
	# Remove Methanothermococcus
	if (taxa.level == 'OTU') {
		if (is.numeric(taxa.names)) warning('taxa.names should be characters!\n')
		ind <- !(rownames(data.obj$otu.tab) %in% paste(taxa.names))
		if (sum(!ind) == 0) {
			warning('Do not detect the given OTUs! Check the OTU names!\n')
			return(data.obj)
		}
	} else {
		if (!taxa.level %in% colnames(data.obj$otu.name)) {
			stop("Can't find the specified taxa levels!\n")
		}
		ind <- !(data.obj$otu.name[, taxa.level] %in% taxa.names)
		
		if (sum(!ind) == 0) {
			warning('Do not detect the given taxa! Check the taxa level!\n')
			return(data.obj)
		}
	}

	cat(sum(!ind), ' OTUs will be removed!\n')
	
	data.obj$otu.tab <- data.obj$otu.tab[ind, ]
	data.obj$otu.name <- data.obj$otu.name[ind, ]
	data.obj$otu.name.full <- data.obj$otu.name.full[ind, ]
	
# Re-create Abundance 
	otu.name <- data.obj$otu.name
	otu.tab <- data.obj$otu.tab
	abund.list <- list()
	hierachs <- c('Phylum', 'Class', 'Order', 'Family', 'Genus')
	for (hierach in hierachs) {	
		if (hierach != 'Phylum') {
			single.names <- otu.name[, hierach]
			#	single.names[grepl('unclassified', single.names, ignore.case=T)] <- paste0('Unclassified',substr(hierach, 1, 1))
			tax.family <- paste(otu.name[, 'Phylum'], single.names, sep=";")
			tax.family[grepl('unclassified', tax.family, ignore.case=T)] <- paste0('Unclassified_', hierach)
		} else {
			tax.family <- otu.name[, 'Phylum']
			tax.family[grepl('unclassified', tax.family, ignore.case=T)] <- 'Unclassified_Phylum'
		}
		family <- aggregate(otu.tab, by=list(tax.family), FUN=sum)
		rownames(family) <- family[, 1]
		family <- as.matrix(family[, -1])
		abund.list[[hierach]] <- family
	}
	if ('Species' %in% names(data.obj$abund.list)) {
		abund.list[['Species']] <- data.obj$abund.list[['Species']][ind, ]
	}
	data.obj$abund.list <- abund.list
	# Erase size factor
	data.obj$size.factor <- NULL
	data.obj$norm.method <- NULL
	data.obj$norm.level <- NULL
	if (!is.na.null(data.obj$rff)) {
		if (data.obj$rff == TRUE) {
			warning('The function is not intended to be applied to rarefied object! Rarefaction should be performed again!\n')
			data.obj$rff <- FALSE
			data.obj$rff.dep <- NULL
		}
	}
    data.obj$act.seq <- NULL
	cat('Remove taxa Finished!\n')
	
	ind <- colSums(data.obj$otu.tab) != 0
	
	if (sum(!ind) != 0) {
		cat(sum(!ind), ' samples contain no reads and they are removed!')
		data.obj <- subset_data(data.obj, ind)
	}
	return(data.obj)
}
# New: 2016_12_12
# intersect.no=4, winsor.qt=0.97
calculate_size <- function (data.obj, level='OTU', norm='GMPR', ...) {
	if (!is.null(data.obj$rff)) {
		if (data.obj$rff)
		warning("The data has been rarefied! Better calculate the size factor for unrarefied data!\n")
	}
	if (!is.null(data.obj$winsor)) {
		if (data.obj$winsor) {
			warning("The data has been winsorized! Better calculate the size factor before winsorization!\n")
		}
	}

	if (level == 'OTU') {
		data <- data.obj$otu.tab
	} else {
		if (level %in% names(data.obj$abund.list)) {
			data <- data.obj$abund.list[[level]]
		} else {
			data <- data.obj$otu.tab
			level <-'OTU'
			warning('No or wrong level specified! OTU level will be used!\n')
		}
	}
	if (norm == 'TSS') {
		sf <- colSums(data)
		norm <- 'TSS'
	}
	if (norm == 'GMPR') {
		sf <- GMPR(data, ...)
#		warning('GMPR is only suitable for samples from a same body location!\n')
		norm <- 'GMPR'
	}
	names(sf) <- colnames(data)
	data.obj$size.factor <- sf
	data.obj$norm.method <- norm
	data.obj$norm.level <- level
	data.obj$act.seq <- paste0(data.obj$act.seq, 'N')
	return(data.obj)
}

# Rev: 2016_12_08
winsor_data <- function (data.obj, winsor.qt=0.97) {
	if (data.obj$rff) {
		warning("The data has been rarefied! Better winsorize without rarefaction!\n")
	}
    cat('Winsorize ...\n')
	if (is.null(winsor.qt)) {
		winsor.qt <- 0.97
	}
	otu.tab.12 <- data.obj$otu.tab
	abund.list.12 <- data.obj$abund.list
	
    # Rev: 2016_12_08
	if (is.null(data.obj$size.factor)) {
		sf <- colSums(otu.tab.12)
		data.obj$norm.method <- 'TSS'
		data.obj$norm.level <- 'OTU'
		data.obj$size.factor <- sf
		cat('Size factor not available! Calculating using total sum! You may consider using better method such as GMPR!\n')
		data.obj$act.seq <- paste0(data.obj$act.seq, 'N')
	} else {
		sf <- data.obj$size.factor
	}
	
	# Addressing the outlier (97% percent) or at least one outlier
	abund.list.12 <- lapply(abund.list.12, function(genus) {
				genus.p <- t(t(genus) / sf)
				genus.p <- apply(genus.p, 1, function(x) {
							cutoff <- quantile(x, winsor.qt)
							x[x >= cutoff] <- cutoff
							x
						}
				)
				# column/row switch
				genus.w <- t(round(genus.p * sf))
			})
	# OTU table
	otu.tab.12.p <- t(t(otu.tab.12) / sf)
	otu.tab.12.p <- apply(otu.tab.12.p, 1, function(x) {
				cutoff <- quantile(x, winsor.qt)
				x[x >= cutoff] <- cutoff
				x
			}
	)
	# column/row switch
	otu.tab.12 <- t(round(otu.tab.12.p * sf))
	data.obj$winsor <- TRUE
	data.obj$winsor.qt <- winsor.qt
    data.obj$otu.tab <- otu.tab.12
	data.obj$abund.list <- abund.list.12
	data.obj$act.seq <- paste0(data.obj$act.seq, 'W')
	#data.obj$size.factor <- sf
	return(data.obj)
}

# Rev: 2016_11_28, Bray-curtis use normalized data.
construct_distance <- function (data.obj, unifrac.file=NULL,  Phylum='All', dist.RData=NULL, save.RData=NULL, 
		filter.no=0, rff=FALSE, dep=NULL, seed=1234) {
	set.seed(seed)
	
	if (!is.null(dist.RData)) {
		load(dist.RData, envir=.GlobalEnv )
	} else {
		dist.list.12 <- list()
		cat("Generalized UniFrac ...\n")
		
		otu.tab <- t(data.obj$otu.tab)
		
		if (rff == TRUE) {
			if (is.null(dep)) {
				otu.tab <- Rarefy(otu.tab)$otu.tab.rff
			} else {
				otu.tab <- Rarefy(otu.tab, dep)$otu.tab.rff
			}	
		}
				
		if (Phylum != 'All') {
			ind <- data.obj$otu.name[, 'Phylum'] == Phylum
			otu.tab <- otu.tab[, ind]
		}
		
		# Filter otus with reads <= filter.no
		otu.tab <- otu.tab[, colSums(otu.tab) > filter.no]
        
		# Remove samples with no reads
		if (sum(rowSums(otu.tab) == 0) >= 1) {
			otu.tab <- otu.tab[rowSums(otu.tab) != 0, ]
			warning('Some samples do not have reads after rarefaction! Please be careful!\n')
		}
		
		# To make sure the OTUs in otu.tab are in the tree (rev:2016-06-19)
		
		if (sum(!(colnames(otu.tab) %in% data.obj$tree$tip.label))) {
			warning('Some OTU names are not in the tree! An intersection set will be used!\n')	
		}
		common.otus <- intersect(colnames(otu.tab), data.obj$tree$tip.label)
		unifrac12 <- GUniFrac(otu.tab[, common.otus], data.obj$tree)$unifracs
	
		dist.list.12[['WUniFrac']] <- unifrac12[, , 'd_1']
		dist.list.12[['GUniFrac']] <- unifrac12[, , 'd_0.5']
		if (is.null(unifrac.file)) {
			dist.list.12[['UniFrac']] <- unifrac12[, , 'd_UW']
		} else {
			# The orders may be different
			dist.list.12[['UniFrac']] <- as.matrix(read.table(unifrac.file, row.names=1, header=T)) # Rarefaction
		}

		# Need speed up
		# Suggest using rarefied counts 
	    # If case/control has different sequencing depth, it will result in false clustering! 
        # Rev: 2016_11_28 Use normalized data for BC distance calculation to reduce noise in case of variable library size
		dist.list.12[['BC']] <-as.matrix(vegdist(otu.tab / rowSums(otu.tab)))
		
		genus <- t(data.obj$abund.list[['Genus']])
		genus <- genus / rowSums(genus)
		dist.list.12[['Euc']] <- as.matrix(dist(genus))
		
		genus <- sqrt(genus)
		dist.list.12[['Hel']] <-as.matrix(dist(genus))
#		dist.list.12[['JS']] <- as.matrix(distance(otu_table(data.obj$abund.list[['Genus']], taxa_are_rows=T), method='jsd'))
		
		if (!is.null(save.RData)) {
			save(dist.list.12, file=save.RData)
		}
	}

    return(dist.list.12)
}


outlier_detect <- function (data.obj, dist.obj, min.dep=2000) {
	# Future development
	samIDs <- colnames(data.obj$otu.tab)[colSums(data.obj$otu.tab) >= 2000]
	return(samIDs)
}

is.na.null <- function (x) {
	if (is.null(x)) {
		return(TRUE)
	} else {
		if (is.na(x)[1]) {
			return(TRUE)
		}  else {
			return(FALSE)
		}
	}
	
}

# Rev: 2016_09_26 remove empty OTUs/taxa
# Rev: 2016_12_01 add more logical controls
subset_data <- function (data.obj, samIDs) {
	
	# Rev: 2016_1_19 to add error protection
	# Transform logical samIDs into characer samIDs
	if (is.logical(samIDs) | is.numeric(samIDs)) {
		samIDs <- rownames(data.obj$meta.dat)[samIDs]
	}
	
	data.obj$meta.dat <- data.obj$meta.dat[samIDs, , drop=FALSE]

	if (!is.na.null(data.obj$otu.tab)) {

		data.obj$otu.tab <- data.obj$otu.tab[, samIDs, drop=FALSE]
		data.obj$otu.tab <- data.obj$otu.tab[rowSums(data.obj$otu.tab) != 0, , drop=FALSE]
		data.obj$otu.name <- data.obj$otu.name[rownames(data.obj$otu.tab), , drop=FALSE]

		if (!is.na.null(data.obj$otu.name.full)) {
			data.obj$otu.name.full <- data.obj$otu.name.full[rownames(data.obj$otu.tab), , drop=FALSE]
		}
	}

	if (!is.na.null(data.obj$abund.list)) {
		data.obj$abund.list <- lapply(data.obj$abund.list, function(x) {
					xx <- x[, samIDs, drop=FALSE]
					xx <- xx[rowSums(xx) != 0, , drop=FALSE]
				})
	}

	if (!is.na.null(data.obj$size.factor)) {
		data.obj$size.factor <- data.obj$size.factor[samIDs]
	}

	if (!is.na.null(data.obj$ko.list)) {
		data.obj$ko.list <- lapply(data.obj$ko.list, function(x) {
					xx <- x[, samIDs, drop=FALSE]
					xx <- xx[rowSums(xx) != 0, , drop=FALSE]
				})
	}

	if (!is.na.null(data.obj$cog.list)) {
		data.obj$cog.list <- lapply(data.obj$cog.list, function(x) {
					xx <- x[, samIDs, drop=FALSE]
					xx <- xx[rowSums(xx) != 0, , drop=FALSE]
				})
	}
	return(data.obj)
}

# Rev: 2016_12_01 add more logical controls
# Rev: 2016_02_01 fix one error
subset_dist <- function (dist.obj, samIDs) {
	
	# Rev: 2016_1_19 to add error protection
	# Transform logical samIDs into character samIDs
	if (is.logical(samIDs) | is.numeric(samIDs)) {
		samIDs <- rownames(dist.obj[[1]])[samIDs]
	}
	
	lapply(dist.obj, function(x) {
				if(!is.na.null(x)){
					x <- x[samIDs, samIDs]
				} else {
					x
				}
				x
			})
}

# New: 2018_06_10
generate_detailed_taxonomy <- function (data.obj, finest = 'Species', unclassified.symbol='unclassified') {
	# Create abundance list

	otu.name.12 <- data.obj$otu.name
	otu.name.12[otu.name.12 == '' | is.na(otu.name.12)] <- unclassified.symbol 
	otu.tab.12 <- data.obj$otu.tab
	
	if (finest == 'Species') {
		hierachs <- rev(c('Kingdom', 'Phylum', 'Class', 'Order', 'Family', 'Genus', 'Species'))
	} else {
		hierachs <- rev(c('Kingdom', 'Phylum', 'Class', 'Order', 'Family', 'Genus'))
	}
	
	abund.list.12 <- NULL
	otu.tab <- otu.tab.12
	otu.name <- otu.name.12
	for (hierach in hierachs) {	
		single.names <- otu.name[, hierach]
		if (hierach == 'Species' ) {
			tax.family <- paste0(otu.name[, 'Phylum'], ';', single.names)
		} 
		if (hierach %in% c('Phylum', 'Kingdom')) {
			tax.family <- single.names
		} 
		
		if (hierach %in% c('Class', 'Order', 'Family', 'Genus')) {
			tax.family <- single.names
			tax.family <- paste0(otu.name[, 'Phylum'], ';', single.names)
		} 
		
		if (hierach == 'Kingdom') {
			unclassified.ind <- rep(FALSE, length(tax.family))
			classified.ind <- !unclassified.ind
		} else {
			unclassified.ind <- grepl(unclassified.symbol, tax.family, ignore.case=T)
			classified.ind <- !unclassified.ind
		}

		otu.tab0 <- otu.tab[classified.ind, , drop=FALSE]
		tax.family0 <- tax.family[classified.ind, drop=FALSE]
		
		family <- aggregate(otu.tab0, by=list(tax.family0), FUN=sum)
		rownames(family) <- family[, 1]
		family <- as.matrix(family[, -1])
		abund.list.12 <- rbind(abund.list.12, family)

		if (sum(unclassified.ind) != 0) {
			otu.tab <- otu.tab[unclassified.ind, , drop=FALSE]
			otu.name <- otu.name[unclassified.ind, , drop=FALSE]
		} else{
			break
		}

	}
	data.obj$abund.list[['Detailed']] <- abund.list.12
	return(data.obj)
}


# 2020_01_25, allows zero-read samples and allows stratification by grp.name
perform_sequence_stat_analysis2 <- function (data.obj,  ann='', grp.name = NULL, prev.cutoff = 0.9, abund.cutoff = 0.5) {
	
	
	grp <- factor(data.obj$meta.dat[, 'grp.name'])
	levs <- levels(grp)
	
	sink(paste0('Sequence_Analysis_Statistics_', ann, '.txt'))
	otu.tab <- data.obj$otu.tab
	
	# Sequencing depth
	otu.abund <- rowSums(otu.tab)
	sam.abund <- colSums(otu.tab)
	otu.prev <- rowSums(otu.tab != 0) 
	sam.prev <- colSums(otu.tab != 0)
	
	# May keep 0 read sample - e.g. control samples withour reads are also informative
	otu.abund <- otu.abund[otu.abund >= 1]
#	sam.abund <- sam.abund[sam.abund >= 1]
	
	cat('This data set contains ', length(sam.abund), ' samples.\n')
	cat('16S rDNA targeted sequencing yields  a median of ', median(sam.abund), 'reads/sample  (range:', min(sam.abund), '-', max(sam.abund), ').\n')
	cat('Clustering of these 16S sequence tags produces ', sum(otu.abund > 0), ' OTUs at 97% similarity level.\n')
	
	
	phy.abund <- data.obj$abund.list[['Phylum']]
	fam.abund <- data.obj$abund.list[['Family']]
	gen.abund <- data.obj$abund.list[['Genus']]
	
	phy.prev <- rowSums(phy.abund != 0) / ncol(phy.abund)
	fam.prev <- rowSums(fam.abund != 0) / ncol(phy.abund)
	gen.prev <- rowSums(gen.abund != 0) / ncol(phy.abund)
	
	phy.abund <- rowMeans(t(t(phy.abund) / sam.abund))
	fam.abund <- rowMeans(t(t(fam.abund) / sam.abund))
	gen.abund <- rowMeans(t(t(gen.abund) / sam.abund))
	
	cat('These OTUs belong to ', sum(phy.abund > 0), ' phyla,', sum(fam.abund > 0), ' families and ', sum(gen.abund > 0), 'genera.\n\n')
	
	phy.prev <- sort(phy.prev, decr=T)
	phy.prev <- round(phy.prev[phy.prev >= prev.cutoff] * 100, 2)
	
	fam.prev <- sort(fam.prev, decr=T)
	fam.prev <- round(fam.prev[fam.prev >= prev.cutoff] * 100, 2)
	
	gen.prev <- sort(gen.prev, decr=T)
	gen.prev <- round(gen.prev[gen.prev >= prev.cutoff] * 100, 2)
	
	# Rev: 2017_02_19 ' ' -> '\n'
	cat('\nThe most prevalent phyla are:\n', paste(paste0(names(phy.prev), '(', phy.prev, '%)'), collapse='\n'), '\n')
	cat('\nThe most prevalent families are:\n', paste(paste0(names(fam.prev), '(', fam.prev, '%)'), collapse='\n'), '\n')
	cat('\nand the most prevalent genera are:\n', paste(paste0(names(gen.prev), '(', gen.prev, '%)'), collapse='\n'), '\n\n')
	
	phy.abund <- sort(phy.abund, decr=T)
	phy.abund <- round(phy.abund[phy.abund >= abund.cutoff] * 100, 2)
	
	fam.abund <- sort(fam.abund, decr=T)
	fam.abund <- round(fam.abund[fam.abund >= abund.cutoff] * 100, 2)
	
	gen.abund <- sort(gen.abund, decr=T)
	gen.abund <- round(gen.abund[gen.abund >= abund.cutoff] * 100, 2)
	
	cat('\nThe most abundant phyla are:\n', paste(paste0(names(phy.abund), '(', phy.abund, '%)'), collapse='\n'), '\n')
	cat('\nThe most abundant families are:\n', paste(paste0(names(fam.abund), '(', fam.abund, '%)'), collapse='\n'), '\n')
	cat('\nand the most abundant genera are:\n', paste(paste0(names(gen.abund), '(', gen.abund, '%)'), collapse='\n'), '\n\n')
	sink()
	
	pdf(paste0('Sequence_Analysis_Statistics_', ann, '.pdf'), height=5, width=5)
	obj <- ggplot2::ggplot(data=data.frame(x=otu.abund), aes(x=x)) + geom_histogram(col='black', fill='gray') + ylab('Frequency') + xlab('Abundance(Total counts)') +
			scale_x_log10(breaks=c(1, 10, 100, 1000, 10000, 100000, 100000))
	print(obj)
	obj <- ggplot2::ggplot(data=data.frame(x=sam.abund), aes(x=x)) + geom_histogram(col='black', fill='gray')  + ylab('Frequency') + xlab('Sequencing depth')
	print(obj)
	obj <- ggplot2::ggplot(data=data.frame(x=otu.prev), aes(x=x))  + ylab('Frequency') + xlab('OTU prevalence(Occurence frequency)') + geom_histogram(col='black', fill='gray')
	print(obj)
	dev.off()
}

perform_sequence_stat_analysis <- function (data.obj,  ann='') {
	sink(paste0('Sequence_Analysis_Statistics_', ann, '.txt'))
	otu.tab <- data.obj$otu.tab
	
	# Sequencing depth
	otu.abund <- rowSums(otu.tab)
	sam.abund <- colSums(otu.tab)
	otu.prev <- rowSums(otu.tab!=0)/ncol(otu.tab)
	
	# May keep 0 read sample - e.g. control samples withour reads are also informative
	otu.abund <- otu.abund[otu.abund >= 1]
	sam.abund <- sam.abund[sam.abund >= 1]
	cat('This data set contains ', length(sam.abund), ' samples after quality controls.\n')
	cat('16S rDNA targeted sequencing yields ', median(sam.abund), 'reads/sample on average (range:', min(sam.abund), '-', max(sam.abund), ').\n')
	cat('Clustering of these 16S sequence tags produces ', sum(otu.abund > 0), ' OTUs at 97% similarity level.\n')
	
	pdf(paste0('Sequence_Analysis_Statistics_', ann, '.pdf'), height=5, width=5)
	obj <- ggplot2::ggplot(data=data.frame(x=otu.abund), aes(x=x)) + geom_histogram(col='black', fill='gray') + ylab('Frequency') + xlab('Abundance(Total counts)') +
			scale_x_log10(breaks=c(1, 10, 100, 1000, 10000, 100000, 100000))
	print(obj)
	obj <- ggplot2::ggplot(data=data.frame(x=sam.abund), aes(x=x)) + geom_histogram(col='black', fill='gray')  + ylab('Frequency') + xlab('Sequencing depth')
	print(obj)
	obj <- ggplot2::ggplot(data=data.frame(x=otu.prev), aes(x=x))  + ylab('Frequency') + xlab('Prevalence(Occurence frequency)') + geom_histogram(col='black', fill='gray')
	print(obj)
	dev.off()
	
	phy.abund <- data.obj$abund.list[['Phylum']]
	fam.abund <- data.obj$abund.list[['Family']]
	gen.abund <- data.obj$abund.list[['Genus']]
	
	phy.prev <- rowSums(phy.abund != 0) / ncol(phy.abund)
	fam.prev <- rowSums(fam.abund != 0) / ncol(phy.abund)
	gen.prev <- rowSums(gen.abund != 0) / ncol(phy.abund)
	
	phy.abund <- rowMeans(t(t(phy.abund) / sam.abund))
	fam.abund <- rowMeans(t(t(fam.abund) / sam.abund))
	gen.abund <- rowMeans(t(t(gen.abund) / sam.abund))
	
	cat('These OTUs belong to ', sum(phy.abund > 0), ' phyla,', sum(fam.abund > 0), ' families and ', sum(gen.abund > 0), 'genera.\n\n')
	
	phy.prev <- sort(phy.prev, decr=T)
	phy.prev <- round(phy.prev[phy.prev >= 0.90] * 100, 2)
	
	fam.prev <- sort(fam.prev, decr=T)
	fam.prev <- round(fam.prev[fam.prev >= 0.90] * 100, 2)
	
	gen.prev <- sort(gen.prev, decr=T)
	gen.prev <- round(gen.prev[gen.prev >= 0.90] * 100, 2)
	
	# Rev: 2017_02_19 ' ' -> '\n'
	cat('\nThe most prevalent phyla are:\n', paste(paste0(names(phy.prev), '(', phy.prev, '%)'), collapse='\n'), '\n')
	cat('\nThe most prevalent families are:\n', paste(paste0(names(fam.prev), '(', fam.prev, '%)'), collapse='\n'), '\n')
	cat('\nand the most prevalent genera are:\n', paste(paste0(names(gen.prev), '(', gen.prev, '%)'), collapse='\n'), '\n\n')
	
	phy.abund <- sort(phy.abund, decr=T)
	phy.abund <- round(phy.abund[phy.abund >= 0.05] * 100, 2)
	
	fam.abund <- sort(fam.abund, decr=T)
	fam.abund <- round(fam.abund[fam.abund >= 0.05] * 100, 2)
	
	gen.abund <- sort(gen.abund, decr=T)
	gen.abund <- round(gen.abund[gen.abund >= 0.05] * 100, 2)
	
	cat('\nThe most abundant phyla are:\n', paste(paste0(names(phy.abund), '(', phy.abund, '%)'), collapse='\n'), '\n')
	cat('\nThe most abundant families are:\n', paste(paste0(names(fam.abund), '(', fam.abund, '%)'), collapse='\n'), '\n')
	cat('\nand the most abundant genera are:\n', paste(paste0(names(gen.abund), '(', gen.abund, '%)'), collapse='\n'), '\n\n')
	sink()
}

# Retire, using 'arsenal' tableby
perform_demograph_analysis <- function (data.obj, grp.name) {
	obj <- summary(data.obj$meta.dat)
	write.csv(obj, "meta.data.summary.csv", quote=F)

	grp <- data.obj$meta.dat[, grp.name]
	res <- NULL
	pv.vec <- NULL
	if (is.factor(grp)) {
		for (var1 in setdiff(colnames(data.obj$meta.dat), grp.name)) {
			temp <- data.obj$meta.dat[, var1]
			res <- rbind(res, c("", var1, rep("", nlevels(grp) - 1)))
			res <- rbind(res, c("", levels(grp)))
			if (is.factor(temp)) {
				res <- rbind(res, cbind(levels(temp), table(temp, grp)))
				if (nlevels(temp) == 1) {
					pv <- NA
				} else {
					err <- try(
							pv <- formatC(fisher.test(table(temp, grp))$p.value, digit=3)
					)
					if (inherits(err, "try-error")) {
						pv <- NA
					}
				}
				res <- rbind(res, c('Fisher p', pv, rep("", nlevels(grp) - 1)))

			} else {
				res <- rbind(res, c('mean', aggregate(temp, by=list(grp), FUN='mean')[, 2]))
				res <- rbind(res, c('sd', aggregate(temp, by=list(grp), FUN='sd')[, 2]))
				
				err <- try(
						pv <- formatC(summary(aov(temp ~ grp))[[1]][1, 'Pr(>F)'], digit=3)
				)
				if (!inherits(err, "try-error")) {
					res <- rbind(res, c('ANOVA p', pv, rep("", nlevels(grp) - 1)))
				} else {
					res <- rbind(res, c('ANOVA p', 'NA', rep("", nlevels(grp) - 1)))
					pv <- NA
				}

			}
			res <- rbind(res, rep("", nlevels(grp)+1))
			pv.vec <- c(pv.vec, pv)
		}
		
	} else {

		
	}

	write.csv(res, "meta.data.by.grp.csv", row.names=F, quote=F)
	names(pv.vec) <- setdiff(colnames(data.obj$meta.dat), grp.name)
	return(pv.vec)
}


# Rev: 2017_08_23 add automatically create phylo.obj
generate_rarefy_curve <- function (data.obj, phylo.obj=NULL, grp.name, depth=NULL, npoint=10, iter.no=5,
		measures=c('Observed', 'Chao1', 'Shannon', 'InvSimpson'), ann='', gg.cmd="theme(legend.justification=c(1,0), legend.position=c(1,0))", wid=5, hei=5) {
	cat("Create rarefaction curves!\n")
	# Rev: 2017_08_23
	if (is.null(phylo.obj)) {
		phylo.obj <- phyloseq(otu_table(data.obj$otu.tab, taxa_are_rows=T), phy_tree(data.obj$tree), 
				tax_table(data.obj$otu.name), sample_data(data.obj$meta.dat))
	}
	if (is.null(depth)) {
		depth <- min(sample_sums(phylo.obj))
		phylo.even <- rarefy_even_depth(phylo.obj, rngseed=12345)
	} else {
		if (depth > min(sample_sums(phylo.obj))) {
			ind <- sample_sums(phylo.obj) >= depth
			cat(sum(!ind), " samples do not have sufficient number of reads!\n")
			sample_data(phylo.obj) <- sample_data(phylo.obj)[ind, ] 
			data.obj <- subset_data(data.obj, ind)
		}
		phylo.even <- rarefy_even_depth(phylo.obj, depth, rngseed=12345)
	}
	
	df <- data.obj$meta.dat
	grp <- df[, grp.name]
	
	# Rev: 2016_12_12
	if (is.character(grp)) {
		grp <- factor(grp)
	}

	if (!is.factor(grp)) {
		stop('Rarefaction curve needs a factor!\n')
	}
	res <- NULL
	incr <- depth %/% npoint
	sink('temp.txt')
	for (dep in c(10, incr*(1:npoint))) {
		x <- 0
		for (i in 1:iter.no) {
			phylo.even <- rarefy_even_depth(phylo.obj, dep, rngseed=12345+i)
			x <- x + estimate_richness(phylo.even, measures=measures)
		}
		
		res <- rbind(res, t(x[, measures, drop=F]/iter.no))
	}
	colnames(res) <- rownames(df)
	sink()
	
	pdf(paste0("Alpha_diversity_Rarefaction_Curve_", ann, ".pdf"), width=wid, height=hei)
	for (i in 1:length(measures)) {
		measure <- measures[i]
		cat("Measure: ", measure, "\n")
		res2 <- res[(0:(npoint))*length(measures)+i, , drop=F]
		m <- t(apply(res2, 1, function(x) tapply(x, grp, mean)))
		se <- t(apply(res2, 1, function(x) tapply(x, grp, function(y) sd(y)/sqrt(length(y)))))
		uci <- m+se
		lci <- m-se
		
		m <- melt(m)
		uci <- melt(uci)
		lci <- melt(lci)
		
		res2 <- cbind(c(10, incr*(1:npoint)), m[, 2:3], uci[, 3], lci[, 3])
		colnames(res2) <- c('Depth', 'Group', 'mean', 'max', 'min')
		
		res2 <- as.data.frame(res2)
		res2$Group <- factor(res2$Group, levels=levels(grp))
		
		#write.table(res2, paste0("Alpha_diversity_Rarefaction_", ann, "_", measure, ".txt"))
		
		obj <- ggplot(res2, aes(x=Depth, y=mean, color=Group, group=Group)) +
				geom_errorbar(aes(ymin=min, ymax=max), alpha=0.5, width=.25, position=position_dodge(.2)) + 
				geom_line() + 
				geom_point(size=3, shape=21, fill="white") +
				labs(y=measure)

		if (!is.null(gg.cmd)) {
			obj <- obj + eval(parse(text=gg.cmd))
		}
		
		print(obj)		
	}
	dev.off()
}

# Rev: 2016_12_25  Add anova, and record the results
# Rev: 2018_02_24  Remove dependence on Phyloseq
perform_alpha_test <- function (data.obj, phylo.obj=NULL, rarefy=TRUE, depth=NULL, iter.no=5, 
		measures=c('Observed', 'Chao1', 'Shannon', 'InvSimpson'),  model='lm', 
		formula=NULL, grp.name=NULL, adj.name=NULL, ann='', seed=123, ...) {
	# Implement future random effects model
	# Rev: 2017_08_23
	if (is.null(phylo.obj)) {
		phylo.obj <- phyloseq(otu_table(data.obj$otu.tab, taxa_are_rows=T), phy_tree(data.obj$tree), 
				tax_table(data.obj$otu.name), sample_data(data.obj$meta.dat))
	}
	
	result <- list()
	if (rarefy == TRUE) {
		if (is.null(depth)) {
			depth <- min(sample_sums(phylo.obj))
		} else {
			if (depth > min(sample_sums(phylo.obj))) {
				ind <- sample_sums(phylo.obj) >= depth
				cat(sum(!ind), " samples do not have sufficient number of reads!\n")
				sample_data(phylo.obj) <- sample_data(phylo.obj)[ind, ] 
				data.obj <- subset_data(data.obj, ind)
			}
		}
			
		x <- 0
		sink('temp.txt')
		for (i in 1:iter.no) {
			phylo.even <- rarefy_even_depth(phylo.obj, depth, rngseed=12345+i)
			x <- x + estimate_richness(phylo.even, measures=measures)
		}
		sink()
		x <- x / iter.no
	} else {
		x <- estimate_richness(phylo.obj, measures=measures)
	}

	df <- data.obj$meta.dat
	
	fitted.obj <- list()
	
	if (rarefy == T) {
		sink(paste0('Alpha_diversity_test_results_rarefied_', ann, '.txt'))
	} else {
		sink(paste0('Alpha_diversity_test_results_unrarefied_', ann, '.txt'))
	}
	
	date()
	
	# variables to adjust always come first in anova analyses
	if (is.null(formula)) {
		if (is.null(adj.name)) {
			formula <- paste('~', grp.name)
		} else {
			formula <- 	paste('~', paste(adj.name, collapse='+'), '+', grp.name)		
		}
	}
	
	for (measure in measures) {
		cat("Alpha diversity:", measure, "\n")
		xx <- x[, measure]
		if (model == 'lm') {
			cat('Linear model:\n')

			lm.obj <- lm(as.formula(paste('xx ', formula)), df, ...)
			prmatrix(summary(lm.obj)$coefficients)
			cat('\nANOVA:\n')
			print(anova(lm.obj))
			cat('\n')
			fitted.obj[[measure]] <- lm.obj
		}
		if (model == 'lme') {
			df$xx <- xx
			cat('Linear mixed effects model:\n')
			lm.obj <- lme(as.formula(paste('xx ', formula)), df, method='ML', ...)
			prmatrix(summary(lm.obj)$tTable)
			cat('\nANOVA:\n')
			print(anova(lm.obj))
			cat('\n')
			fitted.obj[[measure]] <- lm.obj
		}
		cat("\n")
	}
	sink()
	
	result$fitted.obj <- fitted.obj
	result$alpha.diversity <- x
	# Rev: 2016_12_25
	return(invisible(result))

}

# New: 2018_02_25
estimate_richness_ <- function (OTU,  measures = NULL) {
	# Modified over Phyloseq
	
	renamevec = c("Observed", "Chao1", "ACE", "Shannon", "Simpson", 
			"InvSimpson", "Fisher", 'Pielou')
	names(renamevec) <- c("S.obs", "S.chao1", "S.ACE", "shannon", 
			"simpson", "invsimpson", "fisher", 'Pielou')
	if (is.null(measures)) {
		measures = as.character(renamevec)
	}
	if (any(measures %in% names(renamevec))) {
		measures[measures %in% names(renamevec)] <- renamevec[names(renamevec) %in% 
						measures]
	}
	if (!any(measures %in% renamevec)) {
		stop("None of the `measures` you provided are supported. Try default `NULL` instead.")
	}
	outlist = vector("list")
	estimRmeas = c("Chao1", "Observed", "ACE")
	if (any(estimRmeas %in% measures)) {
		outlist <- c(outlist, list(t(data.frame(vegan::estimateR(OTU)))))
	}
	if ("Shannon" %in% measures) {
		outlist <- c(outlist, list(shannon = vegan::diversity(OTU, index = "shannon")))
	}
	if ("Simpson" %in% measures) {
		outlist <- c(outlist, list(simpson = vegan::diversity(OTU, index = "simpson")))
	}
	if ("InvSimpson" %in% measures) {
		outlist <- c(outlist, list(invsimpson = vegan::diversity(OTU, 
								index = "invsimpson")))
	}
	
	if ("Fisher" %in% measures) {
		fisher = tryCatch(vegan::fisher.alpha(OTU, se = TRUE), warning = function(w) {
					warning("estimate_richness: Warning in fisher.alpha(). See `?fisher.fit` or ?`fisher.alpha`. Treat fisher results with caution")
					suppressWarnings(vegan::fisher.alpha(OTU, se = TRUE)[, c("alpha", "se")])
				})
		if (!is.null(dim(fisher))) {
			colnames(fisher)[1:2] <- c("Fisher", "se.fisher")
			outlist <- c(outlist, list(fisher))
		}
		else {
			outlist <- c(outlist, Fisher = list(fisher))
		}
	}
	
	f <- function(ns) {
		sapply(ns, function (n) {
					
					i <- 1:n
					-sum(1 / i * log (1 / i))
				})
	}
	
	cat(names(outlist))
	if ("Pielou" %in% measures) {
		outlist <- c(outlist, list(Pielou = vegan::diversity(OTU, index = "shannon") / f(rowSums(OTU!=0))))
	}
	
	
	out = do.call("cbind", outlist)
	namechange = intersect(colnames(out), names(renamevec))
	colnames(out)[colnames(out) %in% namechange] <- renamevec[namechange]
	colkeep = sapply(paste0("(se\\.){0,}", measures), grep, colnames(out), 
			ignore.case = TRUE)
	out = out[, sort(unique(unlist(colkeep))), drop = FALSE]
	out <- as.data.frame(out)
	return(out)
}

# New: 2018_02_25
generate_alpha_diversity <- function (data.obj,  rarefy=TRUE, depth=NULL, iter.no=5,
		measures=c('Observed', 'Chao1', 'Shannon', 'InvSimpson'), seed=123) {	
	# Rev: 2017_08_23

	OTU <- t(data.obj$otu.tab)
	depths <- rowSums(OTU)
	result <- list()
	if (rarefy == TRUE) {
		if (is.null(depth)) {
			depth <- min(depths)
		} else {
			if (depth > min(depths)) {
				ind <- depths >= depth
				cat(sum(!ind), " samples do not have sufficient number of reads!\n")
				# data.obj <- subset_data(data.obj, ind)
			}
		}

		set.seed(seed)
		x <- 0 
		for (i in 1:iter.no) {
			OTU2 <- Rarefy(OTU, depth = depth)$otu.tab.rff
			x <- x + estimate_richness_(OTU2, measures=measures)
		}
		x <- x / iter.no
		rownames(x) <- rownames(OTU2)
	} else {
		x <- estimate_richness_(OTU, measures=measures)
		rownames(x) <- rownames(OTU)
	}
	
	return(x)
}
	

# Rev: 2016_09_10
# Rev: 2016_11_28
# Rev: 2017_04_18
# Rev: 2018_03_06 position_jitter(h=0)
generate_alpha_boxplot <- function (data.obj, phylo.obj=NULL, rarefy=TRUE, depth=NULL, grp.name, strata=NULL, 
		measures=c('Observed', 'Chao1', 'Shannon', 'InvSimpson'), gg.cmd=NULL, ann='', subject=NULL, p.size=2.5, l.size=0.5,
		hei = NULL, wid = NULL) {	
	# Rev: 2017_08_23
	if (is.null(phylo.obj)) {
		phylo.obj <- phyloseq(otu_table(data.obj$otu.tab, taxa_are_rows=T), phy_tree(data.obj$tree), 
				tax_table(data.obj$otu.name), sample_data(data.obj$meta.dat))
	}
	# To be completed - jetter when strata is not null
	if (rarefy == TRUE) {
		if (is.null(depth)) {
			depth <- min(sample_sums(phylo.obj))
		} else {
			if (depth > min(sample_sums(phylo.obj))) {
				ind <- (sample_sums(phylo.obj) >= depth)
				cat(sum(!ind), " samples do not have sufficient number of reads!\n")
				
				sample_data(phylo.obj) <- sample_data(phylo.obj)[ind, ] 
				data.obj <- subset_data(data.obj, ind)
			}
		}

		phylo.even <- rarefy_even_depth(phylo.obj, depth, rngseed=12345)
		x <- estimate_richness(phylo.even, measures=measures)
	} else {
		x <- estimate_richness(phylo.obj, measures=measures)
	}
	
	df <- data.obj$meta.dat
	grp <- df[, grp.name]
	if (!is.null(subject)) {
		ID <- df[, subject]
	}
	
	if (is.null(hei) | is.null(wid))  {
		hei <- 5
		if (is.null(strata)) {
			wid <- 5
		} else {
			wid <- 5.5
		}
	}

	if (rarefy == T) {
		pdf(paste0('Alpha_diversity_boxplot_rarefied_', ann, '.pdf'), height=hei, width=wid)
	} else {
		pdf(paste0('Alpha_diversity_boxplot_unrarefied_', ann, '.pdf'), height=hei, width=wid)
	}
	if (is.null(subject)) {
		if (is.null(strata)) {
			for (measure in measures) {
				cat(measure, '\n')
				xx <- x[, measure]		
				df2 <- data.frame(Value=xx, Group=grp)
				dodge <- position_dodge(width=0.75)
				obj <- ggplot(df2, aes(x=Group, y=Value, col=Group)) +
						geom_boxplot(position=dodge,  outlier.colour = NA) + 
						geom_jitter(alpha=0.6, size=3.0,  position = position_jitter(w = 0.1, h = 0)) +
						labs(y=measure) +
						theme(legend.position="none")
				if (!is.null(gg.cmd)) {
					obj <- obj + eval(parse(text=gg.cmd))
				}
				
				print(obj)
			}	
		} else {
			for (measure in measures) {
				cat(measure, '\n')
				xx <- x[, measure]		
				grp2 <- df[, strata]
				df2 <- data.frame(Value=xx, Group=grp, Strata=grp2)
				
				dodge <- position_dodge(width=0.9)
				obj <- ggplot(df2, aes(x=Strata, y=Value, col=Group, fill=Group)) +
						geom_jitter(alpha=0.6, size=3.0,  position = position_jitterdodge(dodge.width=0.9)) +
						geom_boxplot(position=dodge,  outlier.colour = NA, fill='white', alpha=0.6) + 
						labs(y=measure, x=strata) 
				if (!is.null(gg.cmd)) {
					obj <- obj + eval(parse(text=gg.cmd))
				}
				print(obj)
			}
			
		}
		dev.off()
	} else {
		if (is.null(strata)) {
			for (measure in measures) {
				cat(measure, '\n')
				xx <- x[, measure]		
				df2 <- data.frame(Value=xx, Group=grp, subject=ID)
				dodge <- position_dodge(width=0.75)
			
				obj <- ggplot(df2, aes(x=Group, y=Value, shape=Group,  group=subject)) +
						geom_point(size=p.size) +
						geom_line(size=l.size) +
						labs(y=measure) +
						theme(legend.position="none")
				if (!is.null(gg.cmd)) {
					obj <- obj + eval(parse(text=gg.cmd))
				}
				
				print(obj)
			}	
		} else {
			warning('Stratum is disallowed when subject is specified!\n')
		}
		dev.off()
	}

}

# Rev: 2018_03_09 Removing phyloseq dependency and add 'subject' parameter, and remove 'model' parameter 

generate_rarefy_curve2 <- function (data.obj,  grp.name, 
		measures=c('Observed', 'Chao1', 'Shannon', 'InvSimpson'), depth=NULL,  iter.no=5, npoint=10, seed=123,
		ann='', gg.cmd="theme(legend.justification=c(1,0), legend.position=c(1,0))", wid=5, hei=5, error = 'se') {
	
	cat("Create rarefaction curves!\n")

	if (is.null(depth)) {
		depth <- min(colSums(data.obj$otu.tab))
	}
	
	if (error == 'se') k <- 1
	if (error == 'ci') k <- 1.96
	
	ind <- colSums(data.obj$otu.tab) >= depth
	if (sum(!ind) != 0) {
		cat(sum(!ind), " samples do not have sufficient number of reads!\n")
		data.obj <- subset_data(data.obj, ind)
	}
	
	df <- data.obj$meta.dat
	grp <- df[, grp.name]

	if (is.character(grp)) {
		grp <- factor(grp)
	}
	
	if (!is.factor(grp)) {
		stop('Rarefaction curve needs a factor!\n')
	}
	res <- NULL
	incr <- depth %/% npoint

	for (dep in c(10, incr*(1:npoint))) {
		x <- generate_alpha_diversity(data.obj,  rarefy=TRUE, depth=dep, iter.no=iter.no, measures=measures, seed=seed)
		res <- rbind(res, t(x[, measures, drop=F]))
	}
	colnames(res) <- rownames(df)

	cat('Wait ...\n')
	pdf(paste0("Alpha_diversity_Rarefaction_Curve_", ann, ".pdf"), width=wid, height=hei)
	for (i in 1:length(measures)) {
		measure <- measures[i]
		cat("Measure: ", measure, "\n")
		res2 <- res[(0:(npoint))*length(measures)+i, , drop=F]
		m <- t(apply(res2, 1, function(x) tapply(x, grp, mean)))
		se <- t(apply(res2, 1, function(x) tapply(x, grp, function(y) k * sd(y) / sqrt(length(y)))))
		uci <- m+se
		lci <- m-se
		
		m <- melt(m)
		uci <- melt(uci)
		lci <- melt(lci)
		
		res2 <- cbind(c(10, incr*(1:npoint)), m[, 2:3], uci[, 3], lci[, 3])
		colnames(res2) <- c('Depth', 'Group', 'mean', 'max', 'min')
		
		res2 <- as.data.frame(res2)
		res2$Group <- factor(res2$Group, levels=levels(grp))
		
		#write.table(res2, paste0("Alpha_diversity_Rarefaction_", ann, "_", measure, ".txt"))
		
		obj <- ggplot(res2, aes(x=Depth, y=mean, color=Group, group=Group)) +
				geom_errorbar(aes(ymin=min, ymax=max), alpha=0.5, width=.25, position=position_dodge(.2)) + 
				geom_line() + 
				geom_point(size=3, shape=21, fill="white") +
				labs(y=measure)
		
		if (!is.null(gg.cmd)) {
			obj <- obj + eval(parse(text=gg.cmd))
		}
		
		print(obj)		
	}
	dev.off()
	cat('Finished!\n')
}

# New: 2018_03_09 Removing phyloseq dependency and add 'subject' parameter, and remove 'model' parameter 
perform_alpha_test2 <- function (data.obj, alpha.obj=NULL, rarefy=TRUE, depth=NULL, iter.no=5, 
		measures=c('Observed', 'Chao1', 'Shannon', 'InvSimpson'),  model='lm', 
		formula=NULL, grp.name=NULL, adj.name=NULL, subject=NULL, ann='', seed=123, ...) {
	if (is.null(alpha.obj)) {
		alpha.obj <- generate_alpha_diversity(data.obj,  rarefy=rarefy, depth=depth, iter.no=iter.no, measures=measures, seed=seed)
		
	} else {
		if (sum(!(rownames(alpha.obj) %in% rownames(data.obj$meta.dat))) != 0){
			stop("alpha.obj contains samples not in data.obj!\n")
		} 
	}
	
	
	x <- alpha.obj
	df <- data.obj$meta.dat[rownames(alpha.obj), ]
	
	if (is.null(subject)) {
		model <- 'lm'
	} else {
		model <- 'lme'
	}
	
	result <- list()
	fitted.obj <- list()
	
	if (rarefy == T) {
		sink(paste0('Alpha_diversity_test_results_rarefied_', ann, '.txt'))
	} else {
		sink(paste0('Alpha_diversity_test_results_unrarefied_', ann, '.txt'))
	}
	
	date()
	
	# variables to adjust always come first in anova analyses
	if (is.null(formula)) {
		if (is.null(adj.name)) {
			formula <- paste('~', grp.name)
		} else {
			formula <- 	paste('~', paste(adj.name, collapse='+'), '+', grp.name)		
		}
	}
	
	for (measure in measures) {
		cat("Alpha diversity:", measure, "\n")
		xx <- x[, measure]
		if (model == 'lm') {
			cat('Linear model:\n')
			
			lm.obj <- lm(as.formula(paste('xx ', formula)), df, ...)
			prmatrix(summary(lm.obj)$coefficients)
			cat('\nANOVA:\n')
			print(anova(lm.obj))
			cat('\n')
			fitted.obj[[measure]] <- lm.obj
		}
		if (model == 'lme') {
			df$xx <- xx
			cat('Linear mixed effects model:\n')
			lm.obj <- lme(as.formula(paste('xx ', formula)), df, method='ML', random=as.formula(paste0(' ~ 1 | ', subject)), ...)
			prmatrix(summary(lm.obj)$tTable)
			cat('\nANOVA:\n')
			print(anova(lm.obj))
			cat('\n')
			fitted.obj[[measure]] <- lm.obj
		}
		cat("\n")
	}
	sink()
	
	result$fitted.obj <- fitted.obj
	result$alpha.diversity <- x
	# Rev: 2016_12_25
	return(invisible(result))
	
}

# New: 2018_03_09 Removing phyloseq dependency
generate_alpha_boxplot2 <- function (data.obj, alpha.obj=NULL,
		rarefy=TRUE, depth=NULL, iter.no=5, measures=c('Observed', 'Chao1', 'Shannon', 'InvSimpson'),  seed  = 123, 
		grp.name, strata=NULL, gg.cmd=NULL, ann='', subject=NULL, p.size=2.5, l.size=0.5,
		hei = NULL, wid = NULL) {	
	# Rev: 2017_08_23
	if (is.null(alpha.obj)) {
		alpha.obj <- generate_alpha_diversity(data.obj,  rarefy=rarefy, depth=depth, iter.no=iter.no, measures=measures, seed=seed)

	} else {
		if (sum(!(rownames(alpha.obj) %in% rownames(data.obj$meta.dat))) != 0){
			stop("alpha.obj contains samples not in data.obj!\n")
		} 
	}

	x <- alpha.obj
    df <- data.obj$meta.dat[rownames(alpha.obj), ]
	grp <- df[, grp.name]
	if (!is.null(subject)) {
		ID <- df[, subject]
	}
	
	if (is.null(hei) | is.null(wid))  {
		hei <- 5
		if (is.null(strata)) {
			wid <- 5
		} else {
			wid <- 5.5
		}
	}
	
	if (rarefy == T) {
		pdf(paste0('Alpha_diversity_boxplot_rarefied_', ann, '.pdf'), height=hei, width=wid)
	} else {
		pdf(paste0('Alpha_diversity_boxplot_unrarefied_', ann, '.pdf'), height=hei, width=wid)
	}
	if (is.null(subject)) {
		if (is.null(strata)) {
			for (measure in measures) {
				cat(measure, '\n')
				xx <- x[, measure]		
				df2 <- data.frame(Value=xx, Group=grp)
				dodge <- position_dodge(width=0.75)
				obj <- ggplot(df2, aes(x=Group, y=Value, col=Group)) +
						geom_boxplot(position=dodge,  outlier.colour = NA, lwd=0.35) + 
						geom_jitter(alpha=0.6, size=p.size,  position = position_jitter(w = 0.1, h = 0)) +
						labs(y=measure) +
						theme(legend.position="none")
				if (!is.null(gg.cmd)) {
					obj <- obj + eval(parse(text=gg.cmd))
				}
				
				print(obj)
			}	
		} else {
			for (measure in measures) {
				cat(measure, '\n')
				xx <- x[, measure]		
				grp2 <- df[, strata]
				df2 <- data.frame(Value=xx, Group=grp, Strata=grp2)
				
				dodge <- position_dodge(width=0.75)
				obj <- ggplot(df2, aes(x=Strata, y=Value, col=Group, fill=Group)) +
						geom_boxplot(position=dodge,  outlier.colour = NA, fill='white', alpha=0.65, lwd=0.35, width=0.65) + 
						geom_point(position=position_jitterdodge(dodge.width=0.75), size=p.size, alpha=0.6) +
						labs(y=measure, x=strata) 
				if (!is.null(gg.cmd)) {
					obj <- obj + eval(parse(text=gg.cmd))
				}
				print(obj)
				
				
			}
			
		}
		dev.off()
	} else {
		if (is.null(strata)) {
			for (measure in measures) {
				cat(measure, '\n')
				xx <- x[, measure]		
				df2 <- data.frame(Value=xx, Group=grp, subject=ID)
				dodge <- position_dodge(width=0.75)
				
				obj <- ggplot(df2, aes(x=Group, y=Value, shape=Group,  group=subject)) +
						geom_point(size=p.size) +
						geom_line(size=l.size) +
						labs(y=measure) +
						theme(legend.position="none")
				if (!is.null(gg.cmd)) {
					obj <- obj + eval(parse(text=gg.cmd))
				}
				
				print(obj)
			}	
		} else {
			warning('Stratum is disallowed when subject is specified!\n')
		}
		dev.off()
	}
	
}

# New: 2018_03_08  Removing phyloseq dependency
# Rev: 2018_07_16  More advanced strata support
generate_alpha_scatterplot2 <- function (data.obj, alpha.obj=NULL, grp.name, subject=NULL,
		rarefy=TRUE, depth=NULL, iter.no=5, seed  = 123,  measures=c('Observed', 'Chao1', 'Shannon', 'InvSimpson'), 
		strata=NULL, strata2=NULL, combine.strata=FALSE, combine.strata2=FALSE, smooth.method='loess', 
		pt.shape=16, pt.alpha=0.5, pt.size=2, subject.pt=FALSE,
		gg.cmd=NULL, ann='', hei=NULL, wid=NULL, pdf=TRUE) {	

	if (is.null(alpha.obj)) {
		alpha.obj <- generate_alpha_diversity(data.obj,  rarefy=rarefy, depth=depth, iter.no=iter.no, measures=measures, seed=seed)
		
	} else {
		if (sum(!(rownames(alpha.obj) %in% rownames(data.obj$meta.dat))) != 0){
			stop("alpha.obj contains samples not in data.obj!\n")
		} 
	}
	
	x <- alpha.obj
	df <- data.obj$meta.dat[rownames(alpha.obj), ]
	grp <- df[, grp.name]
	
	if(is.null(subject)) {
		ID <- NA
	} else {
		ID <- factor(df[, subject])
	}
	
	
	if (is.null(hei) | is.null(wid)) {
		hei <- 5
		wid <- 6
		
		if (!is.null(strata) & combine.strata == FALSE) {
			wid <- 4 * nlevels(factor(df[, strata]))
		} 
		if (!is.null(strata2) & combine.strata2 == FALSE) {
			hei <- 2.5 * nlevels(factor(df[, strata2]))
		} 
	}
	
	if (pdf == TRUE) {
		if (rarefy == T) {
			pdf(paste0('Alpha_diversity_scatterplot_rarefied_', ann, '.pdf'), height=hei, width=wid)
		} else {
			pdf(paste0('Alpha_diversity_scatterplot_unrarefied_', ann, '.pdf'), height=hei, width=wid)
		}
	}

	
	if (is.null(strata)) {
		for (measure in measures) {
			cat(measure, '\n')
			xx <- x[, measure]		
			df2 <- data.frame(Value=xx, Group=grp, ID=ID)
			obj <- ggplot(df2, aes(x=Group, y=Value, group=ID)) +
#					geom_point(size=pt.size, shape=pt.shape, alpha=pt.alpha) +
					geom_smooth(method=smooth.method, aes(group=NA), size=0.75) +
					labs(y='Value', x=grp.name, title=measure) +
					theme(legend.position="none")

			if (!is.null(subject)) {
				if (subject.pt == FALSE) {
					obj <- obj + geom_line(size=0.25, alpha=0.75) 
				}  else {
					obj <- obj + geom_line(size=0.25, alpha=0.75) + geom_point(size=pt.size, shape=pt.shape, alpha=pt.alpha) 
				}
				
			} else {
				obj <- obj + geom_point(size=pt.size, shape=pt.shape, alpha=pt.alpha) 
			}
			if (!is.null(gg.cmd)) {
				obj <- obj + eval(parse(text=gg.cmd))
			}
			print(obj)
		}	
	} else {
		for (measure in measures) {
			cat(measure, '\n')
	
			xx <- x[, measure]
			grp2 <- factor(df[, strata])
			if (!is.null(strata2)) {
				grp3 <- factor(df[, strata2])
			} else {
				grp3 <- grp2
			}
			grp4 <- factor(paste(grp2, grp3))
			
			# VERY bad names with only difference in capital letters, variable names are also confusing
			# Rev: 2018_07_16 
			
			df2 <- data.frame(Value=xx, Group=grp, Strata=grp2, Strata2=grp3, Strata3=grp4, ID=ID)
				
			if (is.null(strata2)) {
				if (combine.strata == TRUE) {
					obj <- ggplot(df2, aes(x=Group, y=Value, group=ID, col=Strata)) +
#							geom_point(size=pt.size, shape=pt.shape, alpha=pt.alpha) +
							geom_smooth(method=smooth.method, aes(group=Strata), size=0.75) +
							labs(y='Value', x=grp.name, title=measure) 
				} else {
					obj <- ggplot(df2, aes(x=Group, y=Value, group=ID)) +
#							geom_point(size=pt.size, shape=pt.shape, alpha=pt.alpha) +
							geom_smooth(method=smooth.method, aes(group=NA), size=0.75) +
							labs(y='Value', x=grp.name, title=measure) + 
							facet_grid(. ~ Strata)
				}
				
			} else {
				if (combine.strata == TRUE) {
					if (combine.strata2 == TRUE) {
						obj <- ggplot(df2, aes(x=Group, y=Value, group=ID, col=Strata3)) +
#								geom_point(size=pt.size, shape=pt.shape, alpha=pt.alpha) +
								geom_smooth(method=smooth.method, aes(group=Strata3), size=0.75) +
								labs(y='Value', x=grp.name, title=measure) 	
					} else {
						obj <- ggplot(df2, aes(x=Group, y=Value, group=ID, col=Strata)) +
#								geom_point(size=pt.size, shape=pt.shape, alpha=pt.alpha) +
								geom_smooth(method=smooth.method, aes(group=Strata), size=0.75) +
								labs(y='Value', x=grp.name, title=measure) + 
								facet_grid(Strata2 ~ .)	
					}
				} else {
					if (combine.strata2 == TRUE) {
						warning('Currently, combine.strata2 will be forced to be FALSE if combine.strata=FALSE!\n')
					}
					obj <- ggplot(df2, aes(x=Group, y=Value, group=ID)) +
#							geom_point(size=pt.size, shape=pt.shape, alpha=pt.alpha) +
							geom_smooth(method=smooth.method, aes(group=NA), size=0.75) +
							labs(y='Value', x=grp.name, title=measure) + 
							facet_grid(Strata2 ~ Strata)
				}
				
			}		
			
			obj <- obj + theme(legend.title=element_blank())	
		
			if (!is.null(subject)) {
				if (subject.pt == FALSE) {
					obj <- obj + geom_line(size=0.25, alpha=0.75) 
				}  else {
					obj <- obj + geom_line(size=0.25, alpha=0.75) + geom_point(size=pt.size, shape=pt.shape, alpha=pt.alpha) 
				}
				
			} else {
				obj <- obj + geom_point(size=pt.size, shape=pt.shape, alpha=pt.alpha) 
			}
			
			if (!is.null(gg.cmd)) {
				obj <- obj + eval(parse(text=gg.cmd))
			}
			print(obj)
		}
		
	}
	if(pdf == TRUE) {
		dev.off()
	}
	
	
}


# New: 2017_02_22 
# Depend on phyloseq - outdated. Please see the newer version generate_alpha_scatterplot2
generate_alpha_scatterplot <- function (data.obj, phylo.obj=NULL, rarefy=TRUE, depth=NULL, grp.name, 
		strata=NULL, strata2=NULL, wrap.nrow=2, smooth.method='auto', hei0=NULL, wid0=NULL,
		measures=c('Observed', 'Chao1', 'Shannon', 'InvSimpson'), gg.cmd=NULL, ann='') {	
	
	# Rev: 2017_08_23
	if (is.null(phylo.obj)) {
		phylo.obj <- phyloseq(otu_table(data.obj$otu.tab, taxa_are_rows=T), phy_tree(data.obj$tree), 
				tax_table(data.obj$otu.name), sample_data(data.obj$meta.dat))
	}
	
	if (rarefy == TRUE) {
		if (is.null(depth)) {
			depth <- min(sample_sums(phylo.obj))
		} else {
			if (depth > min(sample_sums(phylo.obj))) {
				ind <- (sample_sums(phylo.obj) >= depth)
				cat(sum(!ind), " samples do not have sufficient number of reads!\n")
				
				sample_data(phylo.obj) <- sample_data(phylo.obj)[ind, ] 
				data.obj <- subset_data(data.obj, ind)
			}
		}
		
		phylo.even <- rarefy_even_depth(phylo.obj, depth, rngseed=12345)
		x <- estimate_richness(phylo.even, measures=measures)
	} else {
		x <- estimate_richness(phylo.obj, measures=measures)
	}
	
	df <- data.obj$meta.dat
	grp <- df[, grp.name]

	if (is.null(hei0)) {
		hei <- 5
	} else {
		hei <- hei0
	}
	
	if (is.null(strata)) {
		if (is.null(wid0)) {
			wid <- 5
		} else {
			wid <- wid0
		}
		
	} else {
		if (is.null(wid0)) {
			wid <- 5.5
		} else {
			wid <- wid0
		}
	}
	
	if (rarefy == T) {
		pdf(paste0('Alpha_diversity_scatterplot_rarefied_', ann, '.pdf'), height=hei, width=wid)
	} else {
		pdf(paste0('Alpha_diversity_scatterplot_unrarefied_', ann, '.pdf'), height=hei, width=wid)
	}
	
	if (is.null(strata)) {
		for (measure in measures) {
			cat(measure, '\n')
			xx <- x[, measure]		
			df2 <- data.frame(Value=xx, Group=grp)
			obj <- ggplot(df2, aes(x=Group, y=Value)) +
					geom_point() +
					geom_smooth(method=smooth.method) +
					labs(y='Value', x=grp.name, title=measure) +
					theme(legend.position="none")
			if (!is.null(gg.cmd)) {
				obj <- obj + eval(parse(text=gg.cmd))
			}
			print(obj)
		}	
	} else {
		for (measure in measures) {
			cat(measure, '\n')
			
			xx <- x[, measure]		
			grp2 <- df[, strata]
			if (!is.null(strata2)) {
				grp3 <- df[, strata2]
			} else {
				grp3 <- grp2
			}
			
			df2 <- data.frame(Value=xx, Group=grp, Strata=grp2, Strata2=grp3)
			if (is.null(strata2)) {
				obj <- ggplot(df2, aes(x=Group, y=Value)) +
						geom_point() +
						geom_smooth(method=smooth.method) +
						labs(y='Value', x=grp.name, title=measure) + 
						facet_wrap(~ Strata, nrow=wrap.nrow)
			} else {
				obj <- ggplot(df2, aes(x=Group, y=Value)) +
						geom_point() +
						geom_smooth(method=smooth.method) +
						labs(y='Value', x=grp.name, title=measure) + 
						facet_grid(Strata2 ~ Strata)
			}		
			obj <- obj + theme(legend.title=element_blank())			
			if (!is.null(gg.cmd)) {
				obj <- obj + eval(parse(text=gg.cmd))
			}
			print(obj)
		}
		
	}
	dev.off()
	
}

#perform_alpha_test_otu <- function (data.obj, formula, grp.name, ...) {
#	# Assume two groups
#	df <- data.obj$meta.dat
#	grp <- df[, grp.name]
#	dep <- colSums(data.obj$otu.tab)
#	obs <- colSums(data.obj$otu.tab !=0)
#	obj <- lm(as.formula(paste('log(obs)', formula, '+ log(dep)')), df, ...)
#	sink('Alpha_diversity_test_results_observed_OTU.txt')
#	date()
#	cat('Linear model correcting for differential sequencing depth:\n')
#	prmatrix(summary(obj)$coefficients)
#	sink()
#	
#	pdf("Alpha_diversity_test_results_observed_OTU.pdf")
#	plot(dep, obs, log='xy', xlab="Sequencing Depth", ylab="Observed OTU Number", 
#			bg=c('blue', 'red')[grp], pch=21)
#	grp.levels <- levels(grp)
#	abline(lm(obs[grp==grp.levels[1]] ~ dep[grp==grp.levels[1]]), col='red')
#	abline(lm(obs[grp==grp.levels[2]] ~ dep[grp==grp.levels[2]]), col='blue')
#	legend('left', levels(grp), fill=c('blue', 'red'))
#	dev.off()
#}


# Rev: 2017_02_13 Individual label
# Rev: 2017_05_06 Add p value 
generate_ordination <- function (data.obj, dist.obj, dist.names=c('UniFrac', 'GUniFrac', 'WUniFrac', 'BC'), 
		grp.name, adj.name=NULL, emp.lev=NULL, indiv.lab=FALSE, indiv.lab.cex=0.5, is.lightcolor=TRUE,
		strata=NULL,  pc.separate, pca.method='cmd', ann=NULL, sub=NULL,
		clab=1.0, cex.pt=1.25, ellipse=T, cstar= 1, wid=5, hei=5, pdf=TRUE, is.pvalue=FALSE, ...) {
	# Implment strata
	# To be completed, add continuous case
	strata0 <- strata
	
	if (pdf) {
		if (is.null(ann)) {
			pdf(paste0('Beta_diversity_ordination_', pca.method, '_', grp.name, '.pdf'), width=wid, height=hei)
		} else {
			pdf(paste0('Beta_diversity_ordination_', pca.method, '_', ann, '.pdf'), width=wid, height=hei)
		}
	}

	df <- data.obj$meta.dat
	grp <- factor(df[, grp.name])
	
	if (!is.null(emp.lev)) {
		grp <- factor(grp, levels=c(setdiff(levels(grp), emp.lev), emp.lev))
	}
	
	if (!is.null(strata)) {
		strata <- factor(df[, strata])
	} else {
		strata <- factor(grp)
	}
	
	# To be revised
	darkcols <- hue_pal(l=40)(nlevels(grp))
	if (is.lightcolor) {
		lightcols <- hue_pal(c=45, l=80)(nlevels(grp))
	} else {
		lightcols <- darkcols
	}
	
	pchs <- rep(c(21, 22, 23, 24, 25), ceiling(nlevels(strata) / 5))[1:nlevels(strata)]
	
	for (dist.name in dist.names) {
		dist.temp <- dist.obj[[dist.name]]
		if (!is.null(adj.name)) {
			adj <- as.data.frame(df[, adj.name])
			obj <- cmdscale(as.dist(dist.temp), k=ncol(dist.temp)-1)
			dat2 <- apply(obj, 2, function(x) resid(lm(x ~ ., data=adj)))
			dist.temp <- dist(dat2)
		} 
		if (pca.method == 'cmd') {
			obj <- cmdscale(as.dist(dist.temp), k=2, eig=T)
			pve <- round(obj$eig[1:2]/sum(abs(obj$eig))*100, 1)
			y <- cbind(obj$points[, 1], obj$points[, 2])
			
			xlab <- paste0('PC1(', pve[1], '%)')
			ylab <- paste0('PC2(', pve[2], '%)')
		} 

		if (pca.method == 'nmds') {
				obj <- metaMDS(as.dist(dist.temp), k=2)
				y <- cbind(obj$points[, 1], obj$points[, 2])
				xlab <- 'NMDS1'
                ylab <- 'NMDS2'
		} 
		
		if (pca.method == 'pls') {
			require(mixOmics)
			# Test
			obj <- cmdscale(as.dist(dist.temp), k=ncol(dist.temp)-1)
			obj <- plsda(obj, grp, ncomp=2)
			y <- cbind(obj$variates$X[, 1], obj$variates$X[, 2])
			xlab <- 'PLS1'
			ylab <- 'PLS2'
		}
		
		if (is.pvalue == TRUE & nlevels(factor(grp)) > 1) {
			pvalue <- paste0('(P=', adonis(as.dist(dist.temp) ~ grp)$aov.tab[1, 6], ')')
		} else {
			pvalue <- ''
		}
		
		colnames(y) <- c("PC1", "PC2")		
		xlim <- c(-max(range(abs(y[, 1]))) * 1.25, max(range(abs(y[, 1]))) * 1.25)
		ylim <- c(-max(range(abs(y[, 2]))) * 1.25, max(range(abs(y[, 2]))) * 1.25)
		plot(y[, 1], y[, 2], type='n', xlim=xlim, ylim=ylim, 
				xlab=xlab, ylab=ylab)
#		points(y[, 1], y[, 2], bg='yellow', col=darkcols[grp], 
#				type='p', pch = pchs[grp], cex=cex.pt)
		col1 <- lightcols[1:nlevels(grp)]
		col2 <- darkcols[1:nlevels(grp)]
		col3 <- darkcols[grp]
		if (!is.null(emp.lev)) {
			
			col1 <- col2
			col1[which(levels(grp) != emp.lev)] <- rgb(0.5, 0.5, 0.5, 0.5)
			col1[which(levels(grp) == emp.lev)] <- rgb(1.0, 0, 0, 1.0)
			col2[which(levels(grp) != emp.lev)] <- rgb(0.5, 0.5, 0.5, 0.5)
			col2[which(levels(grp) == emp.lev)] <- rgb(1.0, 0, 0, 1.0)
            col3[grp !=  emp.lev] <- rgb(0.5, 0.5, 0.5, 0.5)
			col3[grp ==  emp.lev] <- rgb(1.0, 0, 0, 1.0)

		}
		if (ellipse == T) {
			s.class(y, 
					fac = grp,
					cstar = cstar,
					clab = 0,
					cpoint = 0,
					axesell = F,
					col = col1,
					grid = TRUE,
					add.plot=T,
					...
			)
		}
		
		points(y[, 1], y[, 2], bg=col3, col='black',
				type='p', pch = pchs[strata], cex=cex.pt)
		if (indiv.lab) {
			if (is.null(emp.lev)) {
				lab.temp <- rownames(dist.temp)
				text(y[, 1], y[, 2], labels=lab.temp, cex=indiv.lab.cex, col=rgb(1, 0, 0, 0.75))
			} else {
				lab.temp <- rownames(dist.temp)
				lab.temp[grp !=  emp.lev] <- ''
				text(y[, 1], y[, 2], labels=lab.temp, cex=indiv.lab.cex, col=rgb(1, 0, 0, 0.75))
			}
	
		}
		s.class(y, 
				fac = grp,
				cstar =0,
				cellipse = 0,
				clab = clab,
				cpoint = 0,
				axesell = F,
				col = col2,
				grid = TRUE,
				add.plot=T
		)
		if (!is.null(strata0)) {
			legend('topright', legend=(levels(strata)), pch=pchs[1:nlevels(strata)])	
		}

		title(main=paste(dist.name, "distance"), sub=paste0(sub, pvalue))
#		text(-0.25, 0.3, "PERMANOVA p=0.016")
	}
	
	if (pdf) {
		dev.off()
	}
}


# New: 2018_07_16  PCs trend
generate_PC_scatterplot <- function (data.obj, dist.obj=NULL, grp.name, adj.name=NULL, subject=NULL,
		dist.names=c('UniFrac', 'GUniFrac', 'WUniFrac', 'BC'), nPC=2, pca.method='cmd',
		strata=NULL, strata2=NULL, combine.strata=FALSE, combine.strata2=FALSE, smooth.method='loess', 
		pt.shape=16, pt.alpha=0.5, pt.size=2, subject.pt = FALSE,
		ann='', hei=NULL, wid=NULL, pdf=TRUE, gg.cmd=NULL) {	
	
	df <- data.obj$meta.dat
	grp <- df[, grp.name]
	
	if(is.null(subject)) {
		ID <- NA
	} else {
		ID <- factor(df[, subject])
	}
	
	if (is.null(hei) | is.null(wid)) {
		hei <- 5
		wid <- 6
		
		if (!is.null(strata) & combine.strata == FALSE) {
			wid <- 4 * nlevels(factor(df[, strata]))
		} 
		if (!is.null(strata2) & combine.strata2 == FALSE) {
			hei <- 2.5 * nlevels(factor(df[, strata2]))
		} 
	}
	
	if (pdf == TRUE) {
		pdf(paste0('Beta_diversity_PC_scatterplot_', ann, '.pdf'), height=hei, width=wid)
	} 
	
	measures <- NULL
	x <- NULL
	for (dist.name in dist.names) {
		dist.temp <- dist.obj[[dist.name]]
		if (!is.null(adj.name)) {
			adj <- as.data.frame(df[, adj.name])
			obj <- cmdscale(as.dist(dist.temp), k=ncol(dist.temp)-1)
			dat2 <- apply(obj, 2, function(x) resid(lm(x ~ ., data=adj)))
			dist.temp <- dist(dat2)
		} 
		if (pca.method == 'cmd') {
			obj <- cmdscale(as.dist(dist.temp), k=nPC, eig=T)
			pve <- round(obj$eig[1:nPC]/sum(abs(obj$eig))*100, 1)
			x <- cbind(x, obj$points)
			measures <- c(measures, paste0(dist.name, ' - MDS PC', 1:nPC, '(', pve, '%)'))
		} 
		
		if (pca.method == 'nmds') {
			obj <- metaMDS(as.dist(dist.temp), k=nPC)
			x <- cbind(x, obj$points)
			measures <- c(measures, paste0(dist.name, ' - NMDS PC', 1:nPC))
		} 
	}
	colnames(x) <- measures
		

	if (is.null(strata)) {
		for (measure in measures) {
			cat(measure, '\n')
			xx <- x[, measure]		
			df2 <- data.frame(Value=xx, Group=grp, ID=ID)
			obj <- ggplot(df2, aes(x=Group, y=Value, group=ID)) +
					geom_smooth(method=smooth.method, aes(group=NA), size=0.75) +
					labs(y='Value', x=grp.name, title=measure) +
					theme(legend.position="none")
			if (!is.null(gg.cmd)) {
				obj <- obj + eval(parse(text=gg.cmd))
			}
			
			if (!is.null(subject)) {
				if (subject.pt == FALSE) {
					obj <- obj + geom_line(size=0.25, alpha=0.75) 
				}  else {
					obj <- obj + geom_line(size=0.25, alpha=0.75) + geom_point(size=pt.size, shape=pt.shape, alpha=pt.alpha) 
				}
				
			} else {
				obj <- obj + geom_point(size=pt.size, shape=pt.shape, alpha=pt.alpha) 
			}
			print(obj)
		}	
	} else {
		for (measure in measures) {
			cat(measure, '\n')
			
			xx <- x[, measure]
			grp2 <- factor(df[, strata])
			if (!is.null(strata2)) {
				grp3 <- factor(df[, strata2])
			} else {
				grp3 <- grp2
			}
			grp4 <- factor(paste(grp2, grp3))
			
			# VERY bad names with only difference in capital letters, variable names are also confusing
			# Rev: 2018_07_16 
			
			df2 <- data.frame(Value=xx, Group=grp, Strata=grp2, Strata2=grp3, Strata3=grp4, ID=ID)
			
			if (is.null(strata2)) {
				if (combine.strata == TRUE) {
					obj <- ggplot(df2, aes(x=Group, y=Value, group=ID, col=Strata)) +
					#		geom_point(size=pt.size, shape=pt.shape, alpha=pt.alpha) +
							geom_smooth(method=smooth.method, aes(group=Strata), size=0.75) +
							labs(y='Value', x=grp.name, title=measure) 
				} else {
					obj <- ggplot(df2, aes(x=Group, y=Value, group=ID)) +
					#		geom_point(size=pt.size, shape=pt.shape, alpha=pt.alpha) +
							geom_smooth(method=smooth.method,  aes(group=NA),  size=0.75) +
							labs(y='Value', x=grp.name, title=measure) + 
							facet_grid(. ~ Strata)
				}
				
			} else {
				if (combine.strata == TRUE) {
					if (combine.strata2 == TRUE) {
						obj <- ggplot(df2, aes(x=Group, y=Value, group=ID, col=Strata3)) +
					#			geom_point(size=pt.size, shape=pt.shape, alpha=pt.alpha) +
								geom_smooth(method=smooth.method, aes(group=Strata3), size=0.75) +
								labs(y='Value', x=grp.name, title=measure) 	
					} else {
						obj <- ggplot(df2, aes(x=Group, y=Value, group=ID, col=Strata)) +
					#			geom_point(size=pt.size, shape=pt.shape, alpha=pt.alpha) +
								geom_smooth(method=smooth.method, aes(group=Strata), size=0.75) +
								labs(y='Value', x=grp.name, title=measure) + 
								facet_grid(Strata2 ~ .)	
					}
				} else {
					if (combine.strata2 == TRUE) {
						warning('Currently, combine.strata2 will be forced to be FALSE if combine.strata=FALSE!\n')
					}
					obj <- ggplot(df2, aes(x=Group, y=Value, group=ID)) +
						#	geom_point(size=pt.size, shape=pt.shape, alpha=pt.alpha) +
							geom_smooth(method=smooth.method,  aes(group=NA), size=0.75) +
							labs(y='Value', x=grp.name, title=measure) + 
							facet_grid(Strata2 ~ Strata)
				}
				
			}		
			
			obj <- obj + theme(legend.title=element_blank())	
			
			if (!is.null(gg.cmd)) {
				obj <- obj + eval(parse(text=gg.cmd))
			}
			
			if (!is.null(subject)) {
				if (subject.pt == FALSE) {
					obj <- obj + geom_line(size=0.25, alpha=0.75) 
				}  else {
					obj <- obj + geom_line(size=0.25, alpha=0.75) + geom_point(size=pt.size, shape=pt.shape, alpha=pt.alpha) 
				}
			} else {
				obj <- obj + geom_point(size=pt.size, shape=pt.shape, alpha=pt.alpha) 
			}
			
			print(obj)
		}
		
	}
	if (pdf == TRUE) {
		dev.off()
	}
	
	
}


# New: 2018_07_16  grp.name codes the day
generate_ordination_trajectory <- function (data.obj, dist.obj=NULL, day.name=NULL, adj.name=NULL, subject=NULL,
		dist.names=c('UniFrac', 'GUniFrac', 'WUniFrac', 'BC'),  pca.method='cmd',
		strata=NULL, strata2=NULL, combine.strata=FALSE, combine.strata2=FALSE, smooth.method='auto', 
		pt.shape=16, pt.alpha=0.75, pt.size=2, subject.pt = TRUE,
		ann='', hei=NULL, wid=NULL, pdf=TRUE, gg.cmd=NULL) {	
	
	nPC <- 2
	df <- data.obj$meta.dat
	ind <- order(df[, day.name])
	
	df <- df[ind, ]
	dist.obj <- lapply(dist.obj, function (x) x[ind, ind])
	
	day <- df[, day.name]
	
	
	if(is.null(subject)) {
		ID <- NA
	} else {
		ID <- factor(df[, subject])
	}
	
	if (is.null(hei) | is.null(wid)) {
		hei <- 5
		wid <- 6
		
		if (!is.null(strata) & combine.strata == FALSE) {
			wid <- 4 * nlevels(factor(df[, strata]))
		} 
		if (!is.null(strata2) & combine.strata2 == FALSE) {
			hei <- 2.5 * nlevels(factor(df[, strata2]))
		} 
	}
	
	if (pdf == TRUE) {
		pdf(paste0('Beta_diversity_Subject_Trajectory_', ann, '.pdf'), height=hei, width=wid)
	} 
	
	x1.measures <- NULL
	x2.measures <- NULL
	x1 <- NULL
	x2 <- NULL
	for (dist.name in dist.names) {
		dist.temp <- dist.obj[[dist.name]]
		if (!is.null(adj.name)) {
			adj <- as.data.frame(df[, adj.name])
			obj <- cmdscale(as.dist(dist.temp), k=ncol(dist.temp)-1)
			dat2 <- apply(obj, 2, function(x) resid(lm(x ~ ., data=adj)))
			dist.temp <- dist(dat2)
		} 
		if (pca.method == 'cmd') {
			obj <- cmdscale(as.dist(dist.temp), k=nPC, eig=T)
			pve <- round(obj$eig[1:nPC]/sum(abs(obj$eig))*100, 1)
			x1 <- cbind(x1, obj$points[, 1])
			x2 <- cbind(x2, obj$points[, 2])
			x1.measures <- c(x1.measures, paste0('MDS PC', 1, '(', pve[1], '%)'))
			x2.measures <- c(x2.measures, paste0('MDS PC', 2, '(', pve[2], '%)'))
		} 
		
		if (pca.method == 'nmds') {
			obj <- metaMDS(as.dist(dist.temp), k=nPC)
			x1 <- cbind(x1, obj$points[, 1])
			x2 <- cbind(x2, obj$points[, 2])
			x1.measures <- c(x1.measures, paste0('MDS PC', 1))
			x2.measures <- c(x2.measures, paste0('MDS PC', 2))
		} 
	}
	colnames(x1) <- dist.names
	colnames(x2) <- dist.names
	names(x1.measures) <- dist.names
	names(x2.measures) <- dist.names
	measures <- dist.names
	
	
	if (is.null(strata)) {
		for (measure in measures) {
			cat(measure, '\n')
			xx1 <- x1[, measure]		
			xx2 <- x2[, measure]
			df2 <- data.frame(Day=factor(day), ID=ID, xx1=xx1, xx2=xx2)
			obj <- ggplot(df2, aes(x=xx1, y=xx2, group=ID, col=Day)) +
					#		geom_smooth(method=smooth.method, aes(group=NA), size=0.75) +
					labs(y=x2.measures[measure], x=x1.measures[measure], title=measure) 

			
			if (subject.pt == FALSE) {
				obj <- obj + geom_path(size=0.25, alpha=0.5, colour='black') 
			}  else {
				obj <- obj + geom_path(size=0.25, alpha=0.5, colour='black') + geom_point(size=pt.size, shape=pt.shape, alpha=pt.alpha) 
			}
			
			if (!is.null(gg.cmd)) {
				obj <- obj + eval(parse(text=gg.cmd))
			}
			
			obj <- obj + theme(legend.title=element_blank())	
			
			print(obj)
		}	
	} else {
		for (measure in measures) {
			cat(measure, '\n')
			
			xx1 <- x1[, measure]		
			xx2 <- x2[, measure]
			grp2 <- factor(df[, strata])
			if (!is.null(strata2)) {
				grp3 <- factor(df[, strata2])
			} else {
				grp3 <- grp2
			}
			grp4 <- factor(paste(grp2, grp3))
			
			# VERY bad names with only difference in capital letters, variable names are also confusing
			# Rev: 2018_07_16 
			
			df2 <- data.frame(xx1=xx1, xx2=xx2, Strata=grp2, Strata2=grp3, Strata3=grp4, ID=ID, Day=factor(day))
			
			if (is.null(strata2)) {
				if (combine.strata == TRUE) {
					obj <- ggplot(df2, aes(x=xx1, y=xx2, group=ID, col=Day, linetype=Strata)) +
							#		geom_point(size=pt.size, shape=pt.shape, alpha=pt.alpha) +
							#	geom_smooth(method=smooth.method, aes(group=Strata), size=0.75) +
							labs(y=x2.measures[measure], x=x1.measures[measure], title=measure)
					
					if (subject.pt == FALSE) {
						obj <- obj + geom_path(size=0.25, alpha=0.75, aes(col=Strata)) 
					}  else {
						obj <- obj + geom_path(size=0.25, alpha=0.75, aes(col=Strata)) + geom_point(size=pt.size, shape=pt.shape, alpha=pt.alpha) 
					}
					
				} else {
					obj <- ggplot(df2, aes(x=xx1, y=xx2, group=ID, col=Day)) +
							#		geom_point(size=pt.size, shape=pt.shape, alpha=pt.alpha) +
							# geom_smooth(method=smooth.method,  aes(group=NA),  size=0.75) +
							labs(y=x2.measures[measure], x=x1.measures[measure], title=measure) +
							facet_grid(. ~ Strata)
					if (subject.pt == FALSE) {
						obj <- obj + geom_path(size=0.25, alpha=0.5, col='black') 
					}  else {
						obj <- obj + geom_path(size=0.25, alpha=0.5, col='black') + geom_point(size=pt.size, shape=pt.shape, alpha=pt.alpha) 
					}
					
				}
				
			} else {
				if (combine.strata == TRUE) {
					if (combine.strata2 == TRUE) {
						obj <- ggplot(df2, aes(x=xx1, y=xx2, group=ID, col=Day, linetype=Strata3)) +
								#			geom_point(size=pt.size, shape=pt.shape, alpha=pt.alpha) +
								# geom_smooth(method=smooth.method, aes(group=Strata3), size=0.75) +
								labs(y=x2.measures[measure], x=x1.measures[measure], title=measure) 
						if (subject.pt == FALSE) {
							obj <- obj + geom_path(size=0.25, alpha=0.75, aes(col=Strata3)) 
						}  else {
							obj <- obj + geom_path(size=0.25, alpha=0.75, aes(col=Strata3)) + geom_point(size=pt.size, shape=pt.shape, alpha=pt.alpha) 
						}
					} else {
						obj <- ggplot(df2, aes(x=xx1, y=xx2, group=ID, col=Day, linetype=Strata)) +
								#			geom_point(size=pt.size, shape=pt.shape, alpha=pt.alpha) +
								# geom_smooth(method=smooth.method, aes(group=Strata), size=0.75) +
								labs(y=x2.measures[measure], x=x1.measures[measure], title=measure) +
								facet_grid(Strata2 ~ .)	
						if (subject.pt == FALSE) {
							obj <- obj + geom_path(size=0.25, alpha=0.75, aes(col=Strata)) 
						}  else {
							obj <- obj + geom_path(size=0.25, alpha=0.75, aes(col=Strata)) + geom_point(size=pt.size, shape=pt.shape, alpha=pt.alpha) 
						}
			
					}
				} else {
					if (combine.strata2 == TRUE) {
						warning('Currently, combine.strata2 will be forced to be FALSE if combine.strata=FALSE!\n')
					}
					obj <- ggplot(df2, aes(x=xx1, y=xx2, group=ID, col=Day)) +
							#	geom_point(size=pt.size, shape=pt.shape, alpha=pt.alpha) +
							#	geom_smooth(method=smooth.method,  aes(group=NA), size=0.75) +
							labs(y=x2.measures[measure], x=x1.measures[measure], title=measure) +
							facet_grid(Strata2 ~ Strata)
					if (subject.pt == FALSE) {
						obj <- obj + geom_path(size=0.25, alpha=0.5, colour='black') 
					}  else {
						obj <- obj + geom_path(size=0.25, alpha=0.5, colour='black') + geom_point(size=pt.size, shape=pt.shape, alpha=pt.alpha) 
					}
				}
				
			}		
			
			obj <- obj + theme(legend.title=element_blank())	
			
			if (!is.null(gg.cmd)) {
				obj <- obj + eval(parse(text=gg.cmd))
			}
			
			print(obj)
		}
		
	}
	if (pdf == TRUE) {
		dev.off()
	}
	
	
}

# New: 2017_02_21  Separate PC plots for strata2
# Rev: 2017_05_04 Add p value
# Rev: 2017_06_01 Different pages for different distances
generate_ordination_separate <- function (data.obj, dist.obj, dist.names=c('UniFrac', 'GUniFrac', 'WUniFrac', 'BC'), 
		grp.name, adj.name=NULL, emp.lev=NULL, indiv.lab=FALSE, indiv.lab.cex=0.5, is.lightcolor=TRUE,
		strata=NULL,  separate=NULL,  layout=NULL, pc.separate, pca.method='cmd', ann=NULL, sub=NULL,
		clab=1.0, cex.pt=1.25, ellipse=T, cstar= 1, wid=NULL, hei=NULL, pdf=TRUE, is.pvalue = FALSE, ...) {
	# Implment strata
	# To be completed, add continuous case
	strata0 <- strata
	if (is.null(separate)){
		stop('The augment separate is required!\n')
	} else {
		data.obj$meta.dat[, separate] <- factor(data.obj$meta.dat[, separate])
		sep.levels <- levels(data.obj$meta.dat[, separate])
	}
	
	if (!is.null(layout)) {
		if (is.null(hei) | is.null(wid)) {
			hei <- 3 * layout[1]
			wid <- 3 * layout[2]
		}

	} else {
		layout <- c(1, length(sep.levels))
		if (is.null(hei) | is.null(wid)) {
			hei <- 3
			wid <- 3 * length(sep.levels)
		}
	}
	
	if (pdf) {

		if (is.null(ann)) {
			pdf(paste0('Beta_diversity_ordination_', pca.method, '_', grp.name, '_separate.pdf'), width=wid, height=hei)
		} else {
			pdf(paste0('Beta_diversity_ordination_', pca.method, '_', ann, '_separate.pdf'), width=wid, height=hei)
		}
	}
	
	par(mfrow=layout)

	df <- data.obj$meta.dat
	grp <- factor(df[, grp.name])
	
	if (!is.null(emp.lev)) {
		grp <- factor(grp, levels=c(setdiff(levels(grp), emp.lev), emp.lev))
	}
	
	if (!is.null(strata)) {
		strata <- factor(df[, strata])
	} else {
		strata <- factor(grp)
	}
	
	# To be revised
	darkcols <- hue_pal(l=40)(nlevels(grp))
	if (is.lightcolor) {
		lightcols <- hue_pal(c=45, l=80)(nlevels(grp))
	} else {
		lightcols <- darkcols
	}
	
	pchs <- rep(c(21, 22, 23, 24, 25), ceiling(nlevels(strata) / 5))[1:nlevels(strata)]
	
	for (dist.name in dist.names) {
		dist.temp <- dist.obj[[dist.name]]
		
		
		for (sep.level in sep.levels) {
			ind <- df[, separate] == sep.level
			df2 <- df[ind, ]
			grp2 <- grp[ind]
			strata2 <- strata[ind]
			dist.temp2 <- dist.temp[ind, ind]
			
			if (!is.null(adj.name)) {
				adj <- as.data.frame(df2[, adj.name])
				obj <- cmdscale(as.dist(dist.temp2), k=ncol(dist.temp2)-1)
				dat2 <- apply(obj, 2, function(x) resid(lm(x ~ ., data=adj)))
				dist.temp2 <- dist(dat2)
			} 
			if (pca.method == 'cmd') {
				obj <- cmdscale(as.dist(dist.temp2), k=2, eig=T)
				pve <- round(obj$eig[1:2]/sum(abs(obj$eig))*100, 1)
				y <- cbind(obj$points[, 1], obj$points[, 2])
				
				xlab <- paste0('PC1(', pve[1], '%)')
				ylab <- paste0('PC2(', pve[2], '%)')
			} 
			
			if (pca.method == 'nmds') {
				obj <- metaMDS(as.dist(dist.temp2), k=2)
				y <- cbind(obj$points[, 1], obj$points[, 2])
				xlab <- 'NMDS1'
				ylab <- 'NMDS2'
			} 
			
			if (pca.method == 'pls') {
				require(mixOmics)
				# Test
				obj <- cmdscale(as.dist(dist.temp2), k=ncol(dist.temp2)-1)
				obj <- plsda(obj, grp2, ncomp=2)
				y <- cbind(obj$variates$X[, 1], obj$variates$X[, 2])
				xlab <- 'PLS1'
				ylab <- 'PLS2'
			}
			
			if (is.pvalue == TRUE & nlevels(factor(grp2)) > 1) {
				pvalue <- paste0('(P=', adonis(as.dist(dist.temp2) ~ grp2)$aov.tab[1, 6], ')')
			} else {
				pvalue <- ''
			}
			colnames(y) <- c("PC1", "PC2")	
			xlim <- c(-max(range(abs(y[, 1]))) * 1.25, max(range(abs(y[, 1]))) * 1.25)
			ylim <- c(-max(range(abs(y[, 2]))) * 1.25, max(range(abs(y[, 2]))) * 1.25)
			plot(y[, 1], y[, 2], type='n', xlim=xlim, ylim=ylim, 
					xlab=xlab, ylab=ylab)
#		points(y[, 1], y[, 2], bg='yellow', col=darkcols[grp2], 
#				type='p', pch = pchs[grp2], cex=cex.pt)
			col1 <- lightcols[1:nlevels(grp2)]
			col2 <- darkcols[1:nlevels(grp2)]
			col3 <- darkcols[grp2]
			if (!is.null(emp.lev)) {
				
				col1 <- col2
				col1[which(levels(grp2) != emp.lev)] <- rgb(0.5, 0.5, 0.5, 0.5)
				col1[which(levels(grp2) == emp.lev)] <- rgb(1.0, 0, 0, 1.0)
				col2[which(levels(grp2) != emp.lev)] <- rgb(0.5, 0.5, 0.5, 0.5)
				col2[which(levels(grp2) == emp.lev)] <- rgb(1.0, 0, 0, 1.0)
				col3[grp2 !=  emp.lev] <- rgb(0.5, 0.5, 0.5, 0.5)
				col3[grp2 ==  emp.lev] <- rgb(1.0, 0, 0, 1.0)
				
			}
			if (ellipse == T) {
				s.class(y, 
						fac = grp2,
						cstar = cstar,
						clab = 0,
						cpoint = 0,
						axesell = F,
						col = col1,
						grid = TRUE,
						add.plot=T,
						...
				)
			}
			
			points(y[, 1], y[, 2], bg=col3, col='black',
					type='p', pch = pchs[strata2], cex=cex.pt)
			if (indiv.lab) {
				if (is.null(emp.lev)) {
					lab.temp <- rownames(dist.temp2)
					text(y[, 1], y[, 2], labels=lab.temp, cex=indiv.lab.cex, col=rgb(1, 0, 0, 0.75))
				} else {
					lab.temp <- rownames(dist.temp2)
					lab.temp[grp2 !=  emp.lev] <- ''
					text(y[, 1], y[, 2], labels=lab.temp, cex=indiv.lab.cex, col=rgb(1, 0, 0, 0.75))
				}
				
			}
			s.class(y, 
					fac = grp2,
					cstar =0,
					cellipse = 0,
					clab = clab,
					cpoint = 0,
					axesell = F,
					col = col2,
					grid = TRUE,
					add.plot=T
			)
			if (!is.null(strata0)) {
				legend('topright', legend=(levels(strata2)), pch=pchs[1:nlevels(strata2)])	
			}
			
			title(main=sep.level, sub=paste(dist.name, "distance", pvalue))

		}


#		text(-0.25, 0.3, "PERMANOVA p=0.016")
	}
	
	if (pdf) {
		dev.off()
	}
}


# Rev:2017_04_19 Add bootstrap standard error

generate_distance_barplot <- function (data.obj, dist.obj, dist.names=c('UniFrac', 'GUniFrac', 'WUniFrac', 'BC'),
		grp.name, strata=NULL, within=T, between=T, bt.no = 100, ann='') {
	strata.name <- strata
	df <- data.obj$meta.dat
	grp <- df[, grp.name]
	grp.levels <- levels(grp)
	grp.nlevels <- nlevels(grp)
	grp.btws <- outer(grp.levels, grp.levels, paste, sep="#")
	grp.btws <- grp.btws[lower.tri(grp.btws)]
	
	if (!is.null(strata.name)) {
		strata <- df[, strata.name]
	} else {
		strata <- factor(rep(1, nrow(df))) # pseudo strata
	}
	res.df <- NULL
	for (dist.name in dist.names) {
		for (stratum in levels(strata)) {
			ind <- strata %in% stratum
			dist.sub <- dist.obj[[dist.name]][ind, ind]
			df2 <- df[ind, , drop=FALSE]
			if (between) {
				for (grp.btw in grp.btws) {
					ind1 <- which(df2[, grp.name] == unlist(strsplit(grp.btw, "#"))[1])
					ind2 <- which(df2[, grp.name] == unlist(strsplit(grp.btw, "#"))[2])	
					temp <- as.vector(dist.sub[ind1, ind2])
					sem <- sd(sapply(1:bt.no, function (i) {
								mean(dist.sub[as.numeric(sample(paste(ind1), repl=TRUE)), 
												as.numeric(sample(paste(ind2), repl=TRUE))])
							}))
					res.df <- rbind(res.df, data.frame(DistanceMetric=dist.name, Strata=stratum, Compare='Between', 
									DistanceType=grp.btw, Distance=mean(temp), sd=sem))
				}	
			}

			if (within) {
				for (grp.wth in grp.levels) {
					ind1 <- which(df2[, grp.name] == grp.wth)
					temp <- dist.sub[ind1, ind1]			
					temp <- temp[lower.tri(temp)]
					sem <- sd(sapply(1:bt.no, function (i) {
										ind2 <- as.numeric(sample(paste(ind1), repl = TRUE))
										temp <- dist.sub[ind2, ind2]			
										temp <- temp[lower.tri(temp)]
										mean(temp)
									}))
					res.df <- rbind(res.df, data.frame(DistanceMetric=dist.name, Strata=stratum, Compare='Within',
									DistanceType=grp.wth, Distance=mean(temp), sd=sem))
				}	
			}
		}
		
	}
	if (between & within) {
		res.df$DistanceType <- factor(res.df$DistanceType, levels=c(grp.btws, grp.levels))
		levels(res.df$DistanceType) <- c(sapply(strsplit(grp.btws, "#"), paste, collapse=' vs\n'), paste('Within\n', grp.levels))
	} else {
		if (between) {
			res.df$DistanceType <- factor(res.df$DistanceType)
			levels(res.df$DistanceType) <- c(sapply(strsplit(grp.btws, "#"), paste, collapse=' vs\n'))
		} else {
			res.df$DistanceType <- factor(res.df$DistanceType)
			levels(res.df$DistanceType) <- c(paste('Within\n', grp.levels))
		}
	}
	
	if (is.null(strata.name)) {
		pdf(paste0("Beta_diversity_btw", between, "_wth", within, "no_strata_barplot_", ann, ".pdf"),
				width=5, height=5)
		
		limits <- aes(ymax = Distance + sd, ymin=Distance - sd)
		dodge <- position_dodge(width=0.9)
		for (dist.name in dist.names) {
			cat(dist.name, "...\n")
			temp <- res.df[res.df$DistanceMetric == dist.name, ]
			obj1 <- ggplot(temp, aes(x=DistanceType, y=Distance, fill=DistanceType)) + 
					geom_bar(position=dodge, stat="identity", width=0.75) + 
					geom_bar(position=dodge, stat="identity", width=0.75, colour="black", size=0.25) +
					geom_errorbar(limits, position=dodge, size=0.25, width=0.25) +
					labs(y=paste(dist.name, "Distance"), x='') +
					theme(legend.position="none") +
					theme(axis.text.x=element_text(angle=90, hjust=1))
					
			print(obj1)
			
		}
		dev.off()
	} else {
		pdf(paste0("Beta_diversity_btw", between, "_wth", within, "_strata", strata.name, "barplot_", ann, ".pdf"),
				width=2.5*(nlevels(strata)-1) + 5, height=5)
		
		limits <- aes(ymax = Distance + sd, ymin=Distance - sd)
		dodge <- position_dodge(width=0.9)
		for (dist.name in dist.names) {
			cat(dist.name, "...\n")
			temp <- res.df[res.df$DistanceMetric == dist.name, ]
			obj1 <- ggplot(temp, aes(x=Strata, y=Distance, fill=DistanceType)) + 
					geom_bar(position=dodge, stat="identity") + 
					geom_bar(position=dodge, stat="identity", colour="black", size=0.25) +
					geom_errorbar(limits, position=dodge, size=0.25, width=0.5) +
					labs(y=paste(dist.name, "Distance"), x=strata.name) +
					theme(axis.text.x=element_text(angle=90, hjust=1))
			print(obj1)
			
		}
		dev.off()
		
	}
	
}

generate_distance_boxplot <- function (data.obj, dist.obj, dist.names=c('UniFrac', 'GUniFrac', 'WUniFrac', 'BC'),
		grp.name, strata=NULL, within=F, between=T, ann='') {
	strata.name <- strata
	df <- data.obj$meta.dat
	grp <- df[, grp.name]
	grp.levels <- levels(grp)
	grp.nlevels <- nlevels(grp)
	grp.btws <- outer(grp.levels, grp.levels, paste, sep="#")
	grp.btws <- grp.btws[lower.tri(grp.btws)]
	
	if (!is.null(strata.name)) {
		strata <- df[, strata.name]
	} else {
		strata <- factor(rep(1, nrow(df))) # pseudo strata
	}
	res.df <- NULL
	for (dist.name in dist.names) {
		for (stratum in levels(strata)) {
			ind <- strata %in% stratum
			dist.sub <- dist.obj[[dist.name]][ind, ind]
			df2 <- df[ind, , drop=FALSE]
			if (between) {
				for (grp.btw in grp.btws) {
					ind1 <- df2[, grp.name] == unlist(strsplit(grp.btw, "#"))[1]
					ind2 <- df2[, grp.name] == unlist(strsplit(grp.btw, "#"))[2]	
					temp <- as.vector(dist.sub[ind1, ind2])
					n <- length(temp)
					res.df <- rbind(res.df, data.frame(DistanceMetric=rep(dist.name, n), Strata=rep(stratum, n), Compare=rep('Between', n),
									DistanceType=rep(grp.btw, n), Distance=temp))
				}	
			}
			
			if (within) {
				for (grp.wth in grp.levels) {
					ind1 <- df2[, grp.name] == grp.wth
					temp <- dist.sub[ind1, ind1]			
					temp <- temp[lower.tri(temp)]
					n <- length(temp)
					res.df <- rbind(res.df, data.frame(DistanceMetric=rep(dist.name, n), Strata=rep(stratum, n), Compare=rep('Within', n),
									DistanceType=rep(grp.wth, n), Distance=temp))
				}	
			}
		}
		
	}
	if (between & within) {
		res.df$DistanceType <- factor(res.df$DistanceType, levels=c(grp.btws, grp.levels))
		levels(res.df$DistanceType) <- c(sapply(strsplit(grp.btws, "#"), paste, collapse=' vs\n'), paste('Within\n', grp.levels))
	} else {
		if (between) {
			res.df$DistanceType <- factor(res.df$DistanceType)
			levels(res.df$DistanceType) <- c(sapply(strsplit(grp.btws, "#"), paste, collapse=' vs\n'))
		} else {
			res.df$DistanceType <- factor(res.df$DistanceType)
			levels(res.df$DistanceType) <- c(paste('Within\n', grp.levels))
		}
	}
	
	if (is.null(strata.name)) {
		pdf(paste0("Beta_diversity_btw", between, "_wth", within, "no_strata_boxplot_", ann, ".pdf"),
				width=5, height=5)
		
		for (dist.name in dist.names) {
			cat(dist.name, "...\n")
			temp <- res.df[res.df$DistanceMetric == dist.name, ]
			
			dodge <- position_dodge(width=0.95)		
			obj1 <- ggplot(temp, aes(x=DistanceType, y=Distance, col=DistanceType)) + 
					geom_boxplot(position=dodge, outlier.colour = NA) + 
#					geom_jitter(alpha=0.6, size=3.0,  position = position_jitter(w = 0.1)) +
					labs(y=paste(dist.name, "Distance"), x='') +
					theme(legend.position="none")
			
			print(obj1)
			
		}
		dev.off()
	} else {
		pdf(paste0("Beta_diversity_btw", between, "_wth", within, "_strata", strata.name, "boxplot_", ann, ".pdf"),
				width=2.5*(nlevels(strata)-1) + 5, height=5)
		
		for (dist.name in dist.names) {
			cat(dist.name, "...\n")
			temp <- res.df[res.df$DistanceMetric == dist.name, ]
			dodge <- position_dodge(width=0.95)		
			obj1 <- ggplot(temp, aes(x=Strata, y=Distance, col=DistanceType)) + 
					geom_boxplot(position=dodge, outlier.colour = NA) + 
		#			geom_jitter(alpha=0.6, size=3.0,  position = position_jitter(w = 0.1)) +
					labs(y=paste(dist.name, "Distance"), x=strata.name)
			print(obj1)
			
		}
		dev.off()
		
	}
	
}


# Rev:2016_11_25
generate_clustering <- function(data.obj, dist.obj, dist.names=c('UniFrac', 'GUniFrac', 'WUniFrac', 'BC'), meta.info, cluster.method='ward.D', 
		is.labRow=F, cex.lab=NULL, ann="", wid=10, hei=6, colFnsF=NULL, colFnsC=NULL) {
	if (is.null(colFnsC)) {
		colFnsC <- c(colorRampPalette(c('black', 'green')), colorRampPalette(c('black', 'blue')), colorRampPalette(c('black', 'red')))
	} 
	if (is.null(colFnsF)) {
		rainbow3 <- function(x) {
			rainbow(x + 2)[1:x]
		}
		jet3 <- function(x) {
			jet(x + 2)[1:x]
		}
		colFnsF <- c(rainbow3, jet3)
	}
	
	pdf(paste0("Beta_diversity_Hierachical_clustering_", ann, ".pdf"), width=wid, height=hei)
	for (dist.name in dist.names) {

		df <- data.obj$meta.dat
		dist.sub <- dist.obj[[dist.name]]
		dend <- hclust(as.dist(dist.sub), cluster.method)
		

		key.list <- list()
		mat <- NULL
		for (keyID in meta.info) {
			x <- df[, keyID]
			i <- 0
			j <- 0
			if (is.factor(x)) {
				key.list[[keyID]] <- list(breaks=levels(x), colors=(colFnsF[i+1][[1]])(nlevels(x)), base=NA, col.na=NA, right=F, include.lowest=F)	
				i <- (i + 1) %% length(colFnsF)
				mat <- cbind(mat, key.list[[keyID]]$colors[x])
			} else {
				key.list[[keyID]] <- makecmap(x, n=5, colFn=colFnsC[j+1][[1]])
				j <- (j + 1) %% length(colFnsC)
				mat <- cbind(mat, cmap(x, key.list[[keyID]]))
			}
		}
		colnames(mat) <- meta.info

		par(oma = c(1, 2, 1, 2))
		par(mar = c(5,4,4,3)+0.1)  # make space for color keys
		if (is.labRow == F) {
			labRow <- ""
		} else {
			labRow <- rownames(df)
		}
		if (is.null(cex.lab)) {
			cex.lab <- 25 / nrow(df) 
		}
		
		dendromat(dend, mat, labRow=labRow,
				ylab = 'Distance', main = paste(dist.name, "distance"), cex.lab=cex.lab)
		
		par(oma=c(0, 0, 0, 0))
		y.cord <- (1/length(meta.info)) * (0:(length(meta.info) - 1))
		k <- 1
		for (keyID in meta.info) {
			x <- df[, keyID]
			if (is.factor(x)) {
				vkey2(key.list[[keyID]], keyID, y=y.cord[k], stretch=1.2)
			} else {
				vkey(key.list[[keyID]], keyID, y=y.cord[k], stretch=1.2)
			}
			k <- k + 1
		}		
	}
	dev.off()
}


# Rev: 2016_09_10, Implement p value based omnibus test
PermanovaG2 <- function (formula, dat = NULL, ...) 
{
	save.seed <- get(".Random.seed", .GlobalEnv)
	lhs <- formula[[2]]
	lhs <- eval(lhs, dat, parent.frame())
	rhs <- as.character(formula)[3]
	p.perms <- list()
	p.obs <- list()
	for (i in 1:(dim(lhs)[3])) {
		assign(".Random.seed", save.seed, .GlobalEnv)
		Y <- as.dist(lhs[, , i])
		formula2 <- as.formula(paste("Y", "~", rhs))
		obj <- adonis(formula2, dat, ...)
		perm.mat <- obj$f.perms
		p.perms[[i]] <- 1 - (apply(perm.mat, 2, rank) - 1) / nrow(perm.mat)
		p.obs[[i]] <- obj$aov.tab[1:ncol(perm.mat), "Pr(>F)"]

	}
	
	omni.pv <- NULL
	indiv.pv <- NULL
	for (j in 1:ncol(perm.mat)) {
		p.perms.j <- sapply(p.perms, function (x) x[, j])
		p.obj.j <- sapply(p.obs, function (x) x[j])
		omni.pv <- c(omni.pv, mean(c(rowMins(p.perms.j ) <= min(p.obj.j), 1)))
		indiv.pv <- rbind(indiv.pv, p.obj.j)
	}
	colnames(indiv.pv) <- paste0('D', 1:ncol(indiv.pv), '.p.value')
	rownames(indiv.pv) <- 1:nrow(indiv.pv)
	
	aov.tab <- data.frame(indiv.pv, omni.p.value = omni.pv)
	rownames(aov.tab) <- rownames(obj$aov.tab)[1:ncol(perm.mat)]
	list(aov.tab = aov.tab)
}


perform_permanova_test <- function (data.obj, dist.obj, dist.names=c('UniFrac', 'GUniFrac', 'WUniFrac', 'BC'), 
		PermanovaG.dist=c('UniFrac', 'GUniFrac', 'WUniFrac', 'BC'),
		formula=NULL,  grp.name=NULL, adj.name=NULL, pairwise=F, block.perm=F, strata=NULL, ann='', ...) {
	# PermanovaG not implemented for block permutation
	result <- list()
	
	df <- data.obj$meta.dat
	if (!is.null(strata)) {
		if (is.character(strata)) {
			strata <- factor(df[, strata])
		}
	}
	if (!is.null(formula)) {
		ind <- apply(df[, gsub("^\\s+|\\s+$", "", strsplit(strsplit(formula, "~")[[1]][2], "\\+")[[1]]), drop=F], 1, function(x) sum(is.na(x))) == 0
		df <- df[ind, ]
		if (!is.null(strata)) {
			strata <- factor(strata[ind])
		}
		sink(paste0('Beta_diversity_PERMANOVA_test_', ann, '.txt'))
		date()
		cat('\nPERMANOVA test: \n')
		permanova.obj <- list()
		for (dist.name in dist.names) {
			cat(dist.name, " distance: \n")
			dist.mat <- as.dist(dist.obj[[dist.name]][ind, ind])
			if (block.perm == F) {
				obj <- adonis(as.formula(paste("dist.mat", formula)), df,  strata=strata, ...)
			} else {
				obj <- adonis2(as.formula(paste("dist.mat", formula)), df,  strata=strata, ...)
			}
			
			prmatrix(obj$aov.tab)
			permanova.obj[[dist.name]] <- obj$aov.tab
			cat("\n")
		}
		result$permanova.obj <- permanova.obj
		permanovaG.obj <- NULL
		if (block.perm == F & !is.null(PermanovaG.dist)) {
			cat('\nPERMANOVA G test combining ', paste(PermanovaG.dist, collapse=','), '\n')
			response <- array(NA, c(sum(ind), sum(ind), length(PermanovaG.dist)), dimnames=list(NULL, NULL, PermanovaG.dist))
			for (dist.name in PermanovaG.dist) {
				response[, , dist.name] <- dist.obj[[dist.name]][ind, ind]
			}
			obj <- PermanovaG2(as.formula(paste("response", formula)), df,  strata=strata, ...)
			prmatrix(obj$aov.tab)
			permanovaG.obj <- obj$aov.tab
			cat("\n")
			result$permanovaG.obj <- permanovaG.obj
		}
		cat("\n")
		sink()
	} else {
		if (pairwise == F) {
			if (is.null(adj.name)) {
				formula <- paste('~', grp.name)
			} else {
				formula <- 	paste('~', paste(adj.name, collapse='+'), '+', grp.name)		
			}
			
			ind <- apply(df[, gsub("^\\s+|\\s+$", "", strsplit(strsplit(formula, "~")[[1]][2], "\\+")[[1]]), drop=F], 1, function(x) sum(is.na(x))) == 0
			df <- df[ind, ]
			if (!is.null(strata)) {
				strata <- factor(strata[ind])
			}
			sink(paste0('Beta_diversity_PERMANOVA_test_', ann, '.txt'))
			date()
			cat('\nPERMANOVA test: \n')
			permanova.obj <- list()
			for (dist.name in dist.names) {
				cat(dist.name, " distance: \n")
				dist.mat <- as.dist(dist.obj[[dist.name]][ind, ind])
				if (block.perm == F) {
					obj <- adonis(as.formula(paste("dist.mat", formula)), df,  strata=strata, ...)
				} else {
					obj <- adonis2(as.formula(paste("dist.mat", formula)), df,  strata=strata, ...)
				}
				prmatrix(obj$aov.tab)
				permanova.obj[[dist.name]] <- obj$aov.tab
				cat("\n")
			}
			result$permanova.obj <- permanova.obj
			permanovaG.obj <- NULL
			if (block.perm == F & !is.null(PermanovaG.dist)) {
				cat('\nPERMANOVA G test combining ', paste(PermanovaG.dist, collapse=','), '\n')
				response <- array(NA, c(sum(ind), sum(ind), length(PermanovaG.dist)), dimnames=list(NULL, NULL, PermanovaG.dist))
				for (dist.name in PermanovaG.dist) {
					response[, , dist.name] <- dist.obj[[dist.name]][ind, ind]
				}
				obj <- PermanovaG2(as.formula(paste("response", formula)), df,  strata=strata, ...)
				prmatrix(obj$aov.tab)
				permanovaG.obj <- obj$aov.tab
				cat("\n")
				result$permanovaG.obj <- permanovaG.obj
			}
			
			cat("\n")
			sink()
			
		} else {
			sink(paste0('Beta_diversity_PERMANOVA_test_', ann, '_pairwise.txt'))
			date()
			cat('\nPairwise PERMANOVA test: \n')
			grp <- factor(df[, grp.name])
			grp.levels <- levels(grp)
			grp.nlevels <- nlevels(grp)
			pmat.all <- NULL
			rmat.all <- NULL
			pmat.G <- matrix(NA, grp.nlevels, grp.nlevels)
			colnames(pmat.G) <- rownames(pmat.G) <- grp.levels
			for (dist.name in dist.names) {
				cat(dist.name, " distance: \n")
				pmat <- matrix(NA, grp.nlevels, grp.nlevels)
				colnames(pmat) <- rownames(pmat) <- grp.levels
				rmat <- matrix(NA, grp.nlevels, grp.nlevels)
				colnames(rmat) <- rownames(rmat) <- grp.levels
				for (i in 1:(grp.nlevels-1)) {
					grp.level1 <- grp.levels[i]
					for (j in (i+1):grp.nlevels) {
						
						grp.level2 <- grp.levels[j]
						cat(grp.level1, ' vs ', grp.level2, '\n')
						ind <- grp %in% c(grp.level1, grp.level2)
						df2 <- subset(df, ind)
						df2[, grp.name] <- factor(df2[, grp.name])
						dist.mat <- dist.obj[[dist.name]][ind, ind]
						
						if (!is.null(strata)) {
						  strata2 <- factor(strata[ind])
					    } else {
						  strata2 <- NULL
						}
						
						if (is.null(adj.name)) {
							formula <- paste('~', grp.name)
						} else {
							formula <- 	paste('~', paste(adj.name, collapse='+'), '+', grp.name)		
						}
						
						ind2 <- apply(df2[, gsub("^\\s+|\\s+$", "", strsplit(strsplit(formula, "~")[[1]][2], "\\+")[[1]]), drop=F], 1, function(x) sum(is.na(x))) == 0
						df2 <- df2[ind2, ]
						dist.mat2 <- as.dist(dist.mat[ind2, ind2])
						
						if (!is.null(strata2)) {
						    strata2 <- factor(strata2[ind2])
						}
						
						if (block.perm == F) {
							obj <- adonis(as.formula(paste("dist.mat2", formula)), df2,  strata=strata2, ...)
						} else {
							obj <- adonis2(as.formula(paste("dist.mat2", formula)), df2,  strata=strata2,  ...)
						}
						prmatrix(obj$aov.tab)
						cat("\n")
	
						if (block.perm == F) {
							pmat[i, j] <- pmat[j, i] <- obj$aov.tab[length(adj.name)+1, 6]
							rmat[i, j] <- rmat[j, i] <- obj$aov.tab[length(adj.name)+1, 5]
						} else {
							pmat[i, j] <- pmat[j, i] <- obj$aov.tab[1, 6]
							rmat[i, j] <- rmat[j, i] <- obj$aov.tab[1, 5]
						}

						# PERMANOVA G after last distance
						if (block.perm == F & !is.null(PermanovaG.dist)) {
							if (dist.name == dist.names[length(dist.names)]) {
								cat('\nPERMANOVA G test combining ', paste(PermanovaG.dist, collapse=','), '\n')
								response <- array(NA, c(sum(ind2), sum(ind2), length(PermanovaG.dist)), dimnames=list(NULL, NULL, PermanovaG.dist))
								for (dist.name in PermanovaG.dist) {
									# Rev: 2019_05_20 Fixed an error
									response[, , dist.name] <- dist.obj[[dist.name]][ind, ind][ind2, ind2]
								}
								obj <- PermanovaG2(as.formula(paste("response", formula)), df2,  strata=strata2, ...)
								prmatrix(obj$aov.tab)
								cat("\n")
								pmat.G[i, j] <- pmat.G[j, i] <- obj$aov.tab[length(adj.name)+1, 'omni.p.value']
							}
						}
					}
				}
				cat("\n")
				pmat.all <- rbind(pmat.all, c(dist.name, rep('', grp.nlevels-1)), formatC(pmat), rep("", grp.nlevels))
				rmat.all <- rbind(rmat.all, c(dist.name, rep('', grp.nlevels-1)), formatC(rmat), rep("", grp.nlevels))
			}
			cat("\n")
			sink()
			write.csv(pmat.all, paste0('Beta_diversity_PERMANOVA_test_', ann, '_pairwiseP.csv'))
			write.csv(rmat.all, paste0('Beta_diversity_PERMANOVA_test_', ann, '_pairwiseR.csv'))
			write.csv(pmat.G, paste0('Beta_diversity_PERMANOVA_G_test_', ann, '_pairwiseP.csv'))
		}
	}
	
	return(invisible(result))
}

randomForestTest <- function(x, y, perm.no=999, ...) {
	iris.rf <- randomForest(x=x, y=y, importance=FALSE)
	to1 <- mean(abs((as.numeric(y) - 1) - predict(iris.rf,  type='prob')[, 2])^2) #mean squarred error
	to2 <- mean(y !=  predict(iris.rf,   type='response'))  #mean prediction error
	tp <- sapply(1:perm.no, function(i) {
				if (i %% 10 == 0) cat('.')
				y.p <- sample(y)
				iris.rf <- randomForest(x=x, y=y.p, importance=FALSE)
				
				t1 <- mean(abs((as.numeric(y.p) - 1) - predict(iris.rf,  type='prob')[, 2])^2) 
				t2 <- mean(y.p !=  predict(iris.rf,   type='response'))
				c(t1, t2)
			}
	
	)
	pv1 <- (sum(tp[1, ] <= to1) + 1) / (perm.no + 1)
	pv2 <- (sum(tp[2, ] <= to2) + 1) / (perm.no + 1)
	c(pv1=pv1, pv2=pv2)
}

perform_rf_test <- function (data.obj, grp.name, taxa.level='Genus', perm.no=999, prev=0.1, minp=0.000, ann='',...) {
	if (taxa.level == 'Species') {
		if (taxa.level %in% names(data.obj$abund.list)) {
			ct <- data.obj$abund.list[[taxa.level]]
		} else {
			# Accomodate different version
			ct <- data.obj$otu.tab
			rownames(ct) <- paste0("OTU", rownames(ct), ":", data.obj$otu.name[, 'Phylum'], ";", data.obj$otu.name[, 'Genus'])
			data.obj$abund.list[['Species']] <- ct
		}
	} else {
		ct <- data.obj$abund.list[[taxa.level]]
	}
	
	prop <- t(t(ct) / colSums(ct))
	prop <- prop[rowMaxs(prop) > minp & rowSums(prop!=0) > prev*ncol(prop), , drop=FALSE]
	prop <- t(prop)
	
	grp <- data.obj$meta.dat[, grp.name]
	if (!is.factor(grp)) stop('Current random Forest test is designed to deal with binary factor data!\n')

	cat('RF test P values  ...\n')
	obj <- randomForestTest(prop, grp, perm.no, ...)
	sink(paste0('OverallAssoc_RF_test_', taxa.level, '_', ann, '.txt'))
	cat ('Prediction Probability:', obj[1], '\n')
	cat ('Binary Response:', obj[2], '\n')
	sink()
}

# Rev: 2016_12_02, MiKRAT for binary result, add out_type='D'
perform_mirkat_test <- function (data.obj, dist.obj, dist.names=c('UniFrac', 'GUniFrac', 'WUniFrac', 'BC'), 
		grp.name=NULL, adj.name=NULL, pairwise=F,  ann='', ...) {
	
	# MiRKAT not implemented for correlated data
	df <- data.obj$meta.dat
	
	if (pairwise == F) {
		
		ind <- apply(df[, c(grp.name, adj.name), drop=F], 1, function(x) sum(is.na(x))) == 0
		df <- df[ind, ]
		
		grp <- df[, grp.name]
		
		if (is.character(grp)) {
			grp <- factor(grp)
		}
		# Rev: 2016_12_02
		if (is.factor(grp)) {
			if (nlevels(grp) > 2) {
				stop('Currently MiRKAT only supports binary outcome!')
			} else {
				grp <- as.numeric(grp) - 1
				out_type <- 'D'
			}
		} else {
			out_type <- 'C'
		}
		if (!is.null(adj.name)) {
			# No intercept
			adj <- model.matrix(~ ., data.frame(df[, adj.name]))
			# Remove collinear terms
			qadj <- qr(adj, tol = 1e-07)
			adj <- adj[, qadj$pivot, drop = FALSE]
			adj <- adj[, 1:qadj$rank, drop = FALSE]
			# Remove intercept
			adj <- adj[, colSums(adj==1) != nrow(adj)]
		} else {
			adj <- NULL
		}
		
		sink(paste0('Beta_diversity_MiRKAT_test_', ann, '.txt'))
		date()
		cat('\nMiRKAT test combining ', paste(dist.names, collapse=','), '\n')
		Ks <- list()
		for (dist.name in dist.names) {
			Ks[[dist.name]] <- D2K(dist.obj[[dist.name]][ind, ind])
		}
		# Rev: 2016_12_02
		obj <- MiRKAT(grp, X=adj, Ks, out_type=out_type)
		cat('Individual P value: ')
		prmatrix(t(obj$indivP))
		cat('\nOmnibus P value: ')
		cat(obj$omnibus_p)
		cat("\n")
		sink()
		
	} else {
		sink(paste0('Beta_diversity_MiRKAT_test_', ann, '_pairwise.txt'))
		date()
		cat('\nPairwise MiRKAT test: \n')
		grp <- factor(df[, grp.name])
		grp.levels <- levels(grp)
		grp.nlevels <- nlevels(grp)
		pmat.G <- matrix(NA, grp.nlevels, grp.nlevels)
		colnames(pmat.G) <- rownames(pmat.G) <- grp.levels
		parr <- array(NA, c(grp.nlevels, grp.nlevels, length(dist.names)), dimnames=list(grp.levels, grp.levels, dist.names))
		
		for (i in 1:(grp.nlevels-1)) {
			grp.level1 <- grp.levels[i]
			for (j in (i+1):grp.nlevels) {
				
				grp.level2 <- grp.levels[j]
				cat(grp.level1, ' vs ', grp.level2, '\n')
				ind <- grp %in% c(grp.level1, grp.level2)
				df2 <- subset(df, ind)
				df2[, grp.name] <- factor(df2[, grp.name])
				ind2 <- apply(df2[, c(grp.name, adj.name), drop=F], 1, function(x) sum(is.na(x))) == 0
				df2 <- df[ind2, ]
				
				grp2 <- as.numeric(df2[, grp.name]) - 1
				if (!is.null(adj.name)) {
					# No intercept
					adj <- model.matrix(~ ., data.frame(df2[, adj.name]))
					# Remove collinear terms
					qadj <- qr(adj, tol = 1e-07)
					adj <- adj[, qadj$pivot, drop = FALSE]
					adj <- adj[, 1:qadj$rank, drop = FALSE]
					# Remove intercept
					adj <- adj[, colSums(adj==1) != nrow(adj)]
				} else {
					adj <- NULL
				}
				
				Ks <- list()
				for (dist.name in dist.names) {
					Ks[[dist.name]] <- D2K(dist.obj[[dist.name]][rownames(df2), rownames(df2)])
				}
				# Rev: 2016_12_02
				obj <- MiRKAT(grp2, X=adj, Ks, out_type='D')
				pmat.G[i, j] <- pmat.G[j, i] <- obj$omnibus_p
				parr[i, j, ] <- parr[j, i, ] <- obj$indivP
				cat('Individual P value: ')
				prmatrix(t(obj$indivP))
				cat('\nOmnibus P value: ')
				cat(obj$omnibus_p)
				cat("\n")
				
			}
		}
		cat("\n")
		sink()
		
		pmat.all <- NULL
		for (dist.name in dist.names) {
			pmat <- parr[, , dist.name]
			pmat.all <- rbind(pmat.all, c(dist.name, rep('', grp.nlevels-1)), formatC(pmat), rep("", grp.nlevels))
		}
		
		write.csv(pmat.all, paste0('Beta_diversity_MiRKAT_test_', ann, '_pairwiseP.csv'))
		write.csv(pmat.G, paste0('Beta_diversity_MiRKAT_O_test_', ann, '_pairwiseP.csv'))
	}
}


perform_betadisper_test <- function (data.obj, dist.obj, dist.names=c('UniFrac', 'GUniFrac', 'WUniFrac', 'BC'), grp.name) {
	df <- data.obj$meta.dat
	grp <- df[, grp.name]
	sink('Beta_diversity_BETADISPER_test.txt')
	date()
	cat('\nBetadisper test: \n')
	for (dist.name in dist.names) {
		cat(dist.name, " distance: \n")
		dist.mat <- as.dist(dist.obj[[dist.name]])
		obj <- betadisper(dist.mat, grp)
		prmatrix(anova(obj))
		cat("\n")
	}
	cat("\n")
	sink()
}

distance_compare_test <- function (dist.mat, ind1, ind2, ind3, ID2=NULL, ID3=NULL, alternative='greater', nperm=999) {
	
	ind23 <- c(ind2, ind3)
	if (!is.null(ID2) & !is.null(ID3)) {
		ID23 <- c(ID2, ID3)
		ID2u <- unique(ID2)
		ID3u <- unique(ID3)
		ID23u <- c(ID2u, ID3u)
		n2u <- length(ID2u)
		n3u <- length(ID3u)
	}
	n2 <- length(ind2)
	n3 <- length(ind3)
	
	dist12 <- dist.mat[ind1, ind2]
	dist13 <- dist.mat[ind1, ind3]
	
	stat.obs <- mean(dist12) - mean(dist13)
	stat.perm <- sapply(1:nperm, function(i) {
				if (is.null(ID2) & is.null(ID3)) {
					ind23.p <- sample(ind23)
					ind2.p <- ind23.p[1:n2]
					ind3.p <- ind23.p[(n2+1):(n2+n3)]
				} else {
					ID23u.p <- sample(ID23u)
					ID2.p <- ID23u.p[1:n2u]
					ID3.p <- ID23u.p[(n2u+1):(n2u+n3u)]
					ind2.p <- ind23[ID23 %in% ID2.p]
					ind3.p <- ind23[ID23 %in% ID3.p]
				}

				dist12.p <- dist.mat[ind1, ind2.p]
				dist13.p <- dist.mat[ind1, ind3.p]
				mean(dist12.p) - mean(dist13.p)
			})
	if (alternative == 'greater') {
		pv <- mean(c(stat.perm >= stat.obs, TRUE))
	} else {
		pv <- mean(c(stat.perm <= stat.obs, TRUE))
	}  
	pv
}

# Note that this is the block-permutation scheme, not within-sbuject permutation
perform_distance_compare_test <- function (data.obj, dist.obj, dist.names=c('UniFrac', 'GUniFrac', 'WUniFrac', 'BC'),
		grp.name, level1, level2, level3, subject=NULL, alternative='greater', nperm=999, seed=123, ann='') {
	sink(paste0('Beta_diversity_test_', level1, '-', level2, '_', alternative, '_', level1, '-', level3, '_', ann, '.txt'))
	set.seed(seed)
	cat('Testing the distance ', level1, '-', level2, ' is ', alternative, ' than ', level1, '-', level3, '\n')
	df <- data.obj$meta.dat
	grp <- df[, grp.name]
	IDs <- df[, subject]
	grp.levels <- levels(grp)
	grp.nlevels <- nlevels(grp)
	ind1 <- which(grp == level1)
	ind2 <- which(grp == level2)
	ind3 <- which(grp == level3)
	if (is.null(subject)) {
		ID2 <- NULL
		ID3 <- NULL
	} else {
		ID2 <- as.character(IDs[grp == level2])
		ID3 <- as.character(IDs[grp == level3])
	}
	for (dist.name in dist.names) {
		cat(dist.name, ' Distance:p=') 
		pv <- distance_compare_test(dist.obj[[dist.name]], ind1, ind2, ind3, ID2, ID3, alternative, nperm)
		cat(pv, '\n')
	}
	sink()
	
}


perform_taxa_compare_test <- function (data.obj, grp.name, level1, level2, level3, alternative='greater', nperm=1000, seed=123,
		taxa.levels=c('Phylum', 'Family', 'Genus'), taxa.name='All', prev=0.1, minp=0.002, ann='') {
	
	df <- data.obj$meta.dat
	grp <- df[, grp.name]
	
	grp.levels <- levels(grp)
	grp.nlevels <- nlevels(grp)
	ind1 <- which(grp == level1)
	ind2 <- which(grp == level2)
	ind3 <- which(grp == level3)
	
	pv.list <- list()
	
	for (LOI in taxa.levels) {
		cat(LOI, "\n")
		prop <- data.obj$abund.list[[LOI]]
		prop <- t(t(prop) / colSums(prop))
		pv.vec <- NULL
		if (taxa.name == 'All') {
			prop <- prop[rowMaxs(prop) > minp & rowSums(prop!=0) > prev*ncol(prop), , drop=FALSE]
		} else {
			prop <- prop[taxa.name, , drop=FALSE]
		}
		
		for (taxon in rownames(prop)) {
			cat(".")
			dist.mat <- as.matrix(dist(rank(prop[taxon, ])))
			pv <- distance_compare_test(dist.mat, ind1, ind2, ind3, alternative, nperm)
			pv.vec <- c(pv.vec, pv)
		}
		names(pv.vec) <- rownames(prop)
		pv.list[[LOI]] <- pv.vec
		cat("\n")
	}
	
	for (LOI in taxa.levels) {
		pv.vec <- pv.list[[LOI]]

		qv.vec <- p.adjust(pv.vec, 'fdr')

		
		write.csv(data.frame("p value"=pv.vec, "q value"=qv.vec), paste0("Taxa_TrendAnalysis_", LOI, "_", ann, ".csv"))
	}
	
}

# New: 2017_11_03
# Now default is averaged distance for within or between-subject comparison
perform_site_correlation_test <- function (data.obj, dist.obj, site.name, sites, subject, 
		dist.names = c('UniFrac', 'GUniFrac', 'WUniFrac', 'BC'), dist.ave = TRUE, nPerm = 999, ann = '') {

	pmat <- array(NA, c(length(dist.names), length(sites), length(sites)), dimnames=list(dist.names, sites, sites))
	for (site1 in sites) {
		for(site2 in sites) {
			if (site1 != site2 & is.na(pmat[1, site1, site2])) {
				cat('.')
				sampling.site <- c(site1, site2)
				samIDs <- data.obj$meta.dat[, site.name] %in% sampling.site 
				data.obj1 <- subset_data(data.obj, samIDs)
				dist.obj1 <- subset_dist(dist.obj, samIDs)
				
# Compute the observed distance within subject
				lIDs <- as.character(data.obj1$meta.dat[, site.name])
				pIDs <- as.character(data.obj1$meta.dat[, subject])
				uIDs <- as.character(unique(data.obj1$meta.dat[, subject]))
				
				
				pdf(paste('Permutation_test', site1, site2, 'Correlation_', ann, '.pdf', sep='_'), width=6, height=6)
				for (dist.name in dist.names) {
					cat(dist.name, '...\n')
					
					dist.mat <- dist.obj1[[dist.name]]					
# To self
					dist.o1 <- NULL
					for (uID in uIDs) {
						ind1 <- pIDs == uID & lIDs == site1
						ind2 <- pIDs == uID & lIDs == site2
						
						if (sum(ind1) != 0 & sum(ind2) != 0)
							if (dist.ave) {
								dist.o1 <- c(dist.o1, mean(dist.mat[ind1, ind2]))
							} else {
								dist.o1 <- c(dist.o1, dist.mat[ind1, ind2])
							}
							
					}
					
# To other people
					dist.o2 <- NULL
					for (uID in uIDs) {
						ind1 <- pIDs == uID & lIDs == site1
						ind2 <- pIDs != uID & lIDs == site2
						
						if (sum(ind1) != 0 & sum(ind2) != 0)
							if (dist.ave) {
								dist.o2 <- c(dist.o2, mean(dist.mat[ind1, ind2]))
							} else {
								dist.o2 <- c(dist.o2, dist.mat[ind1, ind2])
							}
							
					}
					
					if (!is.null(dist.o1) & !is.null(dist.o2)) {
						boxplot(list(ToSelf=dist.o1, ToOther=dist.o2), col='steelblue', ylab=paste(dist.name, 'distance'))
						stat.o <- mean(dist.o2) - mean(dist.o1)
						
						stat.p <- NULL
						for (i in 1:nPerm) {
							# Exchange the uterus between people :D
							pIDs.p <- pIDs
							pIDs.uterus <- pIDs[lIDs == site1]
							temp <- factor(pIDs.uterus)
							levels(temp) <- sample(levels(temp))
							pIDs.uterus.p <- as.character(temp)
							pIDs.p[lIDs == site1] <- pIDs.uterus.p
							
							# To increase the number of permutation
							pIDs.uterus <- pIDs[lIDs == site2]
							temp <- factor(pIDs.uterus)
							levels(temp) <- sample(levels(temp))
							pIDs.uterus.p <- as.character(temp)
							pIDs.p[lIDs == site2] <- pIDs.uterus.p
							
							# To self
							dist.o1 <- NULL
							for (uID in uIDs) {
								ind1 <- pIDs.p == uID & lIDs == site1
								ind2 <- pIDs.p == uID & lIDs == site2
								
								if (sum(ind1) != 0 & sum(ind2) != 0)
									if (dist.ave) {
										dist.o1 <- c(dist.o1, mean(dist.mat[ind1, ind2]))
									} else {
										dist.o1 <- c(dist.o1, dist.mat[ind1, ind2])
									}
							}
							
# To other people
							dist.o2 <- NULL
							for (uID in uIDs) {
								ind1 <- pIDs.p == uID & lIDs == site1
								ind2 <- pIDs.p != uID & lIDs == site2
								
								if (sum(ind1) != 0 & sum(ind2) != 0)
									if (dist.ave) {
										dist.o2 <- c(dist.o2, mean(dist.mat[ind1, ind2]))
									} else {
										dist.o2 <- c(dist.o2, dist.mat[ind1, ind2])
									}
							}
							
							# boxplot(list(ToSelf=dist.o1, ToOther=dist.o2))
							stat.p <- c(stat.p, mean(dist.o2) - mean(dist.o1))
						}
						
						pv <- mean(c(stat.p >= stat.o, TRUE))
						
						hist(stat.p, xlab=paste(dist.name, 'distance'), col='steelblue', xlim=c(min(stat.p) * 2, max(stat.p) * 2),
								main='Average distances observed under permutation', sub=paste('P < ', pv))
						
						abline(v=stat.o, col='red')
						pmat[dist.name, site1, site2] <- pmat[dist.name, site2, site1] <- pv
					}

				}
				dev.off()
			}
			
		}
	}
	cat('Finished!\n')
	
	pmat.csv <- NULL
	for (dist.name in dist.names) {
		temp <- as.matrix(pmat[dist.name, ,  ])
		mode(temp) <- 'character'
		pmat.csv <- rbind(pmat.csv, rbind(Distance=c(dist.name, rep('', ncol(temp) - 1)), temp, ''))
	}
	
	write.csv(pmat.csv, paste0('SiteCorrelationP_', ann, '.csv'))
	return(invisible(pmat))
}

# New: 2017_11_03
perform_site_taxa_correlation_test <- function (data.obj, site.name, sites, subject, 
		taxa.levels = c('Genus'), taxa.names = NULL, dist.func = function (x) {dist(sqrt(x))}, 
		prev=0.1, minp=0.002, medianp=NULL, ann = '', ...) {
	pmat.list <- list()
	for (taxa.level in taxa.levels) {
		cat(taxa.level, '...\n')
		genus <- data.obj$abund.list[[taxa.level]]
		genus <- t(t(genus) / colSums(genus))
		if (is.null(taxa.names)) {
			ind <- rep(TRUE, nrow(genus))
			if (!is.null(prev)) ind <- ind & rowMeans(genus != 0) > prev
			if (!is.null(minp)) ind <- ind & rowMaxs(genus) > minp
			if (!is.null(medianp)) {
				nz.mean <- apply(genus, 1, function(x) median(x[x!=0]))
				ind <- ind & nz.mean > medianp
			}
			genus <- genus[ind, , drop = FALSE]
			gen.names <- rownames(genus)
		} else {
			if (sum(!(taxa.names %in% rownames(genus))) != 0) {
				stop('Could not find the taxa! Please check!\n')
			}
			genus <- genus[taxa.names, , drop = FALSE]
			gen.names <- taxa.names
		}

		# Convert into distance
	    dist.obj <- list()
		for (gen.name in gen.names) {
			dist.obj[[gen.name]] <- as.matrix(dist.func(genus[gen.name, ]))
		}
		
		pmat.list[[taxa.level]] <- perform_site_correlation_test(data.obj, dist.obj, site.name, sites, subject, 
				dist.names = gen.names,  ann = paste(taxa.level, ann, sep = '_'), ...)
		
	}
	return(invisible(pmat.list))
}

# Rev: 2017_02_19 Add hei and wid
# Rev: 2018_01_15 Add qt.outlier=0.097
# Rev: 2018_03_06 position_jitter(h = 0), coord_cartesian
# Rev: 2018_07_16 
generate_taxa_boxplot <- function (data.obj,  grp.name, strata=NULL, scale='P',  taxa.levels=c('Phylum', 'Class', 'Order', 'Family', 'Genus'), 
		taxa.name='All', pseudo.ct=0.5, rm.outlier=TRUE, qt.outlier=0.97, prev=0.1, minp=0.002, ann='All', 
		subject=NULL, l.size=0.5, p.size=2.5, hei=NULL, wid=NULL) {
	# To be completed
	df <- data.obj$meta.dat
	grp <- df[, grp.name]
	if (!is.null(subject)) {
		ID <- df[, subject]
	}
	
	if (is.null(hei)) {
		hei <- 5
	} else {
		hei <- hei
	}
	
	if (is.null(strata)) {
		if (is.null(wid)) {
			wid <- 5
		} else {
			wid <- wid
		}	
	} else {
		if (is.null(wid)) {
			wid <- 5.5
		} else {
			wid <- wid
		}
	}
	
	if (scale == 'P') {
		ylab <- 'Proportion'
	} 
	if (scale == 'logP') {
		ylab <- 'log10(Proportion)'
	}
	if (scale == 'sqrtP') {
		ylab <- 'sqrt(Proportion)'
	}
	if (scale == 'binary') {
		ylab <- 'Count'
	} 
	
	for (LOI in taxa.levels) {
		if (LOI == 'All') {
			if (taxa.name == 'All') stop('Taxa names are not required to be all when taxa level is also all!\n')
			headnames <- NULL
			prop <- NULL
			for (LOI2 in names(data.obj$abund.list)) {
				prop2 <- data.obj$abund.list[[LOI2]]
				taxa.name2 <- taxa.name[taxa.name %in% rownames(prop2)]
				if (length(taxa.name2) != 0) {
					if (scale == 'logP') {
						prop2 <- prop2 + pseudo.ct
					} 
					prop2 <- t(t(prop2) / colSums(prop2))			
					headnames2 <- sapply(strsplit(rownames(prop2), ";"), paste, collapse="\n")
					names(headnames2) <- rownames(prop2)
					prop <- rbind(prop, prop2[taxa.name2, , drop=FALSE])
					headnames <- c(headnames, headnames2)
				}
			}
			
		} else {

			cat(LOI, "\n")
			ct <- data.obj$abund.list[[LOI]]
			prop <- t(t(ct) / colSums(ct))
			ind <- rowMaxs(prop) > minp & rowSums(prop != 0) > prev * ncol(prop)
			
			if (scale == 'logP') {
				ct <- ct + pseudo.ct
				prop <- t(t(ct) / colSums(ct))
			} 
			
			headnames <- sapply(strsplit(rownames(prop), ";"), paste, collapse="\n")
			names(headnames) <- rownames(prop)
			
			if (taxa.name == 'All') {
				prop <- prop[ind, , drop=FALSE]
			} else {
				# Rev: 2018_07_16
				prop <- prop[rownames(prop) %in% taxa.name, , drop=FALSE]
			}
			
			
		}
		
		if (scale == 'logP') {
			prop <- log10(prop)
		}
		
		if (scale == 'sqrtP') {
			prop <- sqrt(prop)
		}
		
		if (scale == 'binary') {
			temp <- prop != 0
			prop[temp] <- 'Presence'
			prop[!temp] <- 'Absence'
		}

		
		pdf(paste("Taxa_Boxplot", LOI, scale, ann, ".pdf", sep="_"), height=hei, width=wid)
		
		if (is.null(strata)) {
			for (taxon in rownames(prop)) {
				taxon.abund <- prop[taxon, ]
				if (scale != 'binary') {
					if (scale == 'P') {
						if (rm.outlier == T) {
							ylims <- c(min(taxon.abund),  min(quantile(taxon.abund, qt.outlier) * 1.25, 1))
						} else {
							ylims <- range(taxon.abund)
						}
						
					} else {
						ylims <- range(taxon.abund)
					}
					
					if (is.null(subject)) {
						df2 <- data.frame(Value=taxon.abund, Group=grp)	
						dodge <- position_dodge(width=0.9)
						obj <- ggplot(df2, aes(x=Group, y=Value, col=Group)) +
								geom_boxplot(position=dodge, outlier.colour = NA, alpha=0.75, lwd=0.35) + 
								geom_jitter(alpha=0.6, size=p.size,  position = position_jitter(w = 0.1, h = 0)) +
								labs(y=ylab, title=headnames[taxon]) 
						if (rm.outlier) {
							obj <- obj + coord_cartesian(ylim = ylims)
						}
						#		ylim(ylims[1], ylims[2]) +
						obj <- obj + theme(legend.position="none")
						print(obj)
					} else {						
						df2 <- data.frame(Value=taxon.abund, Group=grp, subject=ID)	
						dodge <- position_dodge(width=0.9)
						obj <- ggplot(df2, aes(x=Group, y=Value, shape=Group, group=subject)) +
								geom_point(size=p.size) +
								geom_line(size=l.size) +
								labs(y=ylab, title=headnames[taxon]) +
							#	ylim(ylims) +
								theme(legend.position="none")
						print(obj)
						
					}

				} else {
					df2 <- data.frame(Value=taxon.abund, Group=grp)	
					
					obj <- ggplot(df2, aes(x=Group, fill=Value)) +
							geom_bar(width=.5) +
							labs(y=ylab, title=headnames[taxon]) +
							theme(legend.title=element_blank())
					
					print(obj)
				}
				
			}	
		} else {
			for (taxon in rownames(prop)) {
				taxon.abund <- prop[taxon, ]
				if (scale != 'binary') {
					if (scale == 'P') {
						if (rm.outlier == T) {
							ylims <- c(min(taxon.abund),  min(quantile(taxon.abund, qt.outlier) * 1.25, 1))
						} else {
							ylims <- range(taxon.abund)
						}
						
					} else {
						ylims <- range(taxon.abund)
					}
					grp2 <- df[, strata]
					df2 <- data.frame(Value=taxon.abund, Group=grp, Strata=grp2)
					dodge <- position_dodge(width=0.75)
					obj <- ggplot(df2, aes(x=Strata, y=Value, col=Group, fill=Group)) +
							geom_boxplot(fill='white',  position=dodge, outlier.colour = NA, alpha=0.75, width=0.65, lwd=0.35) + 
							geom_point(position=position_jitterdodge(dodge.width=0.75), size=p.size, alpha=0.6) +
							labs(y=ylab, x=strata, title=headnames[taxon])
					if (rm.outlier) {
						obj <- obj + coord_cartesian(ylim = ylims)
					}
					#		ylim(ylims[1], ylims[2]) +
					obj <- obj + theme(legend.title=element_blank())
					print(obj)
				} else {
					grp2 <- df[, strata]
					df2 <- data.frame(Value=taxon.abund, Group=grp, Strata=grp2)
					obj <- ggplot(df2, aes(x=Group, fill=Value)) +
							geom_bar(width=.5) +
							labs(y=ylab, title=headnames[taxon]) +
							facet_wrap(~ Strata) + 
							theme(legend.title=element_blank())
					
					print(obj)
				}
			}
			
		}
		dev.off()
	}
	
}

# Rev: 2017_02_19 Add Pseudo.ct, hei0, wid0; strata2; smooth.method
# Rev: 2018_01_15 Add qt.outlier 
# Rev: 2018_07_16 Add an option to combine strata in the same plot, coord_cartesian
# Rev: 2019_01_03 Selecting taxa before adding pseudo-ct
# Note: if rm.outlier=TRUE, the smooth function only acts on the points in the plot region. May not be desirable
generate_taxa_scatterplot <- function (data.obj,  grp.name, subject=NULL,
		taxa.levels=c('Phylum', 'Class', 'Order', 'Family', 'Genus'), taxa.name='All', prev=0.1, minp=0.002, 
		strata=NULL, strata2=NULL, combine.strata=FALSE, combine.strata2=FALSE, smooth.method='loess', 
		pt.shape=16, pt.alpha=0.5, pt.size=2, subject.pt=FALSE,
		scale='P', pseudo.ct=0.5, is.pvalue=FALSE, rm.outlier=FALSE, qt.outlier=0.97, 
		ann='All', hei=NULL, wid=NULL) {
	# To be completed
	df <- data.obj$meta.dat
	grp <- df[, grp.name]
	
	if(is.null(subject)) {
		ID <- NA
	} else {
		ID <- factor(df[, subject])
	}
	
	if (is.null(hei) | is.null(wid)) {
		hei <- 5
		wid <- 6
		if (scale != 'binary') {
			if (!is.null(strata) & combine.strata == FALSE) {
				wid <- 4 * nlevels(factor(df[, strata]))
			} 
			if (!is.null(strata2) & combine.strata2 == FALSE) {
				hei <- 2.5 * nlevels(factor(df[, strata2]))
			} 
		} else {
			if (!is.null(strata)) {
				wid <- 2.5 * nlevels(factor(df[, strata]))
			} 
			if (!is.null(strata2)) {
				hei <- 2.5 * nlevels(factor(df[, strata2]))
			} 
		}

	}

	if (scale == 'P') {
		ylab <- 'Proportion'
	} 
	if (scale == 'logP') {
		ylab <- 'log10(Proportion)'
	}
	if (scale == 'sqrtP') {
		ylab <- 'sqrt(Proportion)'
	}
	if (scale == 'binary') {
		ylab <- 'Count'
	} 
	
	for (LOI in taxa.levels) {
		if (LOI == 'All') {
			if (taxa.name == 'All') stop('Taxa names need to be specified when taxa level is  all!\n')
			headnames <- NULL
			prop <- NULL
			for (LOI2 in names(data.obj$abund.list)) {
				prop2 <- data.obj$abund.list[[LOI2]]
				taxa.name2 <- taxa.name[taxa.name %in% rownames(prop2)]
				if (length(taxa.name2) != 0) {
					if (scale == 'logP') {
						prop2 <- prop2 + pseudo.ct
					} 
					prop2 <- t(t(prop2) / colSums(prop2))			
					headnames2 <- sapply(strsplit(rownames(prop2), ";"), paste, collapse="\n")
					names(headnames2) <- rownames(prop2)
					prop <- rbind(prop, prop2[taxa.name2, , drop=FALSE])
					headnames <- c(headnames, headnames2)
				}
			}
			
		} else {
			
			cat(LOI, "\n")
			ct <- data.obj$abund.list[[LOI]]
			prop <- t(t(ct) / colSums(ct))
			ind <- rowMaxs(prop) > minp & rowSums(prop != 0) > prev * ncol(prop)
			
			if (scale == 'logP') {
				ct <- ct + pseudo.ct
				prop <- t(t(ct) / colSums(ct))
			} 
			
			headnames <- sapply(strsplit(rownames(prop), ";"), paste, collapse="\n")
			names(headnames) <- rownames(prop)
			
			if (taxa.name == 'All') {
				prop <- prop[ind, , drop=FALSE]
			} else {
				prop <- prop[rownames(prop) %in% taxa.name, , drop=FALSE]
			}
			
		}
		
		if (scale == 'logP') {
			prop <- log10(prop)
		}
		
		if (scale == 'sqrtP') {
			prop <- sqrt(prop)
		}
		if (scale == 'asinsqrtP') {
			prop <- asin(sqrt(prop))
		}
		
		if (scale == 'binary') {
			temp <- prop != 0
			prop[temp] <- 'Presence'
			prop[!temp] <- 'Absence'
		}
		
		
		pdf(paste("Taxa_Scatterplot", LOI, scale, ann, ".pdf", sep="_"), height=hei, width=wid)
		if (is.null(strata)) {
			if (is.pvalue == TRUE) {
				if (scale != 'binary') {
					pvalues <- apply(prop, 1, function (x) {
								formatC(cor.test(as.numeric(x), grp, method='spearman')$p.value, digits=3)
							})
				} else {
					pvalues <- apply(prop, 1, function (x) {
								if (nlevels(factor(x)) > 1) {
									return(formatC(wilcox.test(grp ~ x)$p.value, digits=3))
								} else {
									return('1.0')
								}
								
							})
				}

			} 
			for (taxon in rownames(prop)) {
				taxon.abund <- prop[taxon, ]
				if (scale != 'binary') {
					if (scale == 'P') {
						if (rm.outlier == T) {
							ylims <- c(min(taxon.abund),  min(quantile(taxon.abund, qt.outlier) * 1.25, 1))
						} else {
							ylims <- range(taxon.abund)
						}
					} else {
						ylims <- range(taxon.abund)
					}
					df2 <- data.frame(Value=taxon.abund, Group=grp, ID=ID)	
					dodge <- position_dodge(width=0.9)
					obj <- ggplot(df2, aes(x=Group, y=Value, group=ID)) +
					#		geom_point(size=pt.size, shape=pt.shape, alpha=pt.alpha) +
							geom_smooth(method=smooth.method, aes(group=NA), size=0.75) 
					if (is.pvalue == TRUE) {
						obj <- obj + labs(y=ylab, x=grp.name, title=paste0(headnames[taxon], '(P=', pvalues[taxon], ')'))
					} else {
						obj <- obj + labs(y=ylab, x=grp.name, title=paste0(headnames[taxon]))
					}
					if (rm.outlier) {
						obj <- obj + coord_cartesian(ylim = ylims)
					}
                    obj <- obj + theme(legend.position="none")
					if (!is.null(subject)) {
						if (subject.pt == FALSE) {
							obj <- obj + geom_line(size=0.25, alpha=0.75) 
						}  else {
							obj <- obj + geom_line(size=0.25, alpha=0.75) + geom_point(size=pt.size, shape=pt.shape, alpha=pt.alpha) 
						}
						
					} else {
						obj <- obj + geom_point(size=pt.size, shape=pt.shape, alpha=pt.alpha) 
					}
					print(obj)
				} else {
					df2 <- data.frame(Value=taxon.abund, Group=grp, ID=ID)	
					dodge <- 
							obj <- ggplot(df2, aes(y=Group, x=Value)) +
							geom_boxplot(position=position_dodge(width=0.9), outlier.colour = NA, alpha=0.75) + 
							geom_jitter(alpha=pt.alpha, size=pt.size,  position = position_jitter(w = 0.1, h = 0))
					
					if (is.pvalue == TRUE) {
						obj <- obj + labs(y=grp.name, x='Presence/Absence', title=paste0(headnames[taxon], '(P=', pvalues[taxon], ')'))
					} else {
						obj <- obj + labs(y=grp.name, x='Presence/Absence', title=paste0(headnames[taxon]))
					}
					obj <- obj + theme(legend.position="none")
					
					
					print(obj)
				}
				
			}	
		} else {
			for (taxon in rownames(prop)) {
				taxon.abund <- prop[taxon, ]
				if (scale != 'binary') {
					if (scale == 'P') {
						if (rm.outlier == T) {
							ylims <- c(min(taxon.abund), min(quantile(taxon.abund, qt.outlier) * 1.25, 1))
						} else {
							ylims <- range(taxon.abund)
						}
						
					} else {
						ylims <- range(taxon.abund)
					}
					grp2 <- factor(df[, strata])
					if (!is.null(strata2)) {
						grp3 <- factor(df[, strata2])
					} else {
						grp3 <- grp2
					}
					grp4 <- factor(paste(grp2, grp3))
					
					# VERY bad names with only difference in capital letters, variable names are also confusing
			        # Rev: 2018_07_16 
			
					df2 <- data.frame(Value=taxon.abund, Group=grp, Strata=grp2, Strata2=grp3, Strata3=grp4, ID=ID)
					
					
					if (is.null(strata2)) {
						if (combine.strata == TRUE) {
							obj <- ggplot(df2, aes(x=Group, y=Value, group=ID, col=Strata)) +
						#			geom_point(size=pt.size, shape=pt.shape, alpha=pt.alpha) +
									geom_smooth(method=smooth.method, aes(group=Strata), size=0.75) +
									labs(y=ylab, x=grp.name, title=headnames[taxon])
						} else {
							obj <- ggplot(df2, aes(x=Group, y=Value, group=ID)) +
						#			geom_point(size=pt.size, shape=pt.shape, alpha=pt.alpha) +
									geom_smooth(method=smooth.method, aes(group=NA), size=0.75) +
									labs(y=ylab, x=grp.name, title=headnames[taxon]) + 
									facet_grid(. ~ Strata)
						}

					} else {
						if (combine.strata == TRUE) {
							if (combine.strata2 == TRUE) {
								obj <- ggplot(df2, aes(x=Group, y=Value, group=ID, col=Strata3)) +
							#			geom_point(size=pt.size, shape=pt.shape, alpha=pt.alpha) +
										geom_smooth(method=smooth.method, aes(group=Strata3), size=0.75) +
										labs(y=ylab, x=grp.name, title=headnames[taxon])	
							} else {
								obj <- ggplot(df2, aes(x=Group, y=Value, group=ID, col=Strata)) +
							#			geom_point(size=pt.size, shape=pt.shape, alpha=pt.alpha) +
										geom_smooth(method=smooth.method, aes(group=Strata), size=0.75) +
										labs(y=ylab, x=grp.name, title=headnames[taxon]) +
										facet_grid(Strata2 ~ .)	
							}
						} else {
							if (combine.strata2 == TRUE) {
								warning('Currently, combine.strata2 will be forced to be FALSE if combine.strata=FALSE!\n')
							}
							obj <- ggplot(df2, aes(x=Group, y=Value, group=ID)) +
							#		geom_point(size=pt.size, shape=pt.shape, alpha=pt.alpha) +
									geom_smooth(method=smooth.method, aes(group=NA), size=0.75) +
									labs(y=ylab, x=grp.name, title=headnames[taxon]) + 
									facet_grid(Strata2 ~ Strata)
						}

					}		
					
					if (rm.outlier) {
						obj <- obj + coord_cartesian(ylim = ylims)
					}
					
					obj <- obj + theme(legend.title=element_blank())	
					
					if (!is.null(subject)) {
						if (subject.pt == FALSE) {
							obj <- obj + geom_line(size=0.25, alpha=0.75) 
						}  else {
							obj <- obj + geom_line(size=0.25, alpha=0.75) + geom_point(size=pt.size, shape=pt.shape, alpha=pt.alpha) 
						}
						
					} else {
						obj <- obj + geom_point(size=pt.size, shape=pt.shape, alpha=pt.alpha) 
					}
					print(obj)
					
				} else {				
					grp2 <- df[, strata]
					if (!is.null(strata2)) {
						grp3 <- df[, strata2]
					} else {
						grp3 <- grp2
					}
					df2 <- data.frame(Value=taxon.abund, Group=grp, Strata=grp2, Strata2=grp3)
					dodge <- position_dodge(width=0.9)
							
					if (is.null(strata2)) {
						obj <- ggplot(df2, aes(x=Strata, y=Group, col=Value, fill=Value)) +
								geom_boxplot(fill='white', position=dodge, outlier.colour = NA, alpha=0.75) +
								geom_point(position=position_jitterdodge(dodge.width=0.9), size=pt.size, alpha=pt.alpha) +
								labs(y=grp.name, x=strata, title=headnames[taxon]) 
					}  else {
						obj <- ggplot(df2, aes(x=Strata, y=Group, col=Value, fill=Value)) +
								geom_boxplot(fill='white', position=dodge, outlier.colour = NA, alpha=0.75) +
								geom_point(position=position_jitterdodge(dodge.width=0.9), size=pt.size, alpha=pt.alpha) +
								facet_grid(Strata2 ~ .) +
						        labs(y=grp.name, x=strata, title=headnames[taxon]) 
					}

					print(obj)
				}
			}
			
		}
		dev.off()
	}		
}

# New: 2019_01_03 - e.g., study the correlation between different sampling methods
# Restrict to two-level factor and pairs - labelling outlier has not been completed
generate_taxa_correlationplot <- function(data.obj,  grp.name, subject.name = NULL, strata = NULL, 
		scale='sqrt', pseudo.ct = 0.5, error = 'se', n.bt = 50,  type = c('logP', 'Cor'), p.cutoff = 0.01,
		taxa.levels=c('Species'), taxa.name = 'All', prev = 0.1, minp = 0.002,
		k.outlier = 5, err.wid = 0, err.hei = 0, xlab = 'Grp1.mean', ylab = 'Grp2.mean', 
		wid = 7.5, hei = 6, pt.size = 2,   ann = '') {
	
	type <- match.arg(type)
	# Strata = to color strata
	# We will only focus on pairs
	if (type == 'Cor' & is.null(subject.name)) stop('Correlation measure requires paired samples!\n')
	df <- data.obj$meta.dat
	grp <- factor(df[, grp.name])
	grp2 <- as.numeric(grp)
	ord <- 1:length(grp)
	
	if (!is.null(subject.name)) {
		subject <- factor(df[, subject.name])
		
		# Get one sample for each subject in each group
		ind <- as.vector(tapply(rownames(df), list(grp, subject), function (x) {
							if (length(x) < 1) {
								return(NULL)
							} else {
								sample(x, 1)
							}
						}))
		ind <- ind[!is.na(ind)]
		data.obj <- subset_data(data.obj, ind)
		
		df <- data.obj$meta.dat
		grp <- factor(df[, grp.name])
		subject <- factor(df[, subject.name])
		
		tab <- table(subject)
		ind <- subject %in% names(tab)[tab == 2]
		
		data.obj <- subset_data(data.obj, ind)
		df <- data.obj$meta.dat
		grp <- factor(df[, grp.name])
		subject <- factor(df[, subject.name])
		
		ord <- order(subject)
		df <- df[ord, ]
		grp <- grp[ord]
		grp2 <- as.numeric(grp)
		subject <- subject[ord]
	}
	
	plot.data.list <- list()
	for (i in 1:length(taxa.levels)) {
		LOI <- taxa.levels[i]
		cat(LOI, "\n")
		
		ct <- data.obj$abund.list[[LOI]][, ord]
		
		prop <- t(t(ct) / colSums(ct))
		ind <- rowMaxs(prop) > minp & rowSums(prop!=0) > prev*ncol(prop)
		
		if (scale == 'log') {
			ct <- ct + pseudo.ct
			prop <- t(t(ct / colSums(ct)))
		}
		
		if (taxa.name == 'All') {
			prop <- prop[ind, , drop=FALSE]
		} else {
			# Rev: 2018_07_16
			prop <- prop[rownames(prop) %in% taxa.name, , drop=FALSE]
		}
		
		if (is.null(strata)) {
			
			# Calculate spearman correlation
			df2 <- t(apply(prop, 1, function (x) {
								x1 <- x[grp2 == 1]
								x2 <- x[grp2 == 2]
								if (error == 'se') scale.factor <- 1
								if (error == 'ci') scale.factor <- 1.96	
								se.x1 <- sd(sapply(1:n.bt, function (i) mean(sample(x1, repl=TRUE)))) * scale.factor
								se.x2 <- sd(sapply(1:n.bt, function (i) mean(sample(x2, repl=TRUE)))) * scale.factor
								m.x1 <- mean(x1)
								m.x2 <- mean(x2)
								if (!is.null(subject.name)) {
									cor.val <- cor(x1, x2, method = 'spearman')
									p.val <- wilcox.test(x1, x2, pair = TRUE)$p.value
								} else {
									cor.val <- NA
									p.val <- wilcox.test(x1, x2)$p.value
								}
								xmin <- m.x1 - se.x1
								xmax <- m.x1 + se.x1
								ymin <- m.x2 - se.x2
								ymax <- m.x2 + se.x2
								if (xmin <= 0) xmin <- 0.00001
								if (xmax >= 1) xmax <- 1 - 0.00001
								if (ymin <= 0) ymin <- 0.00001
								if (ymax >= 1) ymax <- 1 - 0.00001
								p.val.b <- as.numeric(p.val <= p.cutoff)
								
								c(m.x1, m.x2, xmin, xmax, ymin, ymax, cor.val, log10(p.val), p.val.b)
							}))
			
			df2 <- data.frame(rownames(prop), df2)
			colnames(df2) <- c('Taxa', 'x', 'y', 'xmin', 'xmax', 'ymin', 'ymax', 'Cor', 'Pval', 'Pval.b')
			df2[, 'Pval.b'] <- factor(ifelse(df2[, 'Pval.b'] == 1, paste0('p <=', p.cutoff), paste0('p >', p.cutoff)),
					levels = c(paste0('p >', p.cutoff), paste0('p <=', p.cutoff)))
			#df2[, 'Pval.b'] <- factor(df2[, 'Pval.b'] )
			#df2 <- df2[!is.na(df2$Cor), ]
			
			obj1 <-  ggplot(data = df2, aes(x = x,y = y)) + 
					geom_errorbar(aes(ymin = ymin, ymax = ymax), width = err.wid, color = 'gray') + 
					geom_errorbarh(aes(xmin = xmin, xmax = xmax), height = err.hei, color = 'gray') 
			if (type == "Cor" & !is.null(subject.name)) {
				obj1 <- obj1 + geom_point(aes(fill = Cor, shape = Pval.b), size = pt.size) 
			} 
			if (type == "logP") {
				obj1 <- obj1 + geom_point(aes(fill = Pval, shape = Pval.b), size = pt.size) 
			}
			obj1 <- obj1 +
					geom_abline(intercept=0, slope=1, color = 'gray') + 
					scale_shape_manual(values = c(21, 24)) +
                    xlab(xlab) +
					ylab(ylab) +
					labs(fill= ifelse(type == 'logP', 'log10(P-val)', 'Correlation'), shape = NULL) 
			
			if (scale == 'sqrt') {
				# obj1 <- obj1 + scale_y_sqrt(breaks=c(0, 0.001, 0.01, 0.05, 0.1, 0.2, 0.3, 0.4, 0.5, 1.0))
				obj1 <- obj1 + scale_y_sqrt(
								breaks = trans_breaks("sqrt", function(x) x^2),
								labels = trans_format("sqrt", math_format(.x^2))) +
						scale_x_sqrt(
								breaks = trans_breaks("sqrt", function(x) x^2),
								labels = trans_format("sqrt", math_format(.x^2)))
			}
			
			# To be revised
			if (scale == 'log') {
				obj1 <- obj1 + scale_y_log10(
								breaks = trans_breaks("log10", function(x) 10^x),
								labels = trans_format("log10", math_format(10^.x))) + 
						scale_x_log10(
								breaks = trans_breaks("log10", function(x) 10^x),
								labels = trans_format("log10", math_format(10^.x)))
			}
			if (scale == 'boxcox') {
				obj1 <- obj1 + scale_y_continuous(breaks=c(0, 0.0001, 0.001, 0.01, 0.05, 0.1, 0.2, 0.3, 0.4, 0.5, 1.0), trans=boxcox_trans(1/3)) +
						scale_x_continuous(breaks=c(0, 0.0001, 0.001, 0.01, 0.05, 0.1, 0.2, 0.3, 0.4, 0.5, 1.0), trans=boxcox_trans(1/3))
			}
			
		} 
		
		plot.data.list[[LOI]] <- df2
		pdf(paste("Taxa_Correlation_", LOI, scale, ann, ".pdf", sep="_"), height=hei, width=wid)		
		print(obj1)
		dev.off()		
	}
	return(invisible(plot.data.list))
}

# Rev: 2018_03_08 add bootstrap standard error (normal approximation)
# Rev: 2019_01_03 handling zeros for log scales
taxa_barplot_aggregate <- function (prop, df, grp.name, strata=NULL, scale='sqrt',  xsize=10, ylab='Proportion', error='ci') {
	
	if (scale == 'log') {
		# Half of the non-zero proportion
		prop <- t(apply(prop, 1, function (x) {
					temp <- min(x[x != 0])
					x[x == 0] <- temp / 2
					x
				}))
	}
	
    grp <- factor(df[, grp.name])
	
	if (is.null(strata)) {
		df2 <- data.frame(Group=grp, t(prop))
		df2 <- melt(df2)
		colnames(df2) <- c('Group', 'Taxa', 'Value')
		
		# Could be revised
		temp1 <- aggregate(Value ~ Group + Taxa, df2, mean)

		if (error == 'se') {
			temp2 <- aggregate(Value ~ Group + Taxa, df2, function(x) {
						#sd(x) / sqrt(length(x))
						sd(sapply(1:50, function(i) mean(sample(x, repl=TRUE))))
					})
		}
		if (error == 'ci') {
			temp2 <- aggregate(Value ~ Group + Taxa, df2, function(x) {
						#sd(x) / sqrt(length(x))
						2 * sd(sapply(1:50, function (i) mean(sample(x, repl=TRUE))))
					})
		}
		
		
		df2 <- cbind(temp1, temp2[, 3])
		colnames(df2) <- c('Group', 'Taxa', 'Mean', 'SE')
		

		limits <- aes(ymax = Mean + SE, ymin = ifelse(Mean - SE > 0, Mean - SE, 0))
		dodge <- position_dodge(width=0.90)
		
		obj1 <- ggplot(df2, aes(x=Taxa, y=Mean, fill=Group)) + 
				geom_bar(position=dodge, stat="identity", alpha=0.75) + 
				geom_bar(position=dodge, stat="identity", alpha=0.75, colour="black", show.legend=FALSE, size=0.25) +
				geom_errorbar(limits, position=dodge, size=0.25, width=0.25) +
				labs(y=paste(ylab), x='') +
				theme(axis.text.x = element_text(angle = 90, hjust = 1, size=xsize)) +
				theme(legend.position="top", legend.title=element_blank())
		
		if (scale == 'sqrt') {
			# obj1 <- obj1 + scale_y_sqrt(breaks=c(0, 0.001, 0.01, 0.05, 0.1, 0.2, 0.3, 0.4, 0.5, 1.0))
			obj1 <- obj1 + scale_y_sqrt(
					breaks = trans_breaks("sqrt", function(x) x^2),
					labels = trans_format("sqrt", math_format(.x^2)))
		}
		
		# To be revised
		if (scale == 'log') {
			obj1 <- obj1 + scale_y_log10(
					breaks = trans_breaks("log10", function(x) 10^x),
					labels = trans_format("log10", math_format(10^.x)))
		}
		if (scale == 'boxcox') {
			obj1 <- obj1 + scale_y_continuous(breaks=c(0, 0.0001, 0.001, 0.01, 0.05, 0.1, 0.2, 0.3, 0.4, 0.5, 1.0), trans=boxcox_trans(1/3))
		}
		
	} else {
		grp2 <- factor(paste(strata, df[, strata]), levels=paste(strata, levels(df[, strata])))
		df2 <- data.frame(Group=grp, Strata=grp2, t(prop))
		df2 <- melt(df2)
		colnames(df2) <- c('Group', 'Strata', 'Taxa', 'Value')
		
		# Could be revised
		temp1 <- aggregate(Value ~ Group + Strata + Taxa, df2, mean)

		if (error == 'se') {
			temp2 <- aggregate(Value ~ Group + Strata +Taxa, df2, function(x) {
						#sd(x) / sqrt(length(x))
						sd(sapply(1:50, function(i) mean(sample(x, repl=TRUE))))
					})
		}
		if (error == 'ci') {
			temp2 <- aggregate(Value ~ Group + Strata + Taxa, df2, function(x) {
						#sd(x) / sqrt(length(x))
						2 * sd(sapply(1:50, function (i) mean(sample(x, repl=TRUE))))
					})
		}
		
		
		df2 <- cbind(temp1, temp2[, 4])
		colnames(df2) <- c('Group', 'Strata', 'Taxa', 'Mean', 'SE')
		
		limits <- aes(ymax = Mean + SE, ymin = ifelse(Mean - SE > 0, Mean - SE, 0))
		dodge <- position_dodge(width=0.90)
		
		obj1 <- ggplot(df2, aes(x=Taxa, y=Mean, fill=Group)) + 
				geom_bar(position=dodge, stat="identity", alpha=0.75) + 
				geom_bar(position=dodge, stat="identity", alpha=0.75, colour="black", show.legend=FALSE, size=0.25) +
				geom_errorbar(limits, position=dodge, size=0.25, width=0.25) +
				facet_wrap(~Strata, ncol=1) +
				labs(y=paste(ylab), x='') +
				theme(axis.text.x = element_text(angle = 90, hjust = 1, size=xsize)) +
				theme(legend.position="top", legend.title=element_blank())
		if (scale == 'sqrt') {
			# obj1 <- obj1 + scale_y_sqrt(breaks=c(0, 0.001, 0.01, 0.05, 0.1, 0.2, 0.3, 0.4, 0.5, 1.0))
			obj1 <- obj1 + scale_y_sqrt(
					breaks = trans_breaks("sqrt", function(x) x^2),
					labels = trans_format("sqrt", math_format(.x^2)))
		}
		if (scale == 'log') {
			obj1 <- obj1 + scale_y_log10(
					breaks = trans_breaks("log10", function(x) 10^x),
					labels = trans_format("log10", math_format(10^.x)))
		}
		if (scale == 'boxcox') {
			obj1 <- obj1 + scale_y_continuous(breaks=c(0, 0.0001, 0.001, 0.01, 0.05, 0.1, 0.2, 0.3, 0.4, 0.5, 1.0), trans=boxcox_trans(1/3))
		}
		
	}
	return(obj1)
	
}

# Rev: 2018_03_08 Add geom_point and jsize
# Rev: 2019_01_03 handling zeros for log scales
taxa_boxplot_aggregate <- function (prop, df, grp.name, strata=NULL, scale='none', xsize=10, jsize=NULL, ylab='Proportion') {
	
	
	grp <- factor(df[, grp.name])
	
	if (scale == 'log') {
		# Half of the non-zero proportion
		prop <- t(apply(prop, 1, function (x) {
							temp <- min(x[x != 0])
							x[x == 0] <- temp / 2
							x
						}))
	}
	
	if (is.null(jsize)) {
		nT <- nrow(prop) 
		jsize <- 2 / (nT %/% 20 + 1)
	}

	if (is.null(strata)) {
		df2 <- data.frame(Group=grp, t(prop))
		df2 <- melt(df2)
		colnames(df2) <- c('Group', 'Taxa', 'Value')
		
		dodge <- position_dodge(width=0.88)
		
		obj1 <- ggplot(df2, aes(x=Taxa, y=Value, fill=Group)) + 
				geom_boxplot(position=dodge, alpha = ifelse(jsize == 0, 0.75, 0.75), outlier.alpha=ifelse(jsize == 0, 0.5, 0),  lwd=0.25, fatten=1)
		if (jsize != 0) {
			obj1 <- obj1 + geom_point(position=position_jitterdodge(dodge.width=0.88), size=jsize, alpha=0.3)
		}
		obj1 <- obj1 +
				labs(y=paste(ylab), x='') +
				theme(axis.text.x = element_text(angle = 90, hjust = 1, size=xsize)) +
				theme(legend.position="top", legend.title=element_blank())
		if (scale == 'sqrt') {
			# obj1 <- obj1 + scale_y_sqrt(breaks=c(0, 0.001, 0.01, 0.05, 0.1, 0.2, 0.3, 0.4, 0.5, 1.0))
			obj1 <- obj1 + scale_y_sqrt(
					breaks = trans_breaks("sqrt", function(x) x^2),
					labels = trans_format("sqrt", math_format(.x^2)))
		}
		if (scale == 'log') {
			obj1 <- obj1 + scale_y_log10(
					breaks = trans_breaks("log10", function(x) 10^x),
					labels = trans_format("log10", math_format(10^.x)))
		}
		if (scale == 'boxcox') {
			obj1 <- obj1 + scale_y_continuous(breaks=c(0, 0.0001, 0.001, 0.01, 0.05, 0.1, 0.2, 0.3, 0.4, 0.5, 1.0), trans=boxcox_trans(1/3))
		}
		
	} else {
		grp2 <- factor(paste(strata, df[, strata]), levels=paste(strata, levels(df[, strata])))
		df2 <- data.frame(Group=grp, Strata=grp2, t(prop))
		df2 <- melt(df2)
		colnames(df2) <- c('Group', 'Strata', 'Taxa', 'Value')
		
		dodge <- position_dodge(width=0.88)
		
		obj1 <- ggplot(df2, aes(x=Taxa, y=Value, fill=Group)) + 
				geom_boxplot(position=dodge, alpha = ifelse(jsize == 0, 0.75, 0.75),  outlier.alpha=ifelse(jsize == 0, 0.5, 0),  lwd=0.25, fatten=1) 
		if (jsize != 0) {
			obj1 <- obj1 + geom_point(position=position_jitterdodge(dodge.width=0.88), size=jsize, alpha=0.2)
		}
		obj1 <- obj1 +
			#	geom_point(position=position_jitterdodge(dodge.width=0.95), size=jsize, alpha=0.3) +
				facet_wrap(~Strata, ncol=1) +
				labs(y=paste(ylab), x='') +
				theme(axis.text.x = element_text(angle = 90, hjust = 1, size=xsize)) +
				theme(legend.position="top", legend.title=element_blank())
		if (scale == 'sqrt') {
			# obj1 <- obj1 + scale_y_sqrt(breaks=c(0, 0.001, 0.01, 0.05, 0.1, 0.2, 0.3, 0.4, 0.5, 1.0))
			obj1 <- obj1 + scale_y_sqrt(
					breaks = trans_breaks("sqrt", function(x) x^2),
					labels = trans_format("sqrt", math_format(.x^2)))
		}
		# To be revised
		if (scale == 'log') {
			obj1 <- obj1 + scale_y_log10(
					breaks = trans_breaks("log10", function(x) 10^x),
					labels = trans_format("log10", math_format(10^.x)))
		}
		if (scale == 'boxcox') {
			obj1 <- obj1 + scale_y_continuous(breaks=c(0, 0.0001, 0.001, 0.01, 0.05, 0.1, 0.2, 0.3, 0.4, 0.5, 1.0), trans=boxcox_trans(1/3))
		}
		
	}
	return(obj1)
	
}

generate_taxa_biplot <- function (data.obj, taxa, trans='sqrt', grp.name, ann='', ...) {
	
    grp <- data.obj$meta.dat[, grp.name]

	prop <- NULL
	for (LOI2 in names(data.obj$abund.list)) {
		ct <- data.obj$abund.list[[LOI2]]
		ct <- ct + 1
		prop0 <- t(t(ct) / colSums(ct))
		prop <- rbind(prop, prop0[intersect(rownames(prop0), taxa), , drop=FALSE])	
	}
	colnames(prop) <- colnames(prop0)
	if (nrow(prop) != length(taxa)) {
		warnings('Some taxa not found in abundance lists! Please check the names!\n')
	}
	
	if (trans == 'normal') 	prop <- t(apply(prop, 1, function(x) qqnorm(x, plot=F)$x))
	if (trans == 'log') prop <- log(prop)
	if (trans == 'sqrt') prop <- sqrt(prop)
	if (trans == 'rank') prop <- t(apply(prop, 1, rank))
	
	wine.pca <- prcomp(t(prop), scale. = TRUE)
	g <- ggbiplot(wine.pca, obs.scale = 1, var.scale = 1, 
			groups = grp, ellipse = TRUE, circle = FALSE, ...) 
	g <- g + scale_color_discrete(name = '') + theme_bw()
	g <- g + theme(legend.direction = 'horizontal', legend.position = 'top') 
	pdf(paste0("Taxa_Biplot_", ann, ".pdf"), height=6, width=6)
	print(g)
	dev.off()
}

# Rev: 2017_05_19: new formula for width
#      Add presence and absence bar
# Rev: 2018_07_16
generate_taxa_barplot_aggregate <- function (data.obj,  grp.name, strata=NULL, scale='sqrt', pseudo.ct = 0.5,
		taxa.levels=c('Phylum', 'Class', 'Order', 'Family', 'Genus'),
		taxa.name='All',  prev=0.1, minp=0.002, ann='All', wids=NULL, heis=NULL, xsize=c(14, 12, 10, 9, 8)) {
	# To be completed
	df <- data.obj$meta.dat
	grp <- df[, grp.name]
	
	for (i in 1:length(taxa.levels)) {
		LOI <- taxa.levels[i]
		cat(LOI, "\n")
		
		ct <- data.obj$abund.list[[LOI]]
		prop <- t(t(ct / colSums(ct)))
		ind <- rowMaxs(prop) > minp & rowSums(prop!=0) > prev*ncol(prop)
		
		if (scale == 'log') {
			ct <- ct + pseudo.ct
			prop <- t(t(ct) / colSums(ct))
		}
		
		if (taxa.name == 'All') {
			prop <- prop[ind, , drop=FALSE]
		} else {
			# Rev: 2018_07_16
			prop <- prop[rownames(prop) %in% taxa.name, , drop=FALSE]
		}
			
		# decreasing
		prop <- prop[rev(order(rowMeans(prop))), ]
		
		if (is.null(wids) | is.null(heis)) {
			wid <- 7 * ifelse(nrow(prop) / 30 < 1, 1, nrow(prop) / 30)
			wid <- sqrt(nlevels(grp) / 2) * wid
	        hei <- 7
		} else {
			wid <- wids[i]
			hei <- heis[i]
		}
			
		pdf(paste("Taxa_Barplot_Aggregate", LOI, scale, ann, ".pdf", sep="_"), height=hei, width=wid)		
		obj1 <- taxa_barplot_aggregate(prop, df, grp.name, strata, scale, xsize[i]) 
		print(obj1)
		dev.off()		
	}
}

# Rev: 2017_05_19: new formula for width
# Rev: 2018_03_08  jsize
# Rev: 2018_07_16 
generate_taxa_boxplot_aggregate <- function (data.obj,  grp.name, strata=NULL, scale='sqrt', pseudo.ct = 0.5,
		taxa.levels=c('Phylum', 'Class', 'Order', 'Family', 'Genus'),
		taxa.name='All',  prev=0.1, minp=0.002, ann='All', wids=NULL, heis=NULL, xsize=c(14, 12, 10, 9, 8, 6, 4), jsize = 0) {
	# To be completed
	df <- data.obj$meta.dat
	grp <- factor(df[, grp.name])
	
	for (i in 1:length(taxa.levels)) {
		LOI <- taxa.levels[i]
		cat(LOI, "\n")
		
		ct <- data.obj$abund.list[[LOI]]
		prop <- t(t(ct) / colSums(ct))
		ind <- rowMaxs(prop) > minp & rowSums(prop!=0) > prev*ncol(prop)
		
		if (scale == 'log') {
			ct <- ct + pseudo.ct
			prop <- t(t(ct / colSums(ct)))
		}
		
		if (taxa.name == 'All') {
			prop <- prop[ind, , drop=FALSE]
		} else {
			# Rev: 2018_07_16
			prop <- prop[rownames(prop) %in% taxa.name, , drop=FALSE]
		}
		
		# decreasing
		prop <- prop[rev(order(rowMeans(prop))), ]
		
		if (is.null(wids) | is.null(heis)) {
			wid <- 7 * ifelse(nrow(prop) / 30 < 1, 1, nrow(prop) / 30)
			wid <- sqrt(nlevels(grp) / 2) * wid
		    
			hei <- 7
		} else {
			wid <- wids[i]
			hei <- heis[i]
		}
		
		pdf(paste("Taxa_Boxplot_Aggregate", LOI, scale, ann, ".pdf", sep="_"), height=hei, width=wid)		
		obj1 <- taxa_boxplot_aggregate (prop, df, grp.name, strata, scale, xsize[i], jsize=jsize) 
		print(obj1)
		dev.off()		
	}
}

# Add combined barplot with error bar and presence/absence bar (currently presence/absence bar is in generate_taxa_boxplot
# Rev: 2018_01_15 Add qt.outlier=0.97
# Rev: 2018_03_06 coord_cartesian
# Rev: 2018_05_31 Add x axis label control
# Rev: 2018_07_16
# Rev: 2019_01_03 add sqrtP and selecting taxa before adding pseudo-count
generate_taxa_barplot <- function (data.obj,  grp.name, strata=NULL, scale='P', pseudo.ct = 0.5,
		taxa.levels=c('Phylum', 'Class', 'Order', 'Family', 'Genus'),
		taxa.name='All', rm.outlier=T, qt.outlier=0.97, prev=0.1, minp=0.002, ann='All', x.axis.lab=FALSE, x.axis.size = 6) {
	# To be completed
	df <- data.obj$meta.dat
	grp <- factor(df[, grp.name])
	
	for (LOI in taxa.levels) {
		if (LOI == 'All') {
			if (taxa.name == 'All') stop('Taxa names are not allowed to be all when taxa level is also all!\n')
			headnames <- NULL
			prop <- NULL
			for (LOI2 in names(data.obj$abund.list)) {
				prop2 <- data.obj$abund.list[[LOI2]]
				taxa.name2 <- taxa.name[taxa.name %in% rownames(prop2)]
				if (length(taxa.name2) != 0) {
					if (scale == 'logP') {
						prop2 <- prop2 + pseudo.ct
					} 
					prop2 <- t(t(prop2) / colSums(prop2))			
					headnames2 <- sapply(strsplit(rownames(prop2), ";"), paste, collapse="\n")
					names(headnames2) <- rownames(prop2)
					prop <- rbind(prop, prop2[taxa.name2, , drop=FALSE])
					headnames <- c(headnames, headnames2)
				}
			}
			
		} else {
			cat(LOI, "\n")
			ct <- data.obj$abund.list[[LOI]]
			prop <- t(t(ct) / colSums(ct))
			ind <- rowMaxs(prop) > minp & rowSums(prop != 0) > prev * ncol(prop)
			
			if (scale == 'logP') {
				ct <- ct + pseudo.ct
				prop <- t(t(ct) / colSums(ct))
			} 
			
			headnames <- sapply(strsplit(rownames(prop), ";"), paste, collapse="\n")
			names(headnames) <- rownames(prop)
			
			if (taxa.name == 'All') {
				prop <- prop[ind, , drop=FALSE]
			} else {
				# Rev: 2018_07_16
				prop <- prop[rownames(prop) %in% taxa.name, , drop=FALSE]
			}
			
		}

		if (scale == 'logP') {
			prop <- log10(prop)
		}
		
		if (scale == 'sqrtP') {
			prop <- sqrt(prop)
		}
		
		
		hei <- 5
		if (is.null(strata)) {
			wid <- 5
		} else {
			wid <- 4 * nlevels(df[, strata])
		}
		
		if (scale == 'P') {
			ylab <- 'Proportion'
		} 
		
		if (scale == 'logP') {
			ylab <- 'log10(Proportion)'
		}
		
		if (scale == 'sqrtP') {
			ylab <- 'sqrt(Proportion)'
		}
		
		pdf(paste("Taxa_Barplot", LOI, scale, ann, ".pdf", sep="_"), height=hei, width=wid)
		if (is.null(strata)) {
			for (taxon in rownames(prop)) {
				taxon.abund <- prop[taxon, ]
				taxon.abund2 <- taxon.abund
				if (scale == 'P') {
					if (rm.outlier == T) {
						ylims <- c(0, quantile(taxon.abund, qt.outlier) * 1.25)
						taxon.abund[taxon.abund > quantile(taxon.abund, qt.outlier) * 1.25] <- quantile(taxon.abund, qt.outlier) * 1.25
					} else {
						ylims <- c(0, max(taxon.abund))
					}
					
				} else {
					ylims <- range(taxon.abund)
				}
				# df2 <- data.frame(x=factor(1:length(taxon.abund)), Value=taxon.abund, Group=grp)
		        df2 <- data.frame(x=colnames(prop), Value=taxon.abund, Group=grp)
				rownames(df2) <- colnames(prop)
				
				dodge <- position_dodge(width=0.99)
				obj <- ggplot(df2, aes(x=x, y=Value, fill=Group)) +
						geom_bar(position=dodge, stat='identity', alpha=0.75) + 
						facet_grid(. ~ Group, scales='free_x', space="free") +
						labs(y=ylab, title=headnames[taxon])
				
				if (rm.outlier) {
					obj <- obj + coord_cartesian(ylim = ylims)
				}
				
				if (!x.axis.lab) {
					obj <- obj + theme(axis.ticks.x=element_blank(), axis.text.x = element_blank()) 
				} else {
					obj <- obj + theme(axis.text.x = element_text(size = x.axis.size, angle = 90, vjust = 0.5, hjust=1))
				}
				
				obj <- obj  + 
						xlab('') +

						theme(legend.position="none")
				mean_df <- data.frame(Group=levels(grp), yint = tapply(taxon.abund2, grp, mean))
				obj <- obj + geom_hline(data = mean_df, aes(yintercept = yint))		
				mean_df <- data.frame(Group=levels(grp), yint = tapply(taxon.abund2, grp, median))
				obj <- obj + geom_hline(data = mean_df, aes(yintercept = yint), linetype=2)
				
				print(obj)
			}	
		} else {
			for (taxon in rownames(prop)) {
				taxon.abund <- prop[taxon, ]
				taxon.abund2 <- taxon.abund
				if (scale == 'P') {
					if (rm.outlier == T) {
						ylims <- c(0, quantile(taxon.abund, qt.outlier) * 1.25)
						taxon.abund[taxon.abund > quantile(taxon.abund, qt.outlier) * 1.25] <- quantile(taxon.abund, qt.outlier) * 1.25
					} else {
						ylims <- c(0, max(taxon.abund))
					}
					
				} else {
					ylims <- range(taxon.abund)
				}
				
				grp2 <- df[, strata]
				obj.list <- list()
				for (level in levels(grp2)) {
					ind <- grp2 %in% level
					# df2 <- data.frame(x=factor(1:length(taxon.abund[ind])), Value=taxon.abund[ind], Group=grp[ind])	
			        df2 <- data.frame(x=colnames(prop)[ind], Value=taxon.abund[ind], Group=grp[ind])	
					rownames(df2) <- colnames(prop)[ind]
					
					dodge <- position_dodge(width=0.99)
					obj0 <- ggplot(df2, aes(x=x, y=Value, fill=Group)) +
							geom_bar(position=dodge, stat='identity', alpha=0.75) + 
							facet_grid(. ~ Group, scales='free_x', space="free") +
							labs(y=ylab, title=headnames[taxon])
					
					if (rm.outlier) {
						obj0 <- obj0 + coord_cartesian(ylim = ylims)
					}
					
					if (!x.axis.lab) {
						obj0 <- obj0 + theme(axis.ticks.x=element_blank(), axis.text.x = element_blank()) 
					} else {
						obj0 <- obj0 + theme(axis.text.x = element_text(size = x.axis.size, angle = 90, vjust = 0.5, hjust=1))
					}
					
					
					obj0 <- obj0  + 
							xlab(paste(strata, level)) +
							theme(legend.position="none")
					mean_df <- data.frame(Group=levels(grp[ind]), yint = tapply(taxon.abund2[ind], grp[ind], mean))
					obj0 <- obj0 + geom_hline(data = mean_df, aes(yintercept = yint))		
					mean_df <- data.frame(Group=levels(grp[ind]), yint = tapply(taxon.abund2[ind], grp[ind], median))
					obj0 <- obj0 + geom_hline(data = mean_df, aes(yintercept = yint), linetype=2)
					obj.list[[level]] <- obj0		
				}
				multiplot(plotlist=obj.list, cols=nlevels(grp2))
			}	
			
		}
		dev.off()
	}		
}


twopart.test <- function(x1, x2, zero.p=0.2) {
	
	n1 <- length(x1)
	n2 <- length(x2)
	p1 <- mean(x1 != 0)
	p2 <- mean(x2 != 0)
	m1 <- sum(x1 != 0)
	m2 <- sum(x2 != 0)
	p12 <- (m1 + m2) / (n1 + n2)
	q12 <- 1 - p12
	
	if (q12 >= zero.p) {
		Z <- (abs(p1 - p2) - (1/(2*n1) + 1/(2*n2))) / sqrt(p12 * q12 * (1/n1 + 1/n2))
		x1 <- x1[x1!=0]
		x2 <- x2[x2!=0]
		R1 <- sum(rank(c(x1, x2))[1:length(x1)])
		ti <- as.vector(table(c(x1, x2)))
		W <- (abs(R1 - m1*(m1+m2+1)/2) - 1/2) / sqrt((m1*m2/12)*(m1+m2+1-sum(ti*(ti^2-1))/(m1+m2)/(m1+m2-1)))
		X2 <- Z^2 + W^2
		res <- list()
		res$stat <- X2
		res$p.value <- 1 - pchisq(X2, 2)
		res$Z <- Z
		res$W <- W
		res$test <- 'TwoPart'
	} else {
		res <- wilcox.test(x1, x2)
		res$test <- 'Wilcox'
	}
	res
}

getPermuteMatrix <- function (perm, N, strata = NULL) 
{
	if (length(perm) == 1) {
		perm <- how(nperm = perm)
	}
	if (!missing(strata) && !is.null(strata)) {
		if (inherits(perm, "how") && is.null(getBlocks(perm))) 
			setBlocks(perm) <- strata
	}
	if (inherits(perm, "how")) 
		perm <- shuffleSet(N, control = perm)
	if (is.null(attr(perm, "control"))) 
		attr(perm, "control") <- structure(list(within = list(type = "supplied matrix"), 
						nperm = nrow(perm)), class = "how")
	perm
}

perm_fdr_adj <- function (F0, Fp) {
	ord <- order(F0, decreasing = T)
	F0 <- F0[ord]
	perm.no <- ncol(Fp)
	Fp <- as.vector(Fp)
	Fp <- Fp[!is.na(Fp)]
	Fp <- sort(c(Fp, F0), decreasing = F)
	n <- length(Fp)
	m <- length(F0)
	FPN <- (n + 1) - match(F0, Fp) - 1:m
	p.adj.fdr <- FPN / perm.no / (1:m)
#		p.adj.fdr <- sapply(F0, function(x) sum(Fp >= 
#									x, na.rm=TRUE) / perm.no)/(1:length(F0))
	p.adj.fdr <- pmin(1, rev(cummin(rev(p.adj.fdr))))[order(ord)]
}

perm_fwer_adj <- function (F0, Fp) {
	ord <- order(F0, decreasing = T)
	F0 <- F0[ord]
	col.max <- colMaxs(Fp, na.rm=TRUE)
	p.adj.fwer <- sapply(F0, function(x) mean(col.max >= x))[order(ord)]
}

# New: 2018_06_20
# Westfall young
perm_fwer_adj2 <- function (F0, Fp) {
	ord <- order(F0, decreasing = T)
	m <- length(F0)
	F0 <- F0[ord]
	Fp <- Fp[ord, , drop=FALSE]
	col.max <- Fp[m, ]
	p.adj.fwer <- sapply(m:1, function(i) {
				x <- F0[i]
				y <- Fp[i, ]
				col.max <<- ifelse(y > col.max, y, col.max)
				mean(col.max >= x)
			})
	p.adj.fwer <- rev(p.adj.fwer)
	p.adj.fwer <- pmin(1, rev(cummin(rev(p.adj.fwer))))[order(ord)]
}

# Need to be further comprehensively tested
# a. Speed up, finished!
# b. Permutation method ï¼ˆresponse, covariate or residual permutation), residual will be default!
# c. Revise - add permutation stratified by subject, finished!
# Rev: 2017_02_02 permutation-based FDR control
# Rev: 2017_02_13 Add LMM-based permutation for block.perm=TRUE (type I error is controled, but power study hasn't been comprehensively studied)
# Rev: 2017_02_24 allow 'adj.name' to contain multiple covariates
# Still need to address NA's, currently simply remove NA's
# Rev: 2018_03_18 add winsorization support for permutation test - Only one side winsorization
# Rev: 2018_03_18 add effect size (partial R2) and Direction
# Rev: 2018_06_20 add Westfall young FWER adjustment
permute_differential_analysis <- function (meta.dat, prop, grp.name, adj.name=NULL, strata=NULL, 
		block.perm=FALSE, sqrt.trans=TRUE, resid.perm=TRUE, perm.no=999, winsor=FALSE, winsor.qt = 0.97, trace = FALSE) {
	# Square root transformation
	# User should take care of the normalization, transformation and addressing outliers
	opt.old <- options('contrasts')
	options(contrasts = c("contr.treatment", "contr.poly"))
	meta.dat <- droplevels(meta.dat)
	if (sqrt.trans) {
		Y <- sqrt(prop)
	} else {
		Y <- prop
	}
	row.names <- rownames(Y)
	
	if (winsor == TRUE) {
		# Only one side winsorization - be careful for different type of transformation
		Y <- t(apply(Y, 1, function (x) {
					cutoff <- quantile(x, winsor.qt)
					x[x >= cutoff] <- cutoff
					x
				}))
	}
	
	if (!is.null(strata)) {
		strata <- factor(strata)
	}
	
	# Prepare model matrix
	n <- ncol(prop)
	I <- diag(n)
	if (is.null(adj.name)) {
		M0 <- model.matrix(~ 1, meta.dat)
	} else {
		df0 <- meta.dat[, c(adj.name), drop=F]
		M0 <- model.matrix( ~., df0)
	}
	
#	P0 <- M0 %*% solve(t(M0) %*% M0) %*% t(M0)
	
	df1 <- meta.dat[, c(adj.name, grp.name), drop=F]
	M1 <- model.matrix( ~., df1)
	
	# Make sure it is contr.tretament
	M2 <- model.matrix (~.,  meta.dat[, c(grp.name), drop=F])
	
	# Remove the effect of confounder
	M2 <- as.matrix(resid(lm(M2[, -1] ~ M0 - 1)))
	
	# QR decompostion
	qrX0 <- qr(M0, tol = 1e-07)
	Q0 <- qr.Q(qrX0)
	Q0 <- Q0[, 1:qrX0$rank, drop=FALSE]
	
	qrX1 <- qr(M1, tol = 1e-07)
	Q1 <- qr.Q(qrX1)
	Q1 <- Q1[, 1:qrX1$rank, drop=FALSE]
	
	# Got residual
	if (resid.perm) {
		if (!block.perm) {
			# Permute the residual
			if (is.null(adj.name)) {
				Y <- t(resid(lm(as.formula(paste('t(Y) ~ 1')), meta.dat)))
			} else {
				Y <- t(resid(lm(as.formula(paste('t(Y) ~ ', paste(adj.name, collapse='+'))), meta.dat)))
			}
			
		} else {
			
			if (is.null(strata)) {
				stop('Block permutation requires strata!\n')
			} else {
				Y.r <- matrix(NA, nrow(Y), nlevels(strata))
				Y.e <- Y
				if(trace) cat('Fitting linear mixed effects model ...\n')
				for (j in 1:nrow(Y)) {
					# Linear mixed effects model
					yy <- Y[j, ]
					meta.dat$yy <- yy
					meta.dat$strata <- strata
					if (is.null(adj.name)) {
						# obj <- lme(as.formula(paste('yy ~ 1')), random =~ 1 |  strata, data=meta.dat, method='ML')
					     obj <- lmer(as.formula(paste('yy ~ 1 + (1 | strata)')),  data=meta.dat, REML=FALSE)
						# The order is the same as the levels
						# Y.r[j, ] <- random.effects(obj)[, 1]
					    Y.r[j, ] <- random.effects(obj)[[1]][, 1]
						Y.e[j, ] <- resid(obj)
					} else {
						# obj <- lme(as.formula(paste('yy ~ ', paste(adj.name, collapse='+'))), random =~ 1 |  strata, data=meta.dat, method='ML')
					    obj <- lmer(as.formula(paste('yy ~ ', paste(adj.name, collapse='+'), ' + (1 | strata)')),data=meta.dat, REML=FALSE)
						# Y.r[j, ] <- random.effects(obj)[, 1]
						Y.r[j, ] <- random.effects(obj)[[1]][, 1]
						Y.e[j, ] <- resid(obj)
					}
				}
				Y <- Y.r[, as.numeric(strata)] + Y.e
	#			Y <- Y - rowMeans(Y)
	#		    Y <- Y.e
			}
		}
	}
	
	TSS <- rowSums(Y^2)
	MSS1 <- rowSums((Y %*% Q1)^2)
	MSS0 <- rowSums((Y %*% Q0)^2)  # Not necessary, it's zero
	F0 <- (MSS1 - MSS0) /  (TSS - MSS1) 
	
	R2 <- (MSS1 - MSS0) / (TSS - MSS0)
	coefficients <- t(solve(t(M2) %*% M2) %*% t(M2) %*% t(Y))
	
#	P1 <- M1 %*% solve(t(M1) %*% M1) %*% t(M1)
#	F0 <- diag(Y %*% (P1 - P0) %*% t(Y)) / diag(Y %*% (I - P1) %*% t(Y))
#	df3 <- df1
	
	if (block.perm == FALSE) {
		perm.ind <- vegan:::getPermuteMatrix(perm.no, n, strata = strata)
		perm.no <- nrow(perm.ind)
	}
	
	if(trace) cat('Permutation test ....\n')
	Fp <- sapply(1:perm.no, function(i) {
				if (i %% 100 == 0)  if(trace) cat('.')
				if (block.perm == FALSE) {
					Yp <- Y[, perm.ind[i, ]]
				} else {
					# Double permutation
					strata.p <- factor(strata, levels=sample(levels(strata)))
				    Yp <- Y.r[, as.numeric(strata.p)] + Y.e[, sample(ncol(Y))]
#				    Yp <- Y.e[, sample(ncol(Y))]
#					Yp <- Yp - rowMeans(Yp)
				}
				
#				df3[, grp.name] <- sample(df1[, grp.name])
#				M1 <- model.matrix( ~., df3)
#				P1 <- M1 %*% solve(t(M1) %*% M1) %*% t(M1)
				MSS1p <- rowSums((Yp %*% Q1)^2)
				MSS0p <- rowSums((Yp %*% Q0)^2)    
			    if (block.perm == FALSE) {
					TSSp <- TSS
				} else {
					TSSp <- rowSums(Yp^2)
				}
				(MSS1p - MSS0p) /  (TSSp - MSS1p) 
			})
	
	
	if (mean(is.na(F0)) >= 0.1) {
		warning('More than 10% observed F stats have NA! Please check! \n')
	}
	
	if (mean(is.na(Fp)) >= 0.1) {
		warning('More than 10% permuted F stats have NA! Please check! \n')
	}
	
	na.ind <- is.na(F0)
	F0 <- F0[!na.ind]
	Fp <- Fp[!na.ind, ]
	
	p.raw <- cbind(Fp >= F0, 1)
	p.raw <- rowMeans(p.raw)
#	p.raw[is.na(p.raw)] <- 1   
	
	p.adj.fdr <- perm_fdr_adj(F0, Fp)
	p.adj.fwer <- perm_fwer_adj2(F0, Fp)
	
	# Pad back the NA values
	pad <- function (vec, ind) {
		vec0 <- numeric(length(ind))
		vec0[!ind] <- vec
		vec0[ind] <- NA
		vec0
	}
	
	options(contrasts=opt.old$contrast)
	
	F0 <- pad(F0, na.ind)
	p.raw <- pad(p.raw, na.ind)
	p.adj.fdr <- pad(p.adj.fdr, na.ind)
	p.adj.fwer <- pad(p.adj.fwer, na.ind)
	
	names(F0) <- names(p.raw) <- names(p.adj.fdr) <- names(p.adj.fwer) <- row.names
	return(list(F.stat=F0, R2=R2, coefficients=coefficients, p.raw=p.raw, p.adj.fdr=p.adj.fdr, p.adj.fwer=p.adj.fwer))
#	return(p.raw)
}
#


# New: 2017_08_17 Add a new variant of PERMANOVA with matrix decomposition
# Partially validated
permanova2 <- function (meta.dat, D, grp.name, adj.name=NULL, strata=NULL, 
		block.perm=FALSE, resid.perm=TRUE, perm.no=999, eig = c('All', 'Positive', 'Top'), var.exp = 0.90) {
	
	eig <- match.arg(eig)
	# Square root transformation
	# User should take care of the normalization, transformation and addressing outliers

	D <- -as.matrix(D)^2 / 2
	n <- nrow(D)
	G <- mean(D) + D - rowMeans(D) - matrix(rep(1, n), ncol=1) %*% colMeans(D)
	eig.obj <- eigen(G)
	if (eig == 'All') {
		Y <- eig.obj$vectors
		lambda <- eig.obj$values
		ind <- abs(lambda) > 1e-6
		lambda <- lambda[ind]
		Y <- Y[, ind, drop = FALSE]
	}
	
	if (eig == 'Positive') {
		lambda <- eig.obj$values
		ind <- lambda > 1e-6
		lambda <- lambda[ind]
		Y <- Y[, ind, drop = FALSE]
	}

	if (eig == 'Top') {
		Y <- eig.obj$vectors
		lambda <- eig.obj$values
		ind <- lambda > 1e-6
		lambda <- lambda[ind]
		Y <- Y[, ind, drop = FALSE]
	
		ind <- 1:(which(cumsum(lambda / sum(lambda)) > var.exp)[1])
		lambda <- lambda[ind]
		Y <- Y[, ind, drop = FALSE]
	}
	
	
    Y <- t(Y)
	
	if (!is.null(strata)) {
		strata <- factor(strata)
	}
	
	# Prepare model matrix
	n <- ncol(Y)
	I <- diag(n)
	if (is.null(adj.name)) {
		M0 <- model.matrix(~ 1, meta.dat)
	} else {
		df0 <- meta.dat[, c(adj.name), drop=F]
		M0 <- model.matrix( ~., df0)
	}
	
#	P0 <- M0 %*% solve(t(M0) %*% M0) %*% t(M0)
	
	df1 <- meta.dat[, c(adj.name, grp.name), drop=F]
	M1 <- model.matrix( ~., df1)
	
	# QR decompostion
	qrX0 <- qr(M0, tol = 1e-07)
	Q0 <- qr.Q(qrX0)
	Q0 <- Q0[, 1:qrX0$rank, drop=FALSE]
	
	qrX1 <- qr(M1, tol = 1e-07)
	Q1 <- qr.Q(qrX1)
	Q1 <- Q1[, 1:qrX1$rank, drop=FALSE]
	
	# Got residual
	if (resid.perm) {
		if (!block.perm) {
			# Permute the residual
			if (is.null(adj.name)) {
				Y <- t(resid(lm(as.formula(paste('t(Y) ~ 1')), meta.dat)))
			} else {
				Y <- t(resid(lm(as.formula(paste('t(Y) ~ ', paste(adj.name, collapse='+'))), meta.dat)))
			}
			
		} else {
			
			if (is.null(strata)) {
				stop('Block permutation requires strata!\n')
			} else {
				Y.r <- matrix(NA, nrow(Y), nlevels(strata))
				Y.e <- Y
#				cat('Fitting linear mixed effects model ...\n')
				for (j in 1:nrow(Y)) {
					# Linear mixed effects model
					yy <- Y[j, ]
					meta.dat$yy <- yy
					meta.dat$strata <- strata
					if (is.null(adj.name)) {
						
						obj <- lmer(as.formula(paste('yy ~ 1 + (1 | strata)')), data=meta.dat)
						# The order is the same as the levels
						Y.r[j, ] <- random.effects(obj)[[1]][, 1]
						Y.e[j, ] <- resid(obj)
					} else {
						obj <- lmer(as.formula(paste('yy ~ ', paste(adj.name, collapse='+'), '+ (1 | strata)')), data=meta.dat)
						Y.r[j, ] <- random.effects(obj)[[1]][, 1]
						Y.e[j, ] <- resid(obj)
					}
				}
				Y <- Y.r[, as.numeric(strata)] + Y.e
				#			Y <- Y - rowMeans(Y)
				#		    Y <- Y.e
			}
		}
	}
	
	TSS <- rowSums(Y^2)
	MSS1 <- rowSums((Y %*% Q1)^2)
	MSS0 <- rowSums((Y %*% Q0)^2)  # Not necessary, it's zero
	F0 <- sum(lambda * (MSS1 - MSS0)) /  sum(lambda * (TSS - MSS1))
	
#	P1 <- M1 %*% solve(t(M1) %*% M1) %*% t(M1)
#	F0 <- diag(Y %*% (P1 - P0) %*% t(Y)) / diag(Y %*% (I - P1) %*% t(Y))
#	df3 <- df1
	
	if (block.perm == FALSE) {
		perm.ind <- vegan:::getPermuteMatrix(perm.no, n, strata = strata)
		perm.no <- nrow(perm.ind)
	}
	
#	cat('Permutation test ....\n')
	Fp <- sapply(1:perm.no, function(i) {
#				if (i %% 100 == 0) cat('.')
				if (block.perm == FALSE) {
					Yp <- Y[, perm.ind[i, ]]
				} else {
					# Double permutation
					strata.p <- factor(strata, levels=sample(levels(strata)))
					Yp <- Y.r[, as.numeric(strata.p)] + Y.e[, sample(ncol(Y))]
#				    Yp <- Y.e[, sample(ncol(Y))]
#					Yp <- Yp - rowMeans(Yp)
				}
				
#				df3[, grp.name] <- sample(df1[, grp.name])
#				M1 <- model.matrix( ~., df3)
#				P1 <- M1 %*% solve(t(M1) %*% M1) %*% t(M1)
				MSS1p <- rowSums((Yp %*% Q1)^2)
				MSS0p <- rowSums((Yp %*% Q0)^2)    
				if (block.perm == FALSE) {
					TSSp <- TSS
				} else {
					TSSp <- rowSums(Yp^2)
				}
				sum(lambda * (MSS1p - MSS0p)) / sum(lambda * (TSSp - MSS1p)) 
			})
	
	p.value <- mean(c(Fp >= F0, 1))
  
	return(list(f0 = F0, f.perms = Fp, p.value = p.value))
#	return(p.raw)
}




# This function for nonparametric/permutaiton method
# Rev: 2017_02_16  Add normalization method; Add transformation; Remove rarefaction (only output warnings);
# Rev: 2017_10_30  Support filtering based on coefficient of variation
# Rev: 2018_01_30 Add ct.min and handle NA size factor
# Rev: 2018_03_15 Add winsorization support for permutatin test - default is FALSE
# Rev: 2018_10_03 TSS size factor calculation is based on specific taxa level
perform_differential_analysis <- function (data.obj, grp.name, adj.name=NULL, subject=NULL, 
		taxa.levels=c('Phylum', 'Order', 'Class', 'Family', 'Genus', 'Species'),
		method='perm', block.perm=FALSE, perm.no=999,
		norm='GMPR', norm.level='Species', intersect.no=4, ct.min = 2,
		transform='sqrt',
		winsor = FALSE, winsor.qt = 0.97,  
		prev=0.1, minp=0.002, medianp=NULL, cv=NULL,
		mt.method='fdr', cutoff=0.15, 
		ann='', seed=123, ...) {
	# To be completed
	df <- data.obj$meta.dat
	grp <- df[, grp.name]
	
	ind <- !is.na(grp)
	data.obj <- subset_data(data.obj, ind)
	grp <- grp[ind]
	df <- df[ind, ]
	
	if ('Species' %in% taxa.levels & !('Species' %in% names(data.obj$abund.list))) {
		data.obj$abund.list[['Species']] <- data.obj$otu.tab
		rownames(data.obj$abund.list[['Species']]) <- paste0("OTU", rownames(data.obj$otu.tab), ":", 
				data.obj$otu.name[, 'Phylum'], ";", data.obj$otu.name[, 'Genus'])
	}

	# Test for sequence-depth confounding
	dep <- colSums(data.obj$otu.tab)
	
	diff.seq.p <- summary(aov(dep ~ grp))[[1]][1, 'Pr(>F)']
	if (!is.na(diff.seq.p) & diff.seq.p <= 0.05) {
		warning(paste0(
		 '\nSignificant sequencing depth confounding with the variable of interest!\n',
		 'For nonparametric test/permutaiton test, there may be potentially many false postives (for those less prevalent taxa)!\n',
		 'Consider performing rarefaction first! (However, rarefaction will not completly solve the problem.)\n',
		 'May also try count-based models, which might have better false postive controls!\n'))
#		cat("For parametric test with sequence depth adjustment (DESeq2), please be cautious about the results!\n There may be potential residual sequence depth confounding!\n")
		# potential revising
	}
  
	# Calculate size.factor
	if (norm == 'Precalculated') {
		size.factor <- data.obj$size.factor
	}
	if (norm == 'GMPR') {
		if (norm.level %in% c('OTU', 'Species', 'ASV')) {
			tab <- data.obj$otu.tab
		} else {
			tab <- data.obj$abund.list[[norm.level]]
		}
		size.factor <- GMPR(as.matrix(tab), intersect.no, ct.min)
		
		# Rev: 2018_01_30
		ind <- !is.na(size.factor)
		data.obj <- subset_data(data.obj, ind)
		grp <- grp[ind]
		df <- df[ind, ]
		size.factor <- size.factor[ind]
	}	

	
	# Method-dependent processing
	if (is.null(method)) {
		if (nlevels(grp) == 2) {
			method <- 'wilcox'
		} else {
			method <- 'kruskal'
		}
	}
	if (method == 'wilcox.pair') {
		if (nlevels(grp) != 2) stop("Wilcox test requires two groups!\n")
		if (is.null(subject)) stop("Paired wilcox needs subject information!\n")
		subject <- factor(df[, subject])
		ind1 <- ind2 <- NULL
		for(sub in levels(subject)) {
			temp1 <- which(as.numeric(grp) == 1 & subject == sub)
			temp2 <- which(as.numeric(grp) == 2 & subject == sub)
			if (length(temp1) != 0 & length(temp2) != 0) {
				ind1 <- c(ind1, temp1[1])
				ind2 <- c(ind2, temp2[1])
			}
			
		}
		#	if (length(ind1) != length(ind2))  warning('Some subjects are not paired!\n')
	}
	
	if (method == 'perm.pair') {
		if (is.null(subject)) stop("Paired permutation test needs subject information!\n")
		subject <- factor(df[, subject])
	}
	
	if (method == 'perm') {
		if (!is.null(subject)) {
			subject <- factor(df[, subject])
		} 
	}
	
	ann <- paste0(ann, '.', method)
	
	if (is.factor(grp)) {
		
		pv.list <- qv.list <- qv.perm.list <- R2.list <- coef.list <- fc.list <- pc.list <- m.list <- nzm.list  <- prv.list <- list()
		res.final <- NULL
		for (LOI in taxa.levels) {
			cat(LOI, "\n")
			ct <- data.obj$abund.list[[LOI]]
			
			# Rev: 2018_10_03 Move here
			if (norm == 'TSS') {
				size.factor <- colSums(data.obj$abund.list[[LOI]])
			}
			
			# Filtering
			prop0 <- t(t(ct) / colSums(ct))
			if (!is.null(prev)) {
				prop0 <- prop0[rowSums(prop0!=0) > prev * ncol(prop0), , drop=FALSE]	
				ct <- ct[rownames(prop0), , drop=FALSE]
			}
			if (!is.null(minp)) {
				prop0 <- prop0[rowMaxs(prop0) > minp, , drop=FALSE]	
				ct <- ct[rownames(prop0), , drop=FALSE]
			}
			
			if (!is.null(medianp)) {
				nz.mean <- apply(prop0, 1, function(x) median(x[x!=0]))
				prop0 <- prop0[nz.mean > medianp, , drop=FALSE]	
				ct <- ct[rownames(prop0), , drop=FALSE]
			}
			
			if (!is.null(cv)) {
				prop0 <- prop0[rowSds(prop0) / rowMeans(prop0) > cv, , drop=FALSE]	
				ct <- ct[rownames(prop0), , drop=FALSE]
			}
			
			# Normalization
	        prop <- t(t(ct) / size.factor)
			
			# Transformation - Others are possible/may be explored in the future
	        if (transform == 'sqrt') {
				prop <- sqrt(prop)
			}
					 		
			if (method == 'perm') {
				set.seed(seed)
				perm.obj <- permute_differential_analysis(df, prop, grp.name, adj.name, strata=subject, 
						block.perm=block.perm, sqrt.trans=FALSE, perm.no=perm.no, winsor = winsor, winsor.qt = winsor.qt)
				pv.de2 <- perm.obj$p.raw
				names(pv.de2) <- rownames(prop)
			}
			
			# For legacy use
			if (method == 'perm.pair') {
				set.seed(seed)
				perm.obj <- permute_differential_analysis(df, prop, grp.name, adj.name, strata=subject,
						block.perm=FALSE, sqrt.trans=FALSE, perm.no=perm.no, winsor = winsor, winsor.qt = winsor.qt)
				pv.de2 <- perm.obj$p.raw
				names(pv.de2) <- rownames(prop)
			}
			
			pv.vec <- m.vec <- nzm.vec <- prv.vec <-  fc.vec <- pc.vec <-  NULL
			
			for (taxon in rownames(prop)) {
				taxon.abund <- prop[taxon, ]
				taxon.abund0 <- prop0[taxon, ]
				
				pv <- fc <- pc <- m <- nzm <- prv <- NULL
				if (method == 'wilcox') {
					if (nlevels(grp) != 2) stop("Wilcox test requires two groups!\n")
					pv <- wilcox.test(taxon.abund ~ grp)$p.value
					
				}
				if (method == 'wilcox.pair') {
					pv <- wilcox.test(taxon.abund[ind1], taxon.abund[ind2], paired=T)$p.value
				}
				if (method == 'twopart') {
					if (nlevels(grp) != 2) stop("Two part test requires two groups!\n")
					grp1 <- taxon.abund[as.numeric(grp)==1]
					grp2 <- taxon.abund[as.numeric(grp)==2]
					pv <- twopart.test(grp1, grp2)$p.value
				}	
				if (method == 'kruskal') {
					if (nlevels(grp) <= 2) warning("Kruskal-wallis test requires three or more groups!\n")
					pv <- kruskal.test(taxon.abund ~ grp)$p.value
				}
		
				if (method == 'perm') {
					pv <- pv.de2[taxon]
				}
				
				if (method == 'perm.pair') {
					pv <- pv.de2[taxon]
				}
				m <- tapply(taxon.abund0, grp, function(x) mean(x))
				nzm <- tapply(taxon.abund0, grp, function(x) mean(x[x != 0]))
				prv <- tapply(taxon.abund0, grp, function(x) sum(x != 0))				
				
				# Rev: 2017_02_21 fc change baseline grp
				if (nlevels(grp) == 2) {
					grp.no <- table(grp)
					fc <- log2(m[2] / m[1])
					pc <- prv[2] / grp.no[2] / prv[1] * grp.no[1]
				} else {
					pc <- fc <- NA
				}
				
				pv.vec <- rbind(pv.vec, pv)
				fc.vec <- rbind(fc.vec, fc)
				m.vec <- rbind(m.vec, m)
				nzm.vec <- rbind(nzm.vec, nzm)
				pc.vec <- rbind(pc.vec, pc)
				prv.vec <- rbind(prv.vec, prv / table(grp))	
			}
			
			
			temp <- p.adjust(pv.vec[, 1], 'fdr')
			
			qv.vec <- matrix(temp, ncol=1)
			
			rownames(pv.vec) <- rownames(qv.vec) <- rownames(fc.vec) <- rownames(pc.vec) <- rownames(m.vec) <- rownames(nzm.vec) <- rownames(prv.vec) <- rownames(prop)
			colnames(pv.vec) <- 'Pvalue'
			colnames(qv.vec) <- 'Qvalue'
			colnames(fc.vec) <- 'log2(AbundRatio)'
			colnames(pc.vec) <- 'PrevRatio'
			colnames(m.vec) <- paste(levels(grp), 'Mean')
			colnames(nzm.vec) <- paste(levels(grp), 'nzMean')
			colnames(prv.vec) <- paste(levels(grp), 'preval')
			
			pv.list[[LOI]] <- pv.vec
			qv.list[[LOI]] <- qv.vec
			fc.list[[LOI]] <- fc.vec
			pc.list[[LOI]] <- pc.vec
			m.list[[LOI]] <- m.vec
			nzm.list[[LOI]] <- nzm.vec
			prv.list[[LOI]] <- prv.vec
			
			if (method %in% c('perm', 'perm.pair')) {
				qv.perm.list[[LOI]] <- t(t(perm.obj$p.adj.fdr))
				R2.list[[LOI]] <- t(t(perm.obj$R2))
				coef.list[[LOI]] <- perm.obj$coefficients
			}
			
			if (method %in% c('perm', 'perm.pair')) {
				coef.mat <- perm.obj$coefficients
				colnames(coef.mat) <- paste0('coef_', colnames(coef.mat))
				res <- cbind(pv.vec, qv.vec, 'Qvalue.perm'=perm.obj$p.adj.fdr, R2=perm.obj$R2, coef.mat, 
						m.vec, nzm.vec, fc.vec, prv.vec, pc.vec)
				rownames(res) <- rownames(prop)
			} else {
				res <- cbind(pv.vec, qv.vec, m.vec, nzm.vec, fc.vec, prv.vec, pc.vec)
				rownames(res) <- rownames(prop)
			}

			write.csv(res, paste0("Taxa_DifferentialAbundanceAnalysis_", LOI, "_", ann, ".csv"))
			
			if (mt.method == 'fdr') {
				res.final <- rbind(res.final, res[res[, 'Qvalue'] <= cutoff, , drop=F])
			}
			if (mt.method == 'raw') {
				res.final <- rbind(res.final, res[res[, 'Pvalue'] <= cutoff, , drop=F])
			}
			if (mt.method == 'fdr.perm') {
				res.final <- rbind(res.final, res[res[, 'Qvalue.perm'] <= cutoff, , drop=F])
			}
			
		}
		
		if (!is.null(res.final)) {
			colnames(res.final) <- colnames(res)
			write.csv(res.final, paste0("Taxa_DifferentialAbundanceAnalysis_AllLevels_", mt.method, '_', cutoff, "_", ann, ".csv"))
		}
		
		return(list(pv.list=pv.list, fc.list=fc.list, pc.list=pc.list, qv.list=qv.list, qv.perm.list=qv.perm.list, R2.list=R2.list,
						coef.list=coef.list, m.list=m.list))
	} else {
		if (is.null(method)) {
			method <- 'Spearman'
		}
		# Continuous case - currently only has DESeq2 
		pv.list <- qv.list <-  fc.list <-  m.list <- R2.list <- coef.list <- qv.perm.list <- list()
		res.final <- NULL
		for (LOI in taxa.levels) {
			cat(LOI, "\n")
			ct <- data.obj$abund.list[[LOI]]
			
			# Rev: 2018_12_25
			if (norm == 'TSS') {
				size.factor <- colSums(data.obj$abund.list[[LOI]])
			}
			
			# Filtering
			prop0 <- t(t(ct) / colSums(ct))
			if (!is.null(prev)) {
				prop0 <- prop0[rowSums(prop0!=0) > prev * ncol(prop0), , drop=FALSE]	
				ct <- ct[rownames(prop0), , drop=FALSE]
			}
			if (!is.null(minp)) {
				prop0 <- prop0[rowMaxs(prop0) > minp, , drop=FALSE]	
				ct <- ct[rownames(prop0), , drop=FALSE]
			}
			
			if (!is.null(medianp)) {
				nz.mean <- apply(prop0, 1, function(x) median(x[x!=0]))
				prop0 <- prop0[nz.mean > medianp, , drop=FALSE]	
				ct <- ct[rownames(prop0), , drop=FALSE]
			}
			
			if (!is.null(cv)) {
				prop0 <- prop0[rowSds(prop0) / rowMeans(prop0) > cv, , drop=FALSE]	
				ct <- ct[rownames(prop0), , drop=FALSE]
			}
			
			# Normalization
			prop <- t(t(ct) / size.factor)
			
			# Transformation - Others are possible/may be explored in the future
			if (transform == 'sqrt') {
				prop <- sqrt(prop)
			}
			
			if (method == 'perm') {
				set.seed(seed)
				perm.obj <- permute_differential_analysis(df, prop, grp.name, adj.name, strata=subject, 
						block.perm=block.perm, sqrt.trans=FALSE, perm.no=perm.no, winsor = winsor, winsor.qt = winsor.qt)
				pv.de2 <- perm.obj$p.raw
				names(pv.de2) <- rownames(prop)
				# Place holder
				fc.de2 <- sapply(1:nrow(prop), function(i) cor(prop[i, ], df[, grp.name], method='spearman'))
			}
			
			if (method == 'Spearman') {
				if (!is.null(adj.name)) {
					stop("Spearman test can't adjust covariates!")
				}
				pv.de2 <- apply(prop, 1, function(x) {
							cor.test(x, grp, method='spearman')$p.value
						})
				names(pv.de2) <- rownames(prop)
				# Place holder
				fc.de2 <- sapply(1:nrow(prop), function(i) cor(prop[i, ], df[, grp.name], method='spearman'))
			}
			pv.vec <- matrix(pv.de2, ncol=1)	
			qv.vec <- matrix(p.adjust(pv.vec[, 1], 'fdr'), ncol=1)
			fc.vec <- matrix(fc.de2, ncol=1)
			m.vec <- matrix(rowMeans(prop0), ncol=1)
			
			rownames(pv.vec) <- rownames(qv.vec) <- rownames(fc.vec) <- rownames(m.vec)  <- rownames(prop)
			colnames(pv.vec) <- 'Pvalue'
			colnames(qv.vec) <- 'Qvalue'
			colnames(fc.vec) <- 'SpearmanCorr'
			colnames(m.vec) <- 'Mean'
			
			
			pv.list[[LOI]] <- pv.vec
			qv.list[[LOI]] <- qv.vec
			fc.list[[LOI]] <- fc.vec
			m.list[[LOI]] <- m.vec
			
			if (method %in% c('perm', 'perm.pair')) {
				qv.perm.list[[LOI]] <- t(t(perm.obj$p.adj.fdr))
				R2.list[[LOI]] <- t(t(perm.obj$R2))
				coef.list[[LOI]] <- perm.obj$coefficients
			}
			
			if (method %in% c('perm', 'perm.pair')) {
				coef.mat <- perm.obj$coefficients
				colnames(coef.mat) <- paste0('coef_', colnames(coef.mat))
				res <- cbind(pv.vec, qv.vec, 'Qvalue.perm'=perm.obj$p.adj.fdr, R2=perm.obj$R2, coef.mat, fc.vec)
				rownames(res) <- rownames(prop)
			} else {
				res <- cbind(m.vec, fc.vec, pv.vec, qv.vec)
				rownames(res) <- rownames(prop)
			}
			
			
			write.csv(res, paste0("Taxa_DifferentialAbundanceAnalysis_", LOI, "_", ann, ".csv"))
			
			if (mt.method == 'fdr') {
				res.final <- rbind(res.final, res[res[, 'Qvalue'] <= cutoff, , drop=F])
			}
			if (mt.method == 'raw') {
				res.final <- rbind(res.final, res[res[, 'Pvalue'] <= cutoff, , drop=F])
			}
			if (mt.method == 'fdr.perm') {
				res.final <- rbind(res.final, res[res[, 'Qvalue.perm'] <= cutoff, , drop=F])
			}
		}
		
		if (!is.null(res.final)) {
			colnames(res.final) <- colnames(res)
			write.csv(res.final, paste0("Taxa_DifferentialAbundanceAnalysis_AllLevels_", mt.method, '_', cutoff, "_", ann, ".csv"))
		}
		return(list(pv.list=pv.list, fc.list=fc.list, qv.list=qv.list, m.list=m.list, qv.perm.list=qv.perm.list, coef.list=coef.list, R2.list=R2.list))
	}
	
}

#Owls <- transform(Owls, 
#		Nest=reorder(Nest,NegPerChick), 
#		logBroodSize=log(BroodSize), 
#		NCalls=SiblingNegotiation)
#
#fit_zinbinom <- glmmadmb(NCalls~(FoodTreatment+ArrivalTime)*SexParent+ 
#				offset(logBroodSize)+(1|Nest), 
#		data=Owls, 
#		zeroInflation=TRUE, 
#		family="nbinom")
confint.lme <- function (object, parm, level = 0.95, ...) {
	cf <- fixed.effects(object)
	pnames <- names(cf)
	if (missing(parm)) 
		parm <- pnames
	else if (is.numeric(parm)) 
		parm <- pnames[parm]
	a <- (1 - level)/2
	a <- c(a, 1 - a)
	pct <- stats:::format.perc(a, 3)
	fac <- qnorm(a)
	ci <- array(NA, dim = c(length(parm), 2L), dimnames = list(parm, 
					pct))
	ses <- sqrt(diag(vcov(object)))[parm]
	ci[] <- cf[parm] + ses %o% fac
	ci
}

# 2020_02_20 adj.name allow multple variables
# Rev: 2016_09_13 add glmmPQL-based overdipersed Poisson and binomial model
# glmmPQL default has overdispersion parameter. Regular Poisson and Binomial does not work.
perform_differential_analysis_para_single_RE <- function (taxon, ldep, grp.name, adj.name = NULL, subject, df, method='NB', LRT=FALSE) {
	# ldep: log depth (size factor)
	if (!is.null(adj.name) ) {
		if (sum(grepl(grp.name, c(adj.name)))) {
			stop('grp.name could not be part of adj.name, or there will be problem!\n')
		}
	}
	
	if (is.null(subject)) {
		stop('Random effects model require the specification of the subject parameter!\n')
	}	
	
	df$ldep <- ldep
	df$taxon <- taxon
	if (LRT) warning('Currently, only Wald test is implemented!\n')
	
	
	if (method %in% c('NB', 'ZINB1', 'ZINB0', 'B0')) {
		if (is.null(adj.name)) {
			grp.name.adj.name.subject <- grp.name.adj.name.subject <- paste(grp.name,  '+ (1|', subject, ')')
		} else {
			adj.name <- paste(adj.name, collapse = ' + ')
			grp.name.adj.name.subject <- paste(grp.name, '+', adj.name, '+ (1|', subject, ')')
		}
		
		if (method == 'NB') {
			m1.nb <- glmmadmb(as.formula(paste('taxon ~', grp.name.adj.name.subject, '+ offset(ldep)')), data = df, 
					zeroInflation=FALSE, family='nbinom')
		}
		
		# 'B0' uses the glmmadmb, which will be compared to 'B' method of glmmPQL
		if (method == 'B0') {
			taxon2 <- as.numeric(taxon != 0)
			df$taxon2 <- taxon2
			m1.nb <- glmmadmb(as.formula(paste('taxon2 ~', grp.name.adj.name.subject, '+ ldep')), data = df, 
					zeroInflation=FALSE, family='binomial')
		}
		
		if (method == 'ZINB1') {
			m1.nb <- glmmadmb(as.formula(paste('taxon ~', grp.name.adj.name.subject, '+ offset(ldep)')), data = df, 
					zeroInflation=TRUE, family='nbinom')
		}
		
		if (method == 'ZINB0') {
			m1.nb <- glmmadmb(as.formula(paste('taxon ~', grp.name.adj.name.subject, '+ offset(ldep)')), data = df, 
					zeroInflation=TRUE, family='truncnbinom')
		}
		
		code <- list(m1.conv=m1.nb$convmsg)	
		pv.nb <- wald.test(b = coef(m1.nb), Sigma = vcov(m1.nb), Terms = grep(grp.name, names(coef(m1.nb))))$result$chi2['P']
		method <- paste(method, 'Wald')
		
		
		aic.nb <- -2 * m1.nb$loglik + 2 * m1.nb$npar	
		coef.nb <- coef(m1.nb)
		ci.nb <- confint.default(m1.nb)
	} 
	
	if (method %in% c('OP', 'B', 'QB')) {
		if (is.null(adj.name)) {
			grp.name.adj.name <- grp.name
		} else {
			adj.name <- paste(adj.name, collapse = ' + ')
			grp.name.adj.name <- paste(grp.name, '+', adj.name)
		}
		
		subject <- paste('~ 1 |', subject)
		if (method == 'OP') {
			m1.nb <- glmmPQL(as.formula(paste('taxon ~', grp.name.adj.name, '+ offset(ldep)')), random = as.formula(subject), data = df, 
					verbose=F, family=quasipoisson())
		}
		
		# 'B0' uses the glmmadmb, which will be compared to 'B' method of glmmPQL
		if (method == 'B') {
			taxon2 <- as.numeric(taxon != 0)
			df$taxon2 <- taxon2
			m1.nb <- glmmPQL(as.formula(paste('taxon2 ~', grp.name.adj.name, '+ ldep')),  random = as.formula(subject), data = df, 
					verbose=F, family=binomial)
		}
		
		if (method == 'QB') {
			taxon2 <- as.numeric(taxon != 0)
			df$taxon2 <- taxon2
			m1.nb <- glmmPQL(as.formula(paste('taxon2 ~', grp.name.adj.name, '+ ldep')),  random = as.formula(subject), data = df, 
					verbose=F, family=quasibinomial())
		}
		
		pv.nb <- wald.test(b = fixed.effects(m1.nb), Sigma = vcov(m1.nb), Terms = grep(grp.name, names(coef(m1.nb))))$result$chi2['P']
		method <- paste(method, 'Wald')
		code <- NA   # placeholder
		aic.nb <- NA # NA placeholder
		coef.nb <- fixed.effects(m1.nb)
		ci.nb <- confint.lme(m1.nb)
		
	}
	
	fc.nb <- coef.nb[grep(grp.name, names(coef.nb))]
	obj <- ci.nb[grep(grp.name, rownames(ci.nb)), ]
	
	if (is.vector(obj)) {
		fc.lc.nb <- obj[1]
		fc.uc.nb <- obj[2]
	} else {
		fc.lc.nb <- obj[, 1]
		fc.uc.nb <- obj[, 2]
		names(fc.lc.nb) <- paste(names(fc.lc.nb), '2.5%')
		names(fc.uc.nb) <- paste(names(fc.uc.nb), '97.5%')
	}
	
	return(list(method=method, pv=pv.nb, lfc=fc.nb, lfc.lci=fc.lc.nb, lfc.uci=fc.uc.nb, aic=aic.nb, code=code))
}


# 2020_02_20 adj.name allow multple variables
perform_differential_analysis_para_single_FE <- function (taxon.abund, ldep, grp.name, adj.name=NULL, subject=NULL, df, method='NB', LRT=FALSE) {
	# ldep: log depth (size factor)
	if (!is.null(adj.name)) {
		if (sum(grepl(grp.name, c(adj.name)))) {
			stop('grp.name could not be part of adj.name or subject, or there will be problem!\n')
		}
	}
	
	if (!is.null(subject)) {
		warnings('Fixed effects model will ignore the subject variable! Please use randome effects model!\n')
	}
	if (LRT & method == 'OP') warning('Overdispersed Poisson does not support LRT! Wald test used!\n')
	
	if (is.null(adj.name)) {
		grp.name.adj.name <- grp.name
	} else {
		adj.name <- paste(adj.name, collapse = ' + ')
		grp.name.adj.name <- paste(grp.name, '+', adj.name)
	}
	if (method == 'NB') {
		m1.nb <- glm.nb(as.formula(paste('taxon.abund ~', grp.name.adj.name, '+ offset(ldep)')), data = df)
		if (LRT) {
			m0.nb <- update(m1.nb, as.formula(paste('. ~ . -',  grp.name)))
			code <- list(m1.conv=m1.nb$converged, m1.bound=m1.nb$boundary, m0.conv=m0.nb$converged, m0.bound=m0.nb$boundary)
			pv.nb <- anova(m1.nb, m0.nb)['Pr(Chi)'][2, ]
			method <- paste(method, 'LRT')
		} else {
			code <- list(m1.conv=m1.nb$converged, m1.bound=m1.nb$boundary)	
			pv.nb <- wald.test(b = coef(m1.nb), Sigma = vcov(m1.nb), Terms = grep(grp.name, names(coef(m1.nb))))$result$chi2['P']
			method <- paste(method, 'Wald')
		}

		aic.nb <- summary(m1.nb)$aic
		
		coef.nb <- coef(m1.nb)
		fc.nb <- coef.nb[grep(grp.name, names(coef.nb))]
		
		ci.nb <- confint.default(m1.nb)
		obj <- ci.nb[grep(grp.name, rownames(ci.nb)), ]
		
		if (is.vector(obj)) {
			fc.lc.nb <- obj[1]
			fc.uc.nb <- obj[2]
		} else {
			fc.lc.nb <- obj[, 1]
			fc.uc.nb <- obj[, 2]
			names(fc.lc.nb) <- paste(names(fc.lc.nb), '2.5%')
			names(fc.uc.nb) <- paste(names(fc.uc.nb), '97.5%')
		}
		return(list(method=method, pv=pv.nb, lfc=fc.nb, lfc.lci=fc.lc.nb, lfc.uci=fc.uc.nb, aic=aic.nb, code=code))
	}
	if (method == 'B') {
		taxon.abund2 <- as.numeric(taxon.abund != 0)
		m1.b <- glm(as.formula(paste('taxon.abund2 ~', grp.name.adj.name, '+ ldep')), data = df, family=binomial)
		if (LRT) {
			m0.b <- update(m1.b, as.formula(paste('. ~ . -',  grp.name)))
			code <- list(m1.conv=m1.b$converged, m1.bound=m1.b$boundary, m0.conv=m0.b$converged, m0.bound=m0.b$boundary)
			pv.b <- pchisq(2 * (logLik(m1.b) - logLik(m0.b)), df = df.residual(m0.b) - df.residual(m1.b), lower.tail=FALSE)
			method <- paste(method, 'LRT')
		} else {
			code <- list(m1.conv=m1.b$converged, m1.bound=m1.b$boundary)	
			pv.b <- wald.test(b = coef(m1.b), Sigma = vcov(m1.b), Terms = grep(grp.name, names(coef(m1.b))))$result$chi2['P']
			method <- paste(method, 'Wald')
		}

		aic.b <- summary(m1.b)$aic
		coef.b <- coef(m1.b)
		fc.b <- coef.b[grep(grp.name, names(coef.b))]
		
		ci.b <- confint.default(m1.b)
		obj <- ci.b[grep(grp.name, rownames(ci.b)), ]
		
		if (is.vector(obj)) {
			fc.lc.b <- obj[1]
			fc.uc.b <- obj[2]
		} else {
			fc.lc.b <- obj[, 1]
			fc.uc.b <- obj[, 2]
			names(fc.lc.b) <- paste(names(fc.lc.b), '2.5%')
			names(fc.uc.b) <- paste(names(fc.uc.b), '97.5%')
		}
		return(list(method=method, pv=pv.b, lfc=fc.b, lfc.lci=fc.lc.b, lfc.uci=fc.uc.b, aic=aic.b, code=code))
	}
	
	# Rev: 2016_09_13 add 'QB', No likelihood ratio test
	if (method == 'QB') {
		taxon.abund2 <- as.numeric(taxon.abund != 0)
		m1.b <- glm(as.formula(paste('taxon.abund2 ~', grp.name.adj.name, '+ ldep')), data = df, family=quasibinomial)
		
		code <- list(m1.conv=m1.b$converged, m1.bound=m1.b$boundary)	
		pv.b <- wald.test(b = coef(m1.b), Sigma = vcov(m1.b), Terms = grep(grp.name, names(coef(m1.b))))$result$chi2['P']
		method <- paste(method, 'Wald')
		
		
		aic.b <- summary(m1.b)$aic
		coef.b <- coef(m1.b)
		fc.b <- coef.b[grep(grp.name, names(coef.b))]
		
		ci.b <- confint.default(m1.b)
		obj <- ci.b[grep(grp.name, rownames(ci.b)), ]
		
		if (is.vector(obj)) {
			fc.lc.b <- obj[1]
			fc.uc.b <- obj[2]
		} else {
			fc.lc.b <- obj[, 1]
			fc.uc.b <- obj[, 2]
			names(fc.lc.b) <- paste(names(fc.lc.b), '2.5%')
			names(fc.uc.b) <- paste(names(fc.uc.b), '97.5%')
		}
		return(list(method=method, pv=pv.b, lfc=fc.b, lfc.lci=fc.lc.b, lfc.uci=fc.uc.b, aic=aic.b, code=code))
	}
	
	if (method == 'OP') {
		# No LRT
		m1.op <- glm(as.formula(paste('taxon.abund ~', grp.name.adj.name)), offset=ldep, data = df, family=quasipoisson)
		code <- list(m1.conv=m1.op$converged, m1.bound=m1.op$boundary)

		# pv.op <- pchisq(2 * (logLik(m1.op) - logLik(m0.op)), df = df.residual(m0.op) - df.residual(m1.op), lower.tail=FALSE) # LRT not applicable
		coef.op <- coef(m1.op)		
		pv.op <- wald.test(b = coef.op, Sigma = vcov(m1.op), Terms = grep(grp.name, names(coef.op)))$result$chi2['P']
		method <- paste(method, 'Wald')
		fc.op <- coef.op[grep(grp.name, names(coef.op))]
		
		ci.op <- confint.default(m1.op)
		obj <- ci.op[grep(grp.name, rownames(ci.op)), ]
		
		if (is.vector(obj)) {
			fc.lc.op <- obj[1]
			fc.uc.op <- obj[2]
		} else {
			fc.lc.op <- obj[, 1]
			fc.uc.op <- obj[, 2]
			names(fc.lc.op) <- paste(names(fc.lc.op), '2.5%')
			names(fc.uc.op) <- paste(names(fc.uc.op), '97.5%')
		}
		return(list(method=method, pv=pv.op, lfc=fc.op, lfc.lci=fc.lc.op, lfc.uci=fc.uc.op, aic=NULL, code=code))
	}
	
	if (method == 'ZINB0') {
		m1.zinb <- zeroinfl(as.formula(paste('taxon.abund ~', grp.name.adj.name, '+ offset(ldep)')),
				data = df, dist = "negbin", EM = TRUE)
		if (LRT) {
			if (is.null(adj.name)) {
				m0.zinb <- zeroinfl(as.formula(paste('taxon.abund ~ offset(ldep)')),
						data = df, dist = "negbin", EM = TRUE)
			} else {
				m0.zinb <- zeroinfl(as.formula(paste('taxon.abund ~', adj.name, '+ offset(ldep)')),
						data = df, dist = "negbin", EM = TRUE)
			}
			code <- list(m1.conv=m1.zinb$converged, m0.conv=m0.zinb$converged)
			# LRT
			pv.zinb <-  pchisq(2 * (logLik(m1.zinb) - logLik(m0.zinb)), df = df.residual(m0.zinb) - df.residual(m1.zinb), lower.tail=FALSE)
			method <- paste(method, 'LRT')
		} else {
			code <- list(m1.conv=m1.zinb$converged)	
			pv.zinb <- wald.test(b = coef(m1.zinb), Sigma = vcov(m1.zinb), Terms = grep(grp.name, names(coef(m1.zinb))))$result$chi2['P']
			method <- paste(method, 'Wald')
		}
		
		aic.zinb <- -2 * logLik(m1.zinb) + 2 * (m1.zinb$n - m1.zinb$df.residual)
		
		coef.zinb <- coef(m1.zinb)
		fc.zinb <- coef.zinb[grep(grp.name, names(coef.zinb))]
		
		ci.zinb <- confint.default(m1.zinb)
		obj <- ci.zinb[grep(grp.name, rownames(ci.zinb)), ]
		
		if (is.vector(obj)) {
			fc.lc.zinb <- obj[1]
			fc.uc.zinb <- obj[2]
		} else {
			fc.lc.zinb <- obj[, 1]
			fc.uc.zinb <- obj[, 2]
			names(fc.lc.zinb) <- paste(names(fc.lc.zinb), '2.5%')
			names(fc.uc.zinb) <- paste(names(fc.uc.zinb), '97.5%')
		}
		return(list(method=method, pv=pv.zinb, lfc=fc.zinb, lfc.lci=fc.lc.zinb, lfc.uci=fc.uc.zinb, aic=aic.zinb, code=code))
	}
	
	
	if (method == 'ZINB1') {
		m1.zinb <- zeroinfl(as.formula(paste('taxon.abund ~', grp.name.adj.name, '+ offset(ldep) | ldep')),
				data = df, dist = "negbin", EM = TRUE)
		if (LRT) {
			if (is.null(adj.name)) {
				m0.zinb <- zeroinfl(as.formula(paste('taxon.abund ~ offset(ldep) | ldep')),
						data = df, dist = "negbin", EM = TRUE)
			} else {
				m0.zinb <- zeroinfl(as.formula(paste('taxon.abund ~', adj.name, '+ offset(ldep) | ldep')),
						data = df, dist = "negbin", EM = TRUE)
			}
			code <- list(m1.conv=m1.zinb$converged, m0.conv=m0.zinb$converged)
			# LRT
			pv.zinb <-  pchisq(2 * (logLik(m1.zinb) - logLik(m0.zinb)), df = df.residual(m0.zinb) - df.residual(m1.zinb), lower.tail=FALSE)
			method <- paste(method, 'LRT')
		} else {
			code <- list(m1.conv=m1.zinb$converged)	
			pv.zinb <- wald.test(b = coef(m1.zinb), Sigma = vcov(m1.zinb), Terms = grep(grp.name, names(coef(m1.zinb))))$result$chi2['P']
			method <- paste(method, 'Wald')
		}
		
		aic.zinb <- -2 * logLik(m1.zinb) + 2 * (m1.zinb$n - m1.zinb$df.residual)
		
		coef.zinb <- coef(m1.zinb)
		fc.zinb <- coef.zinb[grep(grp.name, names(coef.zinb))]
		
		ci.zinb <- confint.default(m1.zinb)
		obj <- ci.zinb[grep(grp.name, rownames(ci.zinb)), ]
		
		if (is.vector(obj)) {
			fc.lc.zinb <- obj[1]
			fc.uc.zinb <- obj[2]
		} else {
			fc.lc.zinb <- obj[, 1]
			fc.uc.zinb <- obj[, 2]
			names(fc.lc.zinb) <- paste(names(fc.lc.zinb), '2.5%')
			names(fc.uc.zinb) <- paste(names(fc.uc.zinb), '97.5%')
		}
		return(list(method=method, pv=pv.zinb, lfc=fc.zinb, lfc.lci=fc.lc.zinb, lfc.uci=fc.uc.zinb, aic=aic.zinb, code=code))
	}
	
	
	if (method == 'ZINB2') {
		m2.zinb <- zeroinfl(as.formula(paste('taxon.abund ~', grp.name.adj.name, '+ offset(ldep) |', grp.name.adj.name, '+ ldep')),
				data = df, dist = "negbin", EM = TRUE)
		if (LRT) {
			if (is.null(adj.name)) {
				m0.zinb <- zeroinfl(as.formula(paste('taxon.abund ~ offset(ldep) | ldep')),
						data = df, dist = "negbin", EM = TRUE)
			} else {
				m0.zinb <- zeroinfl(as.formula(paste('taxon.abund ~', adj.name, '+ offset(ldep) |', adj.name, ' + ldep')),
						data = df, dist = "negbin", EM = TRUE)
			}
			
			code <- list(m1.conv=m2.zinb$converged, m0.conv=m0.zinb$converged)
			# LRT
			pv2.zinb <-  pchisq(2 * (logLik(m2.zinb) - logLik(m0.zinb)), df = df.residual(m0.zinb) - df.residual(m2.zinb), lower.tail=FALSE)
			method <- paste(method, 'LRT')
		} else {
			code <- list(m2.conv=m2.zinb$converged)	
			pv2.zinb <- wald.test(b = coef(m2.zinb), Sigma = vcov(m2.zinb), Terms = grep(grp.name, names(coef(m2.zinb))))$result$chi2['P']
			method <- paste(method, 'Wald')
		}

		aic2.zinb <- -2 * logLik(m2.zinb) + 2 * (m2.zinb$n - m2.zinb$df.residual)
		
		coef.zinb <- coef(m2.zinb)
		fc2.zinb <- coef.zinb[grep(grp.name, names(coef.zinb))]
		
		ci.zinb <- confint.default(m2.zinb)
		obj <- ci.zinb[grep(grp.name, rownames(ci.zinb)), ]
		
		if (is.vector(obj)) {
			fc2.lc.zinb <- obj[1]
			fc2.uc.zinb <- obj[2]
		} else {
			fc2.lc.zinb <- obj[, 1]
			fc2.uc.zinb <- obj[, 2]
			names(fc2.lc.zinb) <- paste(names(fc2.lc.zinb), '2.5%')
			names(fc2.uc.zinb) <- paste(names(fc2.uc.zinb), '97.5%')
		}
		return(list(method=method, pv=pv2.zinb, lfc=fc2.zinb, lfc.lci=fc2.lc.zinb, lfc.uci=fc2.uc.zinb, aic=aic2.zinb, code=code))
	}

}

# Rev: 2016_09_14 Add Adaptive 0: switch OP and QB depending on the number of zeros. 
# Rev: 2017_10_30  Support filtering based on coefficient of variation
# Rev: 2018_01_30 Add ct.min and handle NA size factor
perform_differential_analysis_para <- function (data.obj,  grp.name, adj.name=NULL, subject=NULL, RE=FALSE, method='Adaptive0', zerop.cutoff=0.25, ZINB='ZINB1', LRT=FALSE, 
		taxa.levels=c('Phylum', 'Order', 'Class', 'Family', 'Genus', 'Species'), winsor=TRUE, winsor.qt=0.97, norm='GMPR', norm.level='Species', intersect.no=4, ct.min = 2,
		prev=0.1, minp=0.002, medianp=NULL, cv=NULL, mt.method='fdr', cutoff=0.15, ann='', ...) {
	# To be completed
	# subject holds the random effects formula
	if (!RE) {
		if (!(method %in% c('ZINB', 'B', 'QB', 'NB', 'OP', 'Adaptive0', 'Adaptive1', 'Adaptive2'))) stop('The speficied model is not supported!\n')
		perform_differential_analysis_para_single <- perform_differential_analysis_para_single_FE
		if (!is.null(subject)) warning('subject will not be used. Are you sure you want to run fixed effects model? ')
	} else {
		if (!(method %in% c('ZINB', 'B', 'B0', 'QB', 'NB', 'OP', 'Adaptive0', 'Adaptive1', 'Adaptive2'))) stop('The speficied model does not have random effects implementation!\n')
		if (ZINB != 'ZINB1') stop('Currently only ZINB1 is supported!\n')
		if (is.null(subject)) warning('subject is not supplied. Fixed effects model will be used instead!\n')
		perform_differential_analysis_para_single <- perform_differential_analysis_para_single_RE
	}

	df <- data.obj$meta.dat
	grp <- df[, grp.name]
	
	ind <- !is.na(grp)
	data.obj <- subset_data(data.obj, ind)
	grp <- grp[ind]
	df <- df[ind, ]
	
	if ('Species' %in% taxa.levels & !('Species' %in% names(data.obj$abund.list))) {
		data.obj$abund.list[['Species']] <- data.obj$otu.tab
		rownames(data.obj$abund.list[['Species']]) <- paste0("OTU", rownames(data.obj$otu.tab), ":", 
				data.obj$otu.name[, 'Phylum'], ";", data.obj$otu.name[, 'Genus'])
	}
	
	dep <- colSums(data.obj$otu.tab)
	diff.seq.p <- summary(aov(dep ~ grp))[[1]][1, 'Pr(>F)']
	
	if (!is.na(diff.seq.p) & diff.seq.p <= 0.05) {
		cat("Signficant sequencing depth confounding!\n")
		cat("For parametric test with sequence depth adjustment, please be cautious about the results!\n")
		cat("There may be potential residual sequence depth confounding!\n")
	}
	
	pv.list <- qv.list <-  fc.list <- fc.lc.list <- fc.uc.list <- met.list <- list()
	res.final <- NULL
	
	if (norm == 'Precalculated') {
		dep <- data.obj$size.factor
	}
	
	if (norm == 'GMPR') {
		if (norm.level %in% c('OTU', 'Species', 'ASV')) {
			tab <- data.obj$otu.tab
		} else {
			tab <- data.obj$abund.list[[norm.level]]
		}
	  # 08/07/2020ï¼š ADD as.matrix() to avoid the error
		dep <- GMPR(as.matrix(tab), intersect.no, ct.min) 
		
		# Rev: 2018_01_30
		ind <- !is.na(dep)
		data.obj <- subset_data(data.obj, ind)
		grp <- grp[ind]
		df <- df[ind, ]
		dep <- dep[ind]
		
	}
	
	if (norm == 'TSS') {
		dep <- colSums(data.obj$otu.tab)
	}
	
	ldep <- log(dep)
	
	for (LOI in taxa.levels) {
		cat(LOI, "\n")

		taxon.ct <- data.obj$abund.list[[LOI]]
		

		if (winsor == TRUE) {
			# Addressing the outlier (97% percent) or at least one outlier
			
			taxon.ct.p <- t(t(taxon.ct) / dep)
			taxon.ct.p <- apply(taxon.ct.p, 1, function(x) {
						cutoff <- quantile(x, winsor.qt)
						x[x >= cutoff] <- cutoff
						x
					}
			)
			# column/row switch
			taxon.ct <- t(round(taxon.ct.p * dep))
			
		}
		
		prop <- t(t(taxon.ct) / colSums(taxon.ct))
#		if (!is.null(minp)) {
#			prop <- prop[rowMaxs(prop) > minp & rowSums(prop!=0) > prev*ncol(prop), , drop=FALSE]	
#			taxon.ct <- taxon.ct[rownames(prop), , drop=FALSE]
#		}
#		
#		if (!is.null(medianp)) {
#			nz.mean <- apply(prop, 1, function(x) median(x[x!=0]))
#			prop <- prop[nz.mean > medianp & rowSums(prop!=0) > prev*ncol(prop), , drop=FALSE]	
#			taxon.ct <- taxon.ct[rownames(prop), , drop=FALSE]
#		}
		
		if (!is.null(prev)) {
			prop <- prop[rowSums(prop!=0) > prev * ncol(prop), , drop=FALSE]	
			taxon.ct <- taxon.ct[rownames(prop), , drop=FALSE]
		}
		if (!is.null(minp)) {
			prop <- prop[rowMaxs(prop) > minp, , drop=FALSE]	
			taxon.ct <- taxon.ct[rownames(prop), , drop=FALSE]
		}
		
		if (!is.null(medianp)) {
			nz.mean <- apply(prop, 1, function(x) median(x[x!=0]))
			prop <- prop[nz.mean > medianp, , drop=FALSE]	
			taxon.ct <- taxon.ct[rownames(prop), , drop=FALSE]
		}
		
		if (!is.null(cv)) {
			prop <- prop[rowSds(prop) / rowMeans(prop) > cv, , drop=FALSE]	
			taxon.ct <- taxon.ct[rownames(prop), , drop=FALSE]
		}
			
		pv.vec <-  fc.vec <- fc.lc.vec <- fc.uc.vec <- met.vec <- conv.vec <- NULL
		obj <- NULL
		for (taxon in rownames(taxon.ct)) {
			cat('.')
			taxon.abund <- taxon.ct[taxon, ]
			
			######## Logistic regression ###############
			if (method == 'B0') error <- try(obj <- perform_differential_analysis_para_single(taxon.abund, ldep, grp.name, adj.name, subject, df, method='B0', LRT, ...)) 
			if (method == 'B') error <- try(obj <- perform_differential_analysis_para_single(taxon.abund, ldep, grp.name, adj.name, subject, df, method='B', LRT, ...)) 
			if (method == 'QB') error <- try(obj <- perform_differential_analysis_para_single(taxon.abund, ldep, grp.name, adj.name, subject, df, method='QB', LRT, ...)) 
			######## Overdispersed Poisson regression #########	
			if (method == 'OP') error <- try(obj <- perform_differential_analysis_para_single(taxon.abund, ldep, grp.name, adj.name, subject, df, method='OP', LRT, ...)) 
			######## Negative binomial regression #########
			if (method == 'NB') error <- try(obj <- perform_differential_analysis_para_single(taxon.abund, ldep, grp.name, adj.name, subject, df, method='NB', LRT, ...)) 
			######## Zeroinflated negbinomial regression 1 ########
			if (method == 'ZINB') error <- try(obj <- perform_differential_analysis_para_single(taxon.abund, ldep, grp.name, adj.name, subject, df, method=ZINB, LRT, ...)) 
			
			# Adpative 0 selects OP and QB based on the zero proportion (Not optimal)
			if (method == 'Adaptive0') {
				temp <- mean(as.numeric(taxon.abund != 0))
				
				if (temp > zerop.cutoff) {
					error <- try(obj <- perform_differential_analysis_para_single(taxon.abund, ldep, grp.name, adj.name, subject, df, method='QB', LRT, ...)) 
				} else {
					error <- try(obj <- perform_differential_analysis_para_single(taxon.abund, ldep, grp.name, adj.name, subject, df, method='OP', LRT, ...)) 
				}
			}
			
			# Adpative 1 selects NB and ZIB based on AIC
			if (method == 'Adaptive1') {
				error1 <- try(obj1 <- perform_differential_analysis_para_single(taxon.abund, ldep, grp.name, adj.name, subject, df, method='NB', LRT, ...)) 
				error2 <- try(obj2 <- perform_differential_analysis_para_single(taxon.abund, ldep, grp.name, adj.name, subject, df, method=ZINB, LRT, ...)) 
				if (class(error1) != 'try-error' & class(error2) != 'try-error') {
					if (obj1$aic < obj2$aic) {
						obj <- obj1
					} else {
						obj <- obj2
					}
					error <- error1
				} else {
					# pv == 0 indicates some problems in fitting
					if (class(error1) != 'try-error' & obj1$pv != 0) {
						obj <- obj1
						error <- error1
					} else {
						if (class(error2) != 'try-error' & obj1$pv != 0) {
							obj <- obj2
							error <- error2
						} else {
							error <- error2
						}
					}
				}	
			}
			
			# Adaptive 2 starts with NB model, if it fails, it switches ZINB
			if (method == 'Adaptive2') {
				error1 <- try(obj1 <- perform_differential_analysis_para_single(taxon.abund, ldep, grp.name, adj.name, subject, df, method='NB', LRT, ...)) 
				
				if (class(error1) == 'try-error' | obj1$pv == 0) {
					error2 <- try(obj2 <- perform_differential_analysis_para_single(taxon.abund, ldep, grp.name, adj.name, subject, df, method=ZINB, LRT, ...)) 
					if (class(error2) != 'try-error') {
						obj <- obj2
						error <- error2
					} else {
						error <- error2
					}
				} else {
					error <- error1
					obj <- obj1
				}
				
			}
			
			# Random Effects model 
			# ZINB, B, NB, Adpative1 is implemented based on glmmADMB
			
            # Set P value NA for those not makes sense
			if (class(error) == "try-error" | abs(obj$lfc) > 100) {
				obj$pv <- obj$lfc <- obj$lfc.lci <- obj$lfc.uci <- obj$method <- NA
			}
			
			
			pv.vec <- rbind(pv.vec, obj$pv)
			fc.vec <- rbind(fc.vec, obj$lfc)
			fc.lc.vec <- rbind(fc.lc.vec, obj$lfc.lci)
			fc.uc.vec <- rbind(fc.uc.vec, obj$lfc.uci)
			met.vec <- rbind(met.vec, obj$method)
			
		}
		cat('\n')

		qv.vec <- matrix(p.adjust(pv.vec[, 1], 'fdr'), ncol=1)
		
		rownames(pv.vec) <- rownames(qv.vec) <- rownames(fc.vec) <- rownames(fc.uc.vec) <- rownames(fc.lc.vec) <- rownames(met.vec) <- rownames(prop)
		colnames(pv.vec) <- 'Pvalue'
		colnames(qv.vec) <- 'Qvalue'
        colnames(met.vec) <- 'Method'

		
		pv.list[[LOI]] <- pv.vec
		qv.list[[LOI]] <- qv.vec
		fc.list[[LOI]] <- fc.vec
		fc.lc.list[[LOI]] <- fc.lc.vec
		fc.uc.list[[LOI]] <- fc.uc.vec
		met.list[[LOI]] <- met.vec
 
		res <- cbind(pv.vec, qv.vec, fc.vec, fc.lc.vec, fc.uc.vec, met.vec)
		rownames(res) <- rownames(prop)
		write.csv(res, paste0("Taxa_DifferentialAbundanceAnalysis_", LOI, "_", ann, ".csv"))
		
		if (mt.method == 'fdr') {
			res.final <- rbind(res.final, res[as.numeric(res[, 'Qvalue']) <= cutoff, , drop=F])
		}
		if (mt.method == 'raw') {
			res.final <- rbind(res.final, res[ as.numeric(res[, 'Pvalue']) <= cutoff, , drop=F])
		}
	}
	
	if (!is.null(res.final)) {
		colnames(res.final) <- colnames(res)
		res.final <- res.final[rowSums(is.na(res.final)) == 0, , drop=F]
		write.csv(res.final, paste0("Taxa_DifferentialAbundanceAnalysis_AllLevels_", mt.method, '_', cutoff, "_", ann, ".csv"))
	}
	return(list(pv.list=pv.list, qv.list=qv.list, fc.list=fc.list, fc.uc.list=fc.uc.list, fc.lc.list=fc.lc.list, met.list=met.list))
}


plot_effect_size <- function (month,  value, pos.lab, neg.lab, ylab, hjust1=1.3, hjust2=-0.3, lab.size=3, xsize=10) {
	month <- factor(month, levels=month)
	dtm <- data.frame(month=month, value=value)
	dtm$colour <- factor(ifelse(dtm$value < 0, neg.lab, pos.lab), levels=c(pos.lab, neg.lab))
	dtm$hjust <- ifelse(dtm$value > 0, hjust1, hjust2)
	obj <- ggplot(dtm, aes(month, value, label = month, hjust = hjust)) + 
			geom_text(aes(y = 0, colour = colour), size=lab.size) + 
			geom_bar(stat = "identity", aes(fill = colour)) +
			theme(axis.text.x = element_text(size=xsize)) +
            ylim(c(-max(abs(value))*1.1, max(abs(value))*1.1)) + 
			coord_flip() +
			scale_x_discrete(breaks = NULL) +
			labs(x = "", y = ylab) +
			theme(legend.position="top", legend.title=element_blank())
}


plot_effect_size2 <- function (fold.dat.plot1, ylabel='log(Fold change)', is.ln = TRUE, ord = TRUE, yint = 0) {
	
	if (is.ln) {
		fold.dat.plot1[, c('Estimate', 'LCI', 'UCI')] <- fold.dat.plot1[, c('Estimate', 'LCI', 'UCI')] * log2(exp(1))
	}
	Alphas <- seq(1, 99, 2) / 100
#Multiplier <- qnorm(1 - Alphas / 2)
	Multiplier <- seq(1, 0.01, len=50)
	zzTransparency <<- 1/(length(Multiplier)/4)
	
#	fold.dat.plot1 <- data.frame(IV=rownames(fold.dat.plot), Estimate=fold.dat.plot[, 1], LCI=fold.dat.plot[, 2], UCI=fold.dat.plot[, 3])
	fold.dat.plot1 <- data.frame(cbind(fold.dat.plot1, Scalar=rep(Multiplier, each = nrow(fold.dat.plot1))))
#	fold.dat.plot1[,  -1] <- apply(fold.dat.plot1[, -1], 2, function(x){as.numeric(as.character(x))})
	fold.dat.plot1$Emphasis <- by(1 - seq(0, 1, length = length(Multiplier) + 1)[-(length(Multiplier) + 1)],
			as.character(round(Multiplier, 5)), mean)[as.character(round(fold.dat.plot1$Scalar, 5))]
	
	fold.dat.plot1$IV <- factor(fold.dat.plot1$IV, unique(fold.dat.plot1$IV))
	
	if (ord) {
		fold.dat.plot1 <- fold.dat.plot1[order(as.character(fold.dat.plot1$IV)), ]
	}
	
	OutputPlot <- ggplot2::qplot(data = fold.dat.plot1, x = IV, y = Estimate,
			ymin = Estimate - (Estimate -LCI)*Scalar, ymax = Estimate + (UCI - Estimate)*Scalar,
			ylab = NULL, xlab = NULL, alpha = I(zzTransparency), colour = I(gray(0)), geom = "blank")
	
	OutputPlot <- OutputPlot + geom_hline(yintercept = yint, lwd = I(7/12), colour = I(hsv(0/12, 7/12, 7/12)), alpha = I(5/12))
	OutputPlot <- OutputPlot + geom_linerange(data = fold.dat.plot1, aes(size = 1/Emphasis), alpha = I(zzTransparency), colour = I(gray(0)))
	OutputPlot <- OutputPlot + scale_size_continuous() + guides(size=FALSE)
#OutputPlot <- OutputPlot + facet_grid(~ ModelName)
	OutputPlot <- OutputPlot + coord_flip() + geom_point(aes(x = IV, y = Estimate), colour = I(gray(0))) + theme_bw() + ylab(ylabel)
}

# Rev: 2016_11_25 Uniqufy
# Rev: 2016_04_18 strata


# New: 2020_02_20  for survival
plot_effect_size3 <- function (fold.dat.plot1, ylabel = 'HR',  ord.type = c('effect', 'taxa'), yint = 1) {
	
	ord.type <- match.arg(ord.type)
	
	Alphas <- seq(1, 99, 2) / 100
#Multiplier <- qnorm(1 - Alphas / 2)
	Multiplier <- seq(1, 0.01, len=50)
	zzTransparency <<- 1/(length(Multiplier)/4)
	
#	fold.dat.plot1 <- data.frame(IV=rownames(fold.dat.plot), Estimate=fold.dat.plot[, 1], LCI=fold.dat.plot[, 2], UCI=fold.dat.plot[, 3])
	fold.dat.plot1 <- data.frame(cbind(fold.dat.plot1, Scalar=rep(Multiplier, each = nrow(fold.dat.plot1))))
#	fold.dat.plot1[,  -1] <- apply(fold.dat.plot1[, -1], 2, function(x){as.numeric(as.character(x))})
	fold.dat.plot1$Emphasis <- by(1 - seq(0, 1, length = length(Multiplier) + 1)[-(length(Multiplier) + 1)],
			as.character(round(Multiplier, 5)), mean)[as.character(round(fold.dat.plot1$Scalar, 5))]
	
	fold.dat.plot1$IV <- factor(fold.dat.plot1$IV, unique(fold.dat.plot1$IV))
	
	if (ord.type == 'taxa') {
		fold.dat.plot1 <- fold.dat.plot1[order(as.character(fold.dat.plot1$IV)), ]
	}
	if (ord.type == 'effect') {
		fold.dat.plot1 <- fold.dat.plot1[order(as.character(fold.dat.plot1$Estimate)), ]
	}
	
	OutputPlot <- ggplot2::qplot(data = fold.dat.plot1, x = IV, y = Estimate,
			ymin = Estimate - (Estimate -LCI) * Scalar, ymax = Estimate + (UCI - Estimate)*Scalar,
			ylab = NULL, xlab = NULL, alpha = I(zzTransparency), colour = I(gray(0)), geom = "blank")
	
	OutputPlot <- OutputPlot + geom_hline(yintercept = yint, lwd = I(7/12), colour = I(hsv(0/12, 7/12, 7/12)), alpha = I(5/12))
	OutputPlot <- OutputPlot + geom_linerange(data = fold.dat.plot1, aes(size = 1/Emphasis), alpha = I(zzTransparency), colour = I(gray(0)))
	OutputPlot <- OutputPlot + scale_size_continuous() + guides(size=FALSE)
#OutputPlot <- OutputPlot + facet_grid(~ ModelName)
	OutputPlot <- OutputPlot + coord_flip() + geom_point(aes(x = IV, y = Estimate), colour = I(gray(0))) + theme_bw() + ylab(ylabel)
}


# Rev: 2020_03_08 Add support for numeric grp.name.n 
visualize_differential_analysis <- function (data.obj, diff.obj,  grp.name=NULL, grp.name.n = NULL,  strata=NULL, test='Nonpara', mt.method='fdr', scale='sqrt', cutoff=0.15,
		taxa.levels=c('Phylum', 'Family', 'Genus'), ord=TRUE, eff.type='logP', indivplot=TRUE, colFnsC=NULL, colFnsF=NULL, subject=NULL,
		xsize=10, ann='', hei1=NULL, wid1=NULL, hei2=NULL, wid2=NULL) {
	
	# uniquefy names
	# For backward compatibility. Newer version will not need this and below. The old version has 'unclassified' which leads to duplicate names.
	# Newer version has 'Unclassified'. Case difference.
	
	# Check whether there is name duplication
	check.names <- NULL
	
	obj0 <- diff.obj[[1]]
	for (level in names(obj0)) {
		obj <- obj0[[level]]
		# rownames(obj) <- gsub('unclassified', paste0('Unclassified',substr(level, 1, 1)), rownames(obj))
		check.names <- c(check.names, rownames(obj))
	}
	
	if (sum(table(check.names) >= 2)) {
		data.obj <- uniquefy_taxa_names(data.obj)
		
		for (name1 in names(diff.obj)) {
			obj0 <- diff.obj[[name1]]
			for (level in names(obj0)) {
				obj <- obj0[[level]]
				# rownames(obj) <- gsub('unclassified', paste0('Unclassified',substr(level, 1, 1)), rownames(obj))
				rownames(obj) <- paste0(rownames(obj), substr(level, 1, 1))
				obj0[[level]] <- obj
			}
			diff.obj[[name1]] <- obj0
		}
		
	}

	#pv.list <- diff.obj$pv.list
	fc.list <- diff.obj$fc.list

	if (mt.method == 'fdr.perm') {
		qv.list <- diff.obj$qv.perm.list
	} else {
		qv.list <- diff.obj$qv.list
	}
	
	pv.list <- diff.obj$pv.list
	if (test == 'Para') {
		fc.lc.list <- diff.obj$fc.lc.list
		fc.uc.list <- diff.obj$fc.uc.list
	}
	
	R2.list <- diff.obj$R2.list
	
	df <- data.obj$meta.dat
	grp <- df[, grp.name]
	
	
	if (!is.null(grp.name.n)) {
		grp.n <- df[, grp.name.n]
	}
	
	ind <- !is.na(grp)
	data.obj <- subset_data(data.obj, ind)
	grp <- grp[ind]
	df <- df[ind, ]
	
	prop <- NULL
	eff <- eff.lc <- eff.uc <- R2 <- NULL
	taxa.names <- NULL
	if (is.null(taxa.levels)) {
		LOIs <- names(qv.list)
	} else {
		LOIs <- taxa.levels
		if (sum(!(taxa.levels %in% names(qv.list)))) {
			stop('Taxa levels are not contained in differential abundance analysis results!\n')
		}
	}
	for (LOI in LOIs) {
		pv.vec <- pv.list[[LOI]]
		fc.vec <- fc.list[[LOI]]
		#qv.vec <- qvalue(pv.vec[, 1])$qvalues
		qv.vec <- qv.list[[LOI]]
		
		if (!is.null(R2.list)) R2.vec <- R2.list[[LOI]]
		
		if (test == 'Para') {
			fc.lc.vec <- fc.lc.list[[LOI]]
			fc.uc.vec <- fc.uc.list[[LOI]]
		}
		
		if (mt.method %in% c('fdr', 'fdr.perm')) {
			taxa.name <- rownames(qv.vec)[qv.vec <= cutoff]
			taxa.name <- taxa.name[!is.na(taxa.name)]
		}
		
		if (mt.method == 'raw') {
			taxa.name <- rownames(pv.vec)[pv.vec <= cutoff]
			taxa.name <- taxa.name[!is.na(taxa.name)]
		}
		
		if (length(taxa.name) != 0) {
			prop0 <- data.obj$abund.list[[LOI]]
			prop0 <- t(t(prop0) / colSums(prop0))
			prop0 <-  prop0[taxa.name, , drop=F]
			if (ord == TRUE) {
				prop0 <- prop0[rev(order(rowMeans(prop0))), , drop=F]
			}
			prop <- rbind(prop, prop0)
			# currently using fold change
		    if (test == 'Para') {
				eff <- rbind(eff, fc.vec[taxa.name, , drop=F])
				eff.lc <- rbind(eff.lc, fc.lc.vec[taxa.name, , drop=F])
				eff.uc <- rbind(eff.uc, fc.uc.vec[taxa.name, , drop=F])
			} else {
				if (eff.type %in% c('LFC', 'Spearman')) {
					eff <- c(eff, fc.vec[taxa.name, ])
				}
				if (eff.type == 'logP') {
					eff <- c(eff, sign(fc.vec[taxa.name, ]) * (-log10(pv.vec[taxa.name, ])))
				}
				if (!is.null(R2.list)) R2 <- c(R2, R2.vec[taxa.name, ])
				
			}
			taxa.names <- c(taxa.names, taxa.name)
		}
	}
	
	if (length(taxa.names) == 0) {
		cat('No differential taxa! \n')
	} else {
		if (length(taxa.names) >= 2) {
			if (is.null(wid1) | is.null(hei1)) {
				wid1 <- 7 * ifelse(nrow(prop) / 30 < 1, 1, nrow(prop) / 30)
				hei1 <- 7
			}
	
			if (!is.null(grp.name)) {
				obj <- taxa_barplot_aggregate(prop, df, grp.name, strata, scale, xsize)
				pdf(paste("Taxa_DifferentialAbundance_AbundanceBarplot", scale, mt.method, cutoff, ann, ".pdf", sep="_"), height=hei1, width=wid1)
				print(obj)
				dev.off()
				
				obj1 <- taxa_boxplot_aggregate(prop, df, grp.name, strata, scale, xsize) 
				pdf(paste("Taxa_DifferentialAbundance_AbundanceBoxplot", scale, mt.method, cutoff, ann, ".pdf", sep="_"), height=hei1, width=wid1)
				print(obj1)
				dev.off()

			}

			# currently fold change
		    if (test == 'Para') {
				rownames(eff) <- rownames(eff.lc) <- rownames(eff.uc) <- taxa.names
				for (k in 1:ncol(eff)) {
					fold.dat.plot1 <- data.frame(Estimate=eff[, k], LCI=eff.lc[, k], UCI=eff.uc[, k], IV=taxa.names)
					obj <- plot_effect_size2(fold.dat.plot1)
					pdf(paste("Taxa_DifferentialAbundance_EffectBarplot", colnames(eff)[k], mt.method, cutoff, ann, ".pdf", sep="_"), height=hei2, width=wid2)
					print(obj)
					dev.off()
				}
			} else {
				if (!is.na(eff[1])) {
					names(eff) <- taxa.names
					eff <- eff[!is.na(eff) & is.finite(eff)]
					eff <- sort(eff)
					taxa.names2 <- names(eff)
					if (is.null(wid2) | is.null(hei2)) {
						hei2 <- 4 + length(taxa.names2) / 20 * 3 
						wid2 <- 6
					}
					if (eff.type == 'LFC') {
						obj <- plot_effect_size(taxa.names2, eff, levels(grp)[1], levels(grp)[2], ylab='Log2 fold change')
						pdf(paste("Taxa_DifferentialAbundance_LFCBarplot", mt.method, cutoff, ann, ".pdf", sep="_"), height=hei2, width=wid2)
						print(obj)
						dev.off()	
					}

					if (eff.type == 'Spearman') {
						obj <- plot_effect_size(taxa.names2, eff, levels(grp)[1], levels(grp)[2], ylab='Spearman correlation')
						pdf(paste("Taxa_DifferentialAbundance_SpearmanBarplot", mt.method, cutoff, ann, ".pdf", sep="_"), height=hei2, width=wid2)
						print(obj)
						dev.off()	
					}
					
					if (eff.type == 'logP') {
						obj <- plot_effect_size(taxa.names2, eff, levels(grp)[1], levels(grp)[2], ylab='-log10(P)')
						pdf(paste("Taxa_DifferentialAbundance_logPBarplot", mt.method, cutoff, ann, ".pdf", sep="_"), height=hei2, width=wid2)
						print(obj)
						dev.off()	
					}	
					
					if (!is.null(R2.list))   {
						R2 <- sort(R2, decr=TRUE)
						taxa <- names(R2)
						taxa <- factor(taxa, levels=taxa)
						df <- data.frame(taxa = taxa, R2 = R2)
						obj <- ggplot(df, aes(taxa, R2)) + geom_col(fill='steelblue', col='gray', size=0.25) + ylab(expression(R^2)) + xlab('') +
								theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))
						pdf(paste("Taxa_DifferentialAbundance_R2_Barplot", mt.method, cutoff, ann, ".pdf", sep="_"), height=wid2, width=hei2)
						print(obj)
						dev.off()
						
					}

					
				}
			}
			
			# create heatmp
#			taxa.names2 <- taxa.names[!grepl('unclassified', taxa.names, ignore.case=T)]
			if (!is.null(grp.name)) {
				
				generate_taxa_heatmap(data.obj, taxa.levels='All', sam.ord=order(grp), taxa=taxa.names, meta.info=c(grp.name, strata), Colv=F, dendrogram='row', 
						ann=paste0(mt.method, '_', cutoff, '_', ann, '_Unclustered'), colFnsC=colFnsC, colFnsF=colFnsF)
				generate_taxa_heatmap(data.obj, taxa.levels='All', taxa=taxa.names, meta.info=c(grp.name, strata),  ann=paste0(mt.method, '_', cutoff, '_', ann), colFnsC=colFnsC, colFnsF=colFnsF)
				generate_taxa_heatmap(data.obj, taxa.levels='All', taxa=taxa.names, meta.info=c(grp.name, strata), data.type='R', ann=paste0(mt.method, '_', cutoff, '_Rank_', ann), colFnsC=colFnsC, colFnsF=colFnsF)
				try(
						generate_taxa_biplot(data.obj, taxa=taxa.names, trans='sqrt', grp.name, ann=paste0(mt.method, '_', cutoff, '_', ann), varname.size = 1.5)	
				)	
			}
		}
		if (!is.null(grp.name)) {
			# Individual plots
	        if (indivplot == TRUE) {
				generate_taxa_boxplot(data.obj, grp.name=grp.name, taxa.levels='All', strata = strata, taxa.name=taxa.names, ann=paste0(mt.method, '_', cutoff, '_', ann))
				if (!is.null(subject)) {
					generate_taxa_boxplot(data.obj, grp.name=grp.name, taxa.levels='All', strata = strata, taxa.name=taxa.names, subject=subject, ann=paste0(mt.method, '_', cutoff, '_', ann, '_Paired'))
				}
				generate_taxa_boxplot(data.obj, grp.name=grp.name, taxa.levels='All', strata = strata, taxa.name=taxa.names, scale='binary', ann=paste0(mt.method, '_', cutoff, '_', ann))
				generate_taxa_barplot(data.obj, grp.name=grp.name, taxa.levels='All', strata = strata, taxa.name=taxa.names, ann=paste0(mt.method, '_', cutoff, '_', ann))
				
				if (!is.null(grp.name.n)) {
					
					if (!is.null(strata)) {
						generate_taxa_scatterplot(data.obj, grp.name=grp.name.n, taxa.levels='All', strata=strata, combine.strata=FALSE, taxa.name=taxa.names, scale='sqrtP', 
								subject=subject, subject.pt=TRUE, ann=paste0(mt.method, '_', cutoff, '_s1_', ann))
						generate_taxa_scatterplot(data.obj, grp.name=grp.name.n, taxa.levels='All', strata=strata, combine.strata=TRUE,  taxa.name=taxa.names, scale='sqrtP',
								subject=subject,  subject.pt=TRUE, ann=paste0(mt.method, '_', cutoff, '_s2_', ann))
					} else {
						generate_taxa_scatterplot(data.obj, grp.name=grp.name.n, taxa.levels='All', taxa.name=taxa.names, scale='sqrtP', 
								subject=subject, subject.pt=TRUE, ann=paste0(mt.method, '_', cutoff, '_', ann))
					}

					
					
				}
			}
			
		}
	}
}

# TODO: Add comment
# 
# Author: jchen1981
###############################################################################
###############################################################################
# New: 2020_02_20
perform_survival_analysis_para <- function (data.obj, obstime.name, delta.name, adj.name = NULL, subject = NULL, 
		RE = FALSE, method = 'cph', 
		taxa.levels = c('Phylum', 'Order', 'Class', 'Family', 'Genus', 'Species'), transform = c('sqrt', 'binary'),
		winsor = TRUE, winsor.qt = 0.97, 
		norm = 'GMPR', norm.level = 'Species', intersect.no=4, ct.min = 2,
		prev = 0.1, minp = 0.002, 
		mt.method = 'fdr', cutoff = 0.1049, ann = '', ...) {
	
	transform <- match.arg(transform)
	# To be completed
	# subject holds the random effects formula
	if (!RE) {
		if (!(method %in% c('cph'))) stop('The speficied method is not supported!\n')
		if (!is.null(subject)) warning('subject will not be used. Are you sure you want to run fixed effects model? ')
	} else {
		if (!(method %in% c('cph'))) stop('The speficied method does not have random effects implementation!\n')
		if (is.null(subject)) stop('subject is not supplied!\n')
	}
	
	# Regression model will handle NA automatically
	df <- data.obj$meta.dat
	obstime <- df[, obstime.name]
	delta <- df[, delta.name]
	
	
	if ('Species' %in% taxa.levels & !('Species' %in% names(data.obj$abund.list))) {
		data.obj$abund.list[['Species']] <- data.obj$otu.tab
		rownames(data.obj$abund.list[['Species']]) <- paste0("OTU", rownames(data.obj$otu.tab), ":", 
				data.obj$otu.name[, 'Phylum'], ";", data.obj$otu.name[, 'Genus'])
	}
	
	dep <- colSums(data.obj$otu.tab)
	diff.seq.p <- coef(summary(coxph(Surv(obstime, delta) ~  dep)))[1, 'Pr(>|z|)']
	
	if (!is.na(diff.seq.p) & diff.seq.p <= 0.05) {
		warning("Sequencing depth is signficantly correlated with surival times!\n")
	}
	
	if (norm == 'Precalculated') {
		dep <- data.obj$size.factor
	}
	
	if (norm == 'GMPR') {
		if (norm.level %in% c('OTU', 'Species', 'ASV')) {
			tab <- data.obj$otu.tab
		} else {
			tab <- data.obj$abund.list[[norm.level]]
		}
		
		dep <- GMPR(tab, intersect.no, ct.min)
		
		ind <- !is.na(dep)
		data.obj <- subset_data(data.obj, ind)
		obstime <- obstime[ind]
		delta <- delta[ind]
		df <- df[ind, ]
		dep <- dep[ind]	
	}
	
	if (norm == 'TSS') {
		dep <- colSums(data.obj$otu.tab)
	}
	
	ldep <- log(dep)
	
	pv.list <- qv.list <-  hr.list <- hr.lc.list <- hr.uc.list <- met.list <- list()
	res.final <- NULL
	
	for (LOI in taxa.levels) {
		cat(LOI, "\n")
		taxon.ct <- data.obj$abund.list[[LOI]]
		
		if (winsor == TRUE) {
			# Addressing the outlier (97% percent) or at least one outlier
			taxon.ct.p <- t(t(taxon.ct) / dep)
			taxon.ct.p <- apply(taxon.ct.p, 1, function(x) {
						cutoff <- quantile(x, winsor.qt)
						x[x >= cutoff] <- cutoff
						x
					}
			)
			# column/row switch
			taxon.ct <- t(round(taxon.ct.p * dep))
		}
		
		# original relative abundance
		prop <- t(t(taxon.ct) / colSums(taxon.ct))
		
		if (!is.null(prev)) {
			prop <- prop[rowSums(prop != 0) > prev * ncol(prop), , drop = FALSE]	
			taxon.ct <- taxon.ct[rownames(prop), , drop = FALSE]
		}
		
		if (!is.null(minp)) {
			prop <- prop[rowMaxs(prop) > minp, , drop = FALSE]	
			taxon.ct <- taxon.ct[rownames(prop), , drop = FALSE]
		}
		
#		if (!is.null(medianp)) {
#			nz.mean <- apply(prop, 1, function(x) median(x[x!=0]))
#			prop <- prop[nz.mean > medianp, , drop=FALSE]	
#			taxon.ct <- taxon.ct[rownames(prop), , drop=FALSE]
#		}
#		
#		if (!is.null(cv)) {
#			prop <- prop[rowSds(prop) / rowMeans(prop) > cv, , drop=FALSE]	
#			taxon.ct <- taxon.ct[rownames(prop), , drop=FALSE]
#		}
#		
		pv.vec <-  hr.vec <- hr.lc.vec <- hr.uc.vec <- met.vec <- conv.vec <- NULL
		obj <- NULL
		
		for (taxon in rownames(taxon.ct)) {
			cat('.')
			
			taxon.abund <- taxon.ct[taxon, ]
			# cox proportional hazard model
			if (!RE) {
				if (method == 'cph') {
					error <- try({
								obj <- survival_cph_fe(taxon.abund, dep, transform, obstime.name, delta.name, adj.name,  df, ...)
							}
					)
				}		
			}
			# Set P value NA for those not makes sense
			if (class(error) == "try-error") {
				obj$pv <- obj$hr <- obj$hr.lci <- obj$hr.uci <- obj$method <- NA
			}
			
			pv.vec <- rbind(pv.vec, obj$pv)
			hr.vec <- rbind(hr.vec, obj$hr)
			hr.lc.vec <- rbind(hr.lc.vec, obj$hr.lci)
			hr.uc.vec <- rbind(hr.uc.vec, obj$hr.uci)
			met.vec <- rbind(met.vec, obj$method)
			
		}
		cat('\n')
		qv.vec <- matrix(p.adjust(pv.vec[, 1], 'fdr'), ncol=1)
		
		rownames(pv.vec) <- rownames(qv.vec) <- rownames(hr.vec) <- rownames(hr.uc.vec) <- rownames(hr.lc.vec) <- rownames(met.vec) <- rownames(prop)
		colnames(pv.vec) <- 'Pvalue'
		colnames(qv.vec) <- 'Qvalue'
		colnames(met.vec) <- 'Method'
		
		pv.list[[LOI]] <- pv.vec
		qv.list[[LOI]] <- qv.vec
		hr.list[[LOI]] <- hr.vec
		hr.lc.list[[LOI]] <- hr.lc.vec
		hr.uc.list[[LOI]] <- hr.uc.vec
		met.list[[LOI]] <- met.vec
		
		res <- cbind(pv.vec, qv.vec, hr.vec, hr.lc.vec, hr.uc.vec, met.vec)
		
		rownames(res) <- rownames(prop)
		
		write.csv(res, paste0("Taxa_SurvivalAnalysis_", LOI, "_", ann, ".csv"))
		
		if (mt.method == 'fdr') {
			res.final <- rbind(res.final, res[as.numeric(res[, 'Qvalue']) <= cutoff, , drop=F])
		}
		
		if (mt.method == 'raw') {
			res.final <- rbind(res.final, res[as.numeric(res[, 'Pvalue']) <= cutoff, , drop=F])
		}
	}
	
	if (!is.null(res.final)) {
		colnames(res.final) <- colnames(res)
		res.final <- res.final[rowSums(is.na(res.final)) == 0, , drop=F]
		write.csv(res.final, paste0("Taxa_SurvivalAnalysis_AllLevels_", mt.method, '_', cutoff, "_", ann, ".csv"))
	}
	return(list(pv.list = pv.list, qv.list = qv.list, hr.list = hr.list, 
					hr.uc.list = hr.uc.list, hr.lc.list = hr.lc.list, met.list = met.list))
}

# New: 2020_02_20
# CPH for fixed effects
survival_cph_fe <- function(taxon.abund, depth, transform = c('sqrt', 'binary'), obstime.name, delta.name, adj.name,  df, ...) {
	
	if (transform == 'sqrt') abundance <- scale(sqrt(taxon.abund / depth))
	if (transform == 'binary') abundance <- as.numeric(taxon.abund == 0)
	
	if (length(grep('abundance', adj.name)) != 0) {
		stop('The adj.name should not contain "abundance"!\n')
	}
	
	obstime <- df[, obstime.name]
	delta <- df[, delta.name]
	if (is.null(adj.name)) {
		obj <- coxph(Surv(obstime, delta) ~ abundance) 
	} else {
		X <- scale(model.matrix(~. , df[, adj.name])[, -1])
		obj <- coxph(Surv(obstime, delta) ~ X + abundance) 
	}
	
	tab <- coef(summary(obj))
	tab <- tab[grep('abundance', rownames(tab)), ]
	
	res <- NULL
	res$pv <- tab["Pr(>|z|)"]
	res$hr <- tab["exp(coef)"]
	res$hr.lci <- exp(tab["coef"] - 1.96 * tab["se(coef)"])
	res$hr.uci <- exp(tab["coef"] + 1.96 * tab["se(coef)"])
	names(res$hr.lci) <- paste('2.5%')
	names(res$hr.uci) <- paste('97.5%')
	res$method <- 'cph(fe)'
	
	return(res)
}

visualize_survival_analysis <- function (data.obj, surv.obj,  mt.method = 'fdr', cutoff = 0.1049,
		taxa.levels=c('Phylum', 'Class', 'Order', 'Family', 'Genus'), 
		indivplot = FALSE, wid2 = NULL, hei2 = NULL, ann = '') {
	
	# uniquefy names
	# For backward compatibility. Newer version will not need this and below. The old version has 'unclassified' which leads to duplicate names.
	# Newer version has 'Unclassified'. Case difference.
	
	# Check whether there is name duplication
	check.names <- NULL
	
	obj0 <- surv.obj[[1]]
	for (level in names(obj0)) {
		obj <- obj0[[level]]
		# rownames(obj) <- gsub('unclassified', paste0('Unclassified',substr(level, 1, 1)), rownames(obj))
		check.names <- c(check.names, rownames(obj))
	}
	
	if (sum(table(check.names) >= 2)) {
		data.obj <- uniquefy_taxa_names(data.obj)
		
		for (name1 in names(surv.obj)) {
			obj0 <- surv.obj[[name1]]
			for (level in names(obj0)) {
				obj <- obj0[[level]]
				# rownames(obj) <- gsub('unclassified', paste0('Unclassified',substr(level, 1, 1)), rownames(obj))
				rownames(obj) <- paste0(rownames(obj), substr(level, 1, 1))
				obj0[[level]] <- obj
			}
			surv.obj[[name1]] <- obj0
		}
		
	}
	
	qv.list <- surv.obj$qv.list
	hr.list <- surv.obj$hr.list
	pv.list <- surv.obj$pv.list
	
	
	hr.lc.list <- surv.obj$hr.lc.list
	hr.uc.list <- surv.obj$hr.uc.list
	
	df <- data.obj$meta.dat
	
	eff <- eff.lc <- eff.uc <- NULL
	taxa.names <- NULL
	if (is.null(taxa.levels)) {
		LOIs <- names(qv.list)
	} else {
		LOIs <- taxa.levels
		if (sum(!(taxa.levels %in% names(qv.list)))) {
			stop('Taxa levels are not contained in survival analysis results!\n')
		}
	}
	for (LOI in LOIs) {
		pv.vec <- pv.list[[LOI]]
		hr.vec <- hr.list[[LOI]]
		qv.vec <- qv.list[[LOI]]
		
		
		hr.lc.vec <- hr.lc.list[[LOI]]
		hr.uc.vec <- hr.uc.list[[LOI]]
		
		if (mt.method %in% c('fdr')) {
			taxa.name <- rownames(qv.vec)[qv.vec <= cutoff]
			taxa.name <- taxa.name[!is.na(taxa.name)]
		}
		
		if (mt.method == 'raw') {
			taxa.name <- rownames(pv.vec)[pv.vec <= cutoff]
			taxa.name <- taxa.name[!is.na(taxa.name)]
		}
		
		if (length(taxa.name) != 0) {
			
			eff <- rbind(eff, hr.vec[taxa.name, , drop=F])
			eff.lc <- rbind(eff.lc, hr.lc.vec[taxa.name, , drop=F])
			eff.uc <- rbind(eff.uc, hr.uc.vec[taxa.name, , drop=F])
			
			taxa.names <- c(taxa.names, taxa.name)
		}
	}
	
	if (length(taxa.names) == 0) {
		cat('No taxa associated with survival times! \n')
	} else {
		if (length(taxa.names) >= 2) {
			if (is.null(hei2)) {
				hei2 <- 4 + length(taxa.names) / 20 * 3 
				wid2 <- 6
			}
			rownames(eff) <- rownames(eff.lc) <- rownames(eff.uc) <- taxa.names
			for (k in 1:ncol(eff)) {
				fold.dat.plot1 <- data.frame(Estimate=eff[, k], LCI = eff.lc[, k], UCI = eff.uc[, k], IV = taxa.names)
				obj <- plot_effect_size3(fold.dat.plot1)
				pdf(paste("Taxa_Survival_HRBarplot", colnames(eff)[k], mt.method, cutoff, ann, ".pdf", sep="_"), height = hei2, width = wid2)
				print(obj)
				dev.off()
			}
			
		} 
	}
	cat('Visualization completed!\n')
}

# Rev: 2016_12_07 when the names of some differential taxa are not consistent
# Rev: 2017_02_21  Color by log fold change m.list ->> fc.list
# To-do-list:  size by effects, accomodate OTU level
create_lefse_format <- function(data.obj, diff.obj, grp.name, mt.method='fdr', cutoff=0.15, prev=0.1, minp=0.002, 
		lefse.dir="/data2/microbiome/jeff/tools/nsegata-lefse/", ann="") {
	
	# To be improved - currently no effect size
	df <- data.obj$meta.dat
	grp <- df[, grp.name]
	levels(grp) <- paste0(1:nlevels(grp), levels(grp))

	qv.list <- diff.obj$qv.list
	pv.list <- diff.obj$pv.list
	fc.list <- diff.obj$fc.list
	
	otu.name.12 <- data.obj$otu.name
	otu.tab.12 <- data.obj$otu.tab
	tax.family.a <- NULL
	for (i in 1:6) {
		tax.family <- apply(otu.name.12[, 1:i, drop=F], 1, paste, collapse=".")
		phlan.tab <- aggregate(otu.tab.12, by=list(tax.family), FUN=sum)
		rownames(phlan.tab) <- phlan.tab[, 1]
		phlan.tab <- as.matrix(phlan.tab [, -1, drop=F])
		phlan.tab <- t(t(phlan.tab) / colSums(phlan.tab))	
		phlan.tab <- phlan.tab[rowSums(phlan.tab!=0) > prev*ncol(phlan.tab) & rowMaxs(phlan.tab) > minp, , drop=F]
		tax.family.a <- c(tax.family.a, rownames(phlan.tab))
		#tax.family.a <- c(tax.family.a, unique(tax.family))
	}
	alias.a <- sapply(strsplit(tax.family.a, "\\."), function(x) {
				if (length(x) >= 2) {
					if (length(x) == 2) {
						return(x[2])
					} else {
						return(paste0(x[2], ";", x[length(x)]))
					}
				} else {
					return(x)
				}
			})
	
	taxa.names <- NULL
	abundant.grp.names <- NULL
	
	for (LOI in setdiff(names(qv.list), 'Species')) {
		qv.vec <- qv.list[[LOI]]
		pv.vec <- pv.list[[LOI]]
		#qv.vec <- qvalue(pv.vec[, 1])$qvalues
		fc.vec <- fc.list[[LOI]]
		if (mt.method == 'fdr') {
			taxa.name <- rownames(qv.vec)[qv.vec <= cutoff]
		#	abundant.grp.name <- apply(m.vec, 1, function(x) levels(grp)[which.max(x)])[qv.vec <= cutoff]
			abundant.grp.name <- apply(fc.vec, 1, function(x) levels(grp)[as.numeric(x >= 0) + 1])[qv.vec <= cutoff]
		}

		if (mt.method == 'raw') {
			taxa.name <- rownames(pv.vec)[pv.vec <= cutoff]
		#	abundant.grp.name <- apply(m.vec, 1, function(x) levels(grp)[which.max(x)])[pv.vec <= cutoff]
		    abundant.grp.name <- apply(fc.vec, 1, function(x) levels(grp)[as.numeric(x >= 0) + 1])[pv.vec <= cutoff]
		}
		
		if (length(taxa.name) != 0) {
			taxa.names <- c(taxa.names, taxa.name)
			abundant.grp.names <- c(abundant.grp.names, abundant.grp.name)
		}
	}

	# remove 'unclassified'
    abundant.grp.names <- abundant.grp.names[!grepl('unclassified', taxa.names, ignore.case=T)]
	taxa.names <- taxa.names[!grepl('unclassified', taxa.names, ignore.case=T)]
	
	# Rev: 2016_12_07
#	taxa.names <- intersect(taxa.names, alias.a)

	ind <- match(taxa.names, alias.a)
	na.ind <- !is.na(ind)

	phlan <- cbind(tax.family.a, '1.5', '\t', '\t', '-')

	phlan[ind[na.ind], 2:5] <- cbind('3.5',  abundant.grp.names[na.ind], '3.0', '-')
	write.table(phlan,  paste0('Lefse.LDA.', ann, '.txt'), row.names=F, col.names=F, quote=F, sep='\t')
#	cmd1 <- paste0('python ', lefse.dir,  'plot_cladogram.py Lefse.LDA.txt Taxa_DifferentialAbundance_', mt.method, cutoff, '_Cladogram_', ann, '.pdf', ' --format pdf')
#	cmd2 <- paste0("python ", lefse.dir, 'plot_res.py Lefse.LDA.txt Taxa_DifferentialAbundance_', mt.method, cutoff, '_LDA_', ann, '.pdf --format pdf')
#	system(cmd1)
#	system(cmd2)
}

perform_lefse_analysis <- function (data.obj,  grp.name, sub.grp.name=NULL, prev=0.1, minp=0.002,
		lefse.dir="/data2/microbiome/jeff/tools/nsegata-lefse/", ann="") {
	otu.name.12 <- data.obj$otu.name
	otu.tab.12 <- data.obj$otu.tab
	meta.dat <- data.obj$meta.dat
	
	levels(meta.dat[, grp.name]) <- paste0(1:nlevels(meta.dat[, grp.name]), levels(meta.dat[, grp.name]))
	
	tax.family <- apply(otu.name.12, 1, paste, collapse="|")
	lefse.tab <- aggregate(otu.tab.12, by=list(tax.family), FUN=sum)
	rownames(lefse.tab) <- lefse.tab[, 1]
	lefse.tab <- as.matrix(lefse.tab [, -1])

	lefse.tab <- t(t(lefse.tab) / colSums(lefse.tab))
	
	lefse.tab <- lefse.tab[rowMaxs(lefse.tab) > minp & rowSums(lefse.tab!=0) > prev*ncol(lefse.tab), , drop=FALSE]

	if (is.null(sub.grp.name)) {
		header <- rbind(class=as.character(meta.dat[colnames(lefse.tab), grp.name]), 
				id=colnames(lefse.tab))
	} else {
		header <- rbind(class=as.character(meta.dat[colnames(lefse.tab), grp.name]), 
				subclass=as.character(meta.dat[colnames(lefse.tab), sub.grp.name]), 
				id=colnames(lefse.tab))
	}

	
	lefse.tab <- rbind(header, lefse.tab)
	write.table(lefse.tab, "lefse.txt", sep="\t", col.names=F, quote=F)
	
#	system(paste0('mkdir LefSe_', ann))
#	output <- paste0('LefSe_', ann, '/')
#	if (is.null(sub.grp.name)) {
#		cmd1 <- paste0("python ", lefse.dir, "format_input.py lefse.txt ", output, "temp.in ", "-c 1 -u 2 -o 1000000")
#	} else {
#		cmd1 <- paste0("python ", lefse.dir, "format_input.py lefse.txt ", output, "temp.in ", "-c 1 -s 2 -u 3 -o 1000000")
#	}
#
#	cmd2 <- paste0("python ", lefse.dir, "run_lefse.py ", output, "temp.in ",  output, "lda.res")
#	cmd3 <- paste0("python ", lefse.dir, "plot_res.py ",  output, "lda.res ", output, "lda.pdf --format pdf")
#	cmd4 <- paste0("python ", lefse.dir, "plot_cladogram.py ",  output, "lda.res ", output, "cladogram.pdf --format pdf --labeled_stop_lev 6 --abrv_stop_lev  6")
#	
#	system(cmd1)
#	system(cmd2)
#	system(cmd3)
#	system(cmd4)
}

plot.Boruta2 <- function (x, colCode = c("green", "yellow", "red", "blue"), sort = TRUE,
		whichShadow = c(TRUE, TRUE, TRUE), col = NULL, xlab = "Attributes", ids=NULL,
		ylab = "Importance", ...)
{
	if (class(x) != "Boruta")
		stop("This function needs Boruta object as an argument.")
	lz <- lapply(1:ncol(x$ImpHistory), function(i) x$ImpHistory[is.finite(x$ImpHistory[, i]), i])
	names(lz) <- colnames(x$ImpHistory)
	numShadow <- sum(whichShadow)
	lz <- lz[c(rep(TRUE, length(x$finalDecision)), whichShadow)]
	col <- Boruta:::generateCol(x, colCode, col, numShadow)
	if (sort) {
		ii <- order(sapply(lz, median))
		lz <- lz[ii]
		col <- col[ii]
	}
	names(lz) <- gsub("^X",  "", names(lz))
	if (is.null(ids)) {
		len <- sum(x$finalDecision %in% c('Confirmed', 'Tentative'))
		ind <- (length(lz) - len) : length(lz)
	} else {
		ind <- match(ids, names(lz))
	}
	
	boxplot(lz[ind], xlab = xlab, ylab = ylab, col = col[ind], ...)
	invisible(x)
	names(lz[ind])
}



createROC <- function (pv.list, lab.list, pos.lab='1', file.name='ROC.pdf', width = 6, height = 6) {
	require(ROCR)
	n <- length(pv.list)
	aucs <- numeric(n)
	names(aucs) <- names(pv.list)

#	cols <- scales::hue_pal()(n)
	cols <- rep(c('red', 'blue', 'orange', 'cyan', 'purple'), ceiling(n/5))[1:n]
	ltys <- rep(c(1, 2), ceiling(n/2))[1:n]
	pdf(file.name, height=6, width=6)
	for (i in 1:n) {
		
  		    cat("*")
			pv.mat <- pv.list[[i]]
			lab.mat <- lab.list[[i]]
			
			pred <- prediction(pv.mat, lab.mat==pos.lab)
			perf <- performance(pred, "tpr", "fpr")
			aucs[i] <- mean(unlist(performance(pred, 'auc')@y.values))
			plot(perf, avg="threshold", spread.estimate = 'stddev', spread.scale = 2,  col=cols[i], lty=ltys[i], lwd=1.5,  add=ifelse(i==1, FALSE, TRUE),  main='ROC curve')
				
		}
	abline(0, 1, col='black')
	legend("right", legend=paste0(names(pv.list), "(AUC:", round(aucs, 3), ")"), col=cols, lty=ltys, lwd=2,  bty="n")
	dev.off()
}

#invlogit <- function(x) {
#	rbinom(length(x), 1, exp(x) / (1 + exp(x)))
#}
#pv.list <- list(x1=rnorm(100), x2=rnorm(100))
#lab.list <- list(x1=invlogit(pv.list[['x1']]), x2=invlogit(pv.list[['x2']]))
#createROC(pv.list, lab.list)

# Rev: 2017_02_17 supply aug.var to decision tree
# Rev: 2017_11_08 Change formula
predictionRF <- function (data.obj,  resp.name, formula=NULL, taxa.level='Species', binary=FALSE, prev=0.1, minp=0.002, B=50, seed=123, 
		boruta.level=c('Confirmed', 'Tentative'), ann='',...) {

	#sink(paste0("Taxa_RandomForest_", taxa.level, ".txt"))
	date()
	response <- data.obj$meta.dat[, resp.name]
	
	if (!is.null(formula)) {
		# adj.var <- unlist(strsplit(unlist(strsplit(formula, '\\s*~\\s*'))[2], '\\s*\\+\\s*'))
		# adj <- data.obj$meta.dat[, adj.var, drop=F]
		adj <- model.matrix(as.formula(formula), data.obj$meta.dat)
		adj.var <- colnames(adj)
	} 

	if (taxa.level == 'Species') {
		if (taxa.level %in% names(data.obj$abund.list)) {
			ct <- data.obj$abund.list[[taxa.level]]
		} else {
			# Accomodate different version
			ct <- data.obj$otu.tab
			rownames(ct) <- paste0("OTU", rownames(ct), ":", data.obj$otu.name[, 'Phylum'], ";", data.obj$otu.name[, 'Genus'])
			data.obj$abund.list[['Species']] <- ct
		}
	} else {
		ct <- data.obj$abund.list[[taxa.level]]
	}

	prop <- t(t(ct) / colSums(ct))
	prop <- prop[rowMaxs(prop) > minp & rowSums(prop!=0) > prev*ncol(prop), , drop=FALSE]
	prop <- t(prop)
	
	if (binary == TRUE) {
		prop <- (prop != 0)
	}
	
    original.names <- colnames(prop)
	set.seed(seed)
	
	if (is.null(formula)) {
		performance <- matrix(0, nrow=B, ncol=2)
		colnames(performance) <- c("RF_M","Guess")
		roc.list <- list(RF_M=NULL)
		lab.list <- roc.list
	} else {
		performance <- matrix(0, nrow=B, ncol=4)
		colnames(performance) <- c("RF_M", "RF_CF", "RF_M+CF", "Guess")
		roc.list <- list("RF_M"=NULL, "RF_CF"=NULL, "RF_M+CF"=NULL)
		lab.list <- roc.list
	}

	
	colnames(prop) <- gsub(";", "_", colnames(prop))
	colnames(prop) <- gsub(":", "_", colnames(prop))
	colnames(prop) <- gsub("-", "_", colnames(prop))
	colnames(prop) <- gsub("\\.", "_", colnames(prop))
	names(original.names) <- colnames(prop)
	if (!is.null(formula)) {
		names(adj.var) <- adj.var
		original.names <- c(original.names, adj.var)
	}
	
	
	if (!is.null(formula)) {
		padj <- cbind(prop, adj)
	} else {
		padj <- prop
	}
	
	I <- nrow(prop)
	cat('Begin to bootstrap ...\n')
	for(b in 1:B){
		if (b %% 50 == 0) cat (".")
		err <- try({
			bsample <- sample(1:I, I, replace=T)
			if (is.factor(response)) {
				rf1 <- randomForest(x=prop[bsample, ], y=response[bsample], xtest=prop[-bsample, ], ytest=response[-bsample], sampsize=table(response[bsample]), ...)
				performance[b, "RF_M"] <- mean(response[-bsample]!= rf1$test$predicted)
				performance[b, "Guess"]<- mean(response[-bsample] != levels(response)[which.max(tabulate(response[bsample]))])
				roc.list[['RF_M']] <- c(roc.list[['RF_M']], rf1$test$vote[, 1])
				lab.list[['RF_M']] <- c(lab.list[['RF_M']], response[-bsample])
				if (!is.null(formula)) {
					rf2 <- randomForest(x=adj[bsample, ], y=response[bsample], xtest=adj[-bsample, ], ytest=response[-bsample], sampsize=table(response[bsample]), ...)
					rf3 <- randomForest(x=padj[bsample, ], y=response[bsample], xtest=padj[-bsample, ], ytest=response[-bsample], sampsize=table(response[bsample]), ...)
					performance[b, "RF_CF"] <- mean(response[-bsample]!= rf2$test$predicted)
					performance[b, "RF_M+CF"] <- mean(response[-bsample]!= rf3$test$predicted)
					roc.list[['RF_CF']] <- c(roc.list[['RF_CF']], rf2$test$vote[, 1])
					roc.list[['RF_M+CF']] <- c(roc.list[['RF_M+CF']], rf3$test$vote[, 1])
					lab.list[['RF_CF']] <- c(lab.list[['RF_CF']], response[-bsample])
					lab.list[['RF_M+CF']] <- c(lab.list[['RF_M+CF']], response[-bsample])
				}
				
			} else {
				rf1 <- randomForest(x=prop[bsample, ], y=response[bsample], xtest=prop[-bsample, ], ytest=response[-bsample], ...)
				performance[b, "RF_M"] <- mean((response[-bsample] - rf1$test$predicted)^2)
				performance[b, "Guess"]<- mean((response[-bsample] - mean(response[bsample]))^2)
				
				if (!is.null(formula)) {
					
					rf2 <- randomForest(x=adj[bsample, ], y=response[bsample], xtest=adj[-bsample, ], ytest=response[-bsample],  ...)
					rf3 <- randomForest(x=padj[bsample, ], y=response[bsample], xtest=padj[-bsample, ], ytest=response[-bsample],  ...)
					performance[b, "RF_CF"] <- mean((response[-bsample] - rf2$test$predicted)^2)
					performance[b, "RF_M+CF"] <- mean((response[-bsample]- rf3$test$predicted)^2)
				}
			}
		})
		if (inherits(err, "try-error")) {
			next
		}

	}
	cat("\n")
	
	sink(paste0("Taxa_Random_forest_FriedmanTest_", taxa.level, '_', ann, ".txt"))
	if (is.null(formula)) {
		cat("Fridman.test p value: ", friedman.test(performance)$p.value, "\n")
	} else {
		cat("Fridman.test p value (M+CF vs CF): ", friedman.test(performance[, c('RF_M+CF', 'RF_CF')])$p.value, "\n")
	}
	sink()
	
	pdf(paste0("Taxa_Random_forest_misclassification_barplot_", taxa.level, '_', ann, ".pdf"), height=5, width=4)
	if (!is.null(formula)) {
		performance2 <- performance[, c('Guess', 'RF_CF', 'RF_M', 'RF_M+CF')]
	} else {
		performance2 <- performance
	}
	if (is.factor(response)) {
		boxplot(performance2, col="#4DAF4A", ylab='Classification error', las=2)
	} else {
		boxplot(performance2, col="#4DAF4A", ylab='PMSE', las=2)
	}	
	dev.off()
	
	# ROC curve - only compare to the first level of the factor 
    if (is.factor(response)) {
		lab.list <- lapply(lab.list, function(x) {
					y <- factor(x)
					levels(y) <- levels(response)
					y
				}
		)
		createROC(roc.list, lab.list, pos.lab=levels(response)[1], 
				file.name=paste0("Taxa_Random_forest_ROC_", taxa.level, '_', ann, ".pdf"))
	}
	
	if (is.factor(response)) {
		rf <- randomForest(x=padj, y=response, sampsize=table(response), importance=T, ...)
	} else {
		rf <- randomForest(x=padj, y=response,  importance=T, ...)
	}
	
	importance <- as.data.frame(rf$importance)
	
	if (is.factor(response)) {
		write.csv(importance[rev(order(importance$MeanDecreaseAccuracy)), ],
				paste0("Taxa_RandomForest_Ranking_MeanDecreaseAccuracy_", taxa.level,'_', ann, ".csv"))
		write.csv(importance[rev(order(importance$MeanDecreaseGini)), ], 
				paste0("Taxa_RandomForest_Ranking_MeanDecreaseGini_", taxa.level, '_', ann, ".csv"))
	} else {
		write.csv(importance[rev(order(importance[, '%IncMSE'])), ],
				paste0("Taxa_RandomForest_Ranking_IncMSE_", taxa.level, '_', ann, ".csv"))
		write.csv(importance[rev(order(importance$IncNodePurity)), ], 
				paste0("Taxa_RandomForest_Ranking_IncNodePurity_", taxa.level, '_', ann, ".csv"))
	}

	
# Boruta Feature Selection - All subset selection (can't solve the confounding problem)
	obj.Boruta <- Boruta(padj, response, doTrace = 2)	
	write.csv(obj.Boruta$finalDecision, paste0("Taxa_Random_forest_Boruta_Feature_Selection_", taxa.level, '_', ann, ".csv"))
	
	pdf(paste0("Taxa_Random_forest_Boruta_Feature_Selection_", taxa.level, '_', ann,  ".pdf"), height=6, width=10)
	par(mar=par('mar') + c(3, 0, 0, 0))
	plot(obj.Boruta, main = "Feature selection by Boruta", ylab="Importance z-score", lwd = 0.5, las = 3, xlab = "",
			cex=1 / (ncol(prop)/50), cex.axis=0.25*200/ncol(prop), yaxt='n')
	axis(2, cex.axis=1)
	dev.off()
	#sink()
	
	pdf(paste0("Taxa_Random_forest_Boruta_Feature_Selection_Significant_Only_", taxa.level, '_', ann, ".pdf"), height=6, width=6)
	par(mar=par('mar') + c(3, 0, 0, 0))
	otu.ids <- plot.Boruta2(obj.Boruta, main = "Feature selection by Boruta", lwd = 0.5, las = 3, 
			ylab="Importance z-score", xlab = "", cex.axis=1, yaxt='n')
	axis(2, cex.axis=1)
	dev.off()
	
	if ('Confirmed' %in% boruta.level) {
		taxa.names <- original.names[names(obj.Boruta$finalDecision)[obj.Boruta$finalDecision %in% c('Confirmed')]] 
		if (!is.null(formula)) {
			taxa.names <- setdiff(taxa.names, adj.var)
			aug.var <- adj.var
		} else {
			aug.var <- NULL
		}

		if (length(taxa.names) > 0) {
			if (length(taxa.names) > 1) {

				generate_taxa_heatmap(data.obj, taxa.levels=taxa.level, taxa=taxa.names,   meta.info=resp.name, width=12,
						margins=c(5, 15), ann=paste0('BorutaFeatures_P_Confirmed_', ann))
				generate_taxa_heatmap(data.obj, taxa.levels=taxa.level, taxa=taxa.names,   meta.info=resp.name, width=12, data.type='R',
						margins=c(5, 15), ann=paste0('BorutaFeatures_R_Comfirmed_', ann))
				generate_taxa_heatmap(data.obj, taxa.levels=taxa.level, taxa=taxa.names,   meta.info=resp.name, width=12, data.type='B',
						margins=c(5, 15), ann=paste0('BorutaFeatures_B_Comfirmed_', ann))
				generate_taxa_heatmap(data.obj, taxa.levels=taxa.level, taxa=taxa.names,   meta.info=resp.name, width=12, Colv=F, dendrogram='row', sam.ord=order(response),
						margins=c(5, 15), ann=paste0('BorutaFeatures_P_Confirmed_Unclusterded_', ann))
				generate_taxa_heatmap(data.obj, taxa.levels=taxa.level, taxa=taxa.names,   meta.info=resp.name, width=12, data.type='R', Colv=F, dendrogram='row', sam.ord=order(response),
						margins=c(5, 15), ann=paste0('BorutaFeatures_R_Comfirmed_Unclusterded_', ann))
				generate_taxa_heatmap(data.obj, taxa.levels=taxa.level, taxa=taxa.names,   meta.info=resp.name, width=12, data.type='B', Colv=F, dendrogram='row', sam.ord=order(response),
						margins=c(5, 15), ann=paste0('BorutaFeatures_B_Comfirmed_Unclusterded_', ann))
			}

			if (is.factor(response)) {
				generate_taxa_boxplot(data.obj, grp.name=resp.name, taxa.levels=taxa.level, taxa.name=taxa.names, ann=paste0('BorutaFeatures_Confirmed_', ann))
				generate_taxa_boxplot(data.obj, grp.name=resp.name, taxa.levels=taxa.level, taxa.name=taxa.names, scale='binary', ann=paste0('BorutaFeatures_Confirmed_', ann))
				generate_taxa_barplot(data.obj, grp.name=resp.name, taxa.levels=taxa.level, taxa.name=taxa.names, ann=paste0('BorutaFeatures_Confirmed_', ann))
				if (length(taxa.names) > 1) {
					generate_taxa_barplot_aggregate(data.obj, grp.name=resp.name, taxa.levels=taxa.level, taxa.name=taxa.names, ann=paste0('BorutaFeatures_Confirmed_', ann))
					generate_taxa_boxplot_aggregate(data.obj, grp.name=resp.name, taxa.levels=taxa.level, taxa.name=taxa.names, ann=paste0('BorutaFeatures_Confirmed_', ann))
					build.decision.tree(data.obj,  resp.name=resp.name, aug.var=aug.var, taxa.level=taxa.level, binary=binary, taxa=taxa.names, ann=paste0('BorutaFeatures_Confirmed_', ann)) 
				}
				gen <- data.obj$abund.list[[taxa.level]]
				gen <- t(t(gen) / colSums(gen))
				dat <- t(gen[taxa.names, ,drop=FALSE])
				colnames(dat) <- paste0('V', 1:ncol(dat))
				response2 <- factor(-as.numeric(response)+2)
				
				mylr <- function(formula, train, test){
					model <- randomForest(formula, data=train)
					x <- predict(model, newdata=test, type='prob')[, 2]
				}
				
				ACC <- Daim(response2 ~., model=mylr, data=as.data.frame(dat), labpos="1",
						control=Daim.control(method="boot", number=100), cutoff="0.632+")
				pdf(paste0('BorutaFeatures_Confirmed_ROC_', taxa.level, '_0.632+', ann, '.pdf'), height=6, width=6)
				plot(ACC, main='Boruta taxa', method='0.632+', lwd=1.5)	
				abline(0, 1, col='black')
				x <- ACC
				legend("bottomright", legend = paste("AUC:", 
								formatC(Daim::auc(x$roc$sens632p, x$roc$spec632p), 
										digits = max(3, getOption("digits") - 3))),
						inset = 0.01)
				dev.off()	
			} else {
				data.obj$meta.dat[, paste0(resp.name, '_b')] <- factor(data.obj$meta.dat[, resp.name] < median(data.obj$meta.dat[, resp.name]))
				levels(data.obj$meta.dat[, paste0(resp.name, '_b')]) <- c('High', 'Low')
				generate_taxa_boxplot(data.obj, grp.name=paste0(resp.name, '_b'), taxa.levels=taxa.level, taxa.name=taxa.names, ann=paste0('BorutaFeatures_Confirmed_', ann))
				generate_taxa_boxplot(data.obj, grp.name=paste0(resp.name, '_b'), taxa.levels=taxa.level, taxa.name=taxa.names, scale='binary', ann=paste0('BorutaFeatures_Confirmed_', ann))
				generate_taxa_barplot(data.obj, grp.name=paste0(resp.name, '_b'), taxa.levels=taxa.level, taxa.name=taxa.names, ann=paste0('BorutaFeatures_Confirmed_', ann))
				if (length(taxa.names) > 1) {
					generate_taxa_barplot_aggregate(data.obj, grp.name=paste0(resp.name, '_b'), taxa.levels=taxa.level, taxa.name=taxa.names, ann=paste0('BorutaFeatures_Confirmed_', ann))
					generate_taxa_boxplot_aggregate(data.obj, grp.name=paste0(resp.name, '_b'), taxa.levels=taxa.level, taxa.name=taxa.names, ann=paste0('BorutaFeatures_Confirmed_', ann))
				}
			}
		}
	}

	if ('Tentative' %in% boruta.level) {
		taxa.names <- original.names[names(obj.Boruta$finalDecision)[obj.Boruta$finalDecision %in% c('Confirmed',  'Tentative')]] 
		if (!is.null(formula)) {
			taxa.names <- setdiff(taxa.names, adj.var)
			aug.var <- adj.var
		} else {
			aug.var <- NULL
		}
		
		if (length(taxa.names) > 0) {
			
			if (length(taxa.names) > 1)  {
				generate_taxa_heatmap(data.obj, taxa.levels=taxa.level, taxa=taxa.names,  meta.info=resp.name, width=12,
						margins=c(5, 15), ann=paste0('BorutaFeatures_P_Tentative_', ann))
				generate_taxa_heatmap(data.obj, taxa.levels=taxa.level, taxa=taxa.names,  meta.info=resp.name, width=12, data.type='R',
						margins=c(5, 15), ann=paste0('BorutaFeatures_R_Tentative_', ann))
				generate_taxa_heatmap(data.obj, taxa.levels=taxa.level, taxa=taxa.names,  meta.info=resp.name, width=12, data.type='B',
						margins=c(5, 15), ann=paste0('BorutaFeatures_B_Tentative_', ann))
				
				generate_taxa_heatmap(data.obj, taxa.levels=taxa.level, taxa=taxa.names,  meta.info=resp.name, width=12, Colv=F, dendrogram='row', sam.ord=order(response),
						margins=c(5, 15), ann=paste0('BorutaFeatures_P_Tentative_Unclustered_', ann))
				generate_taxa_heatmap(data.obj, taxa.levels=taxa.level, taxa=taxa.names,  meta.info=resp.name, width=12, data.type='R', Colv=F, dendrogram='row', sam.ord=order(response),
						margins=c(5, 15), ann=paste0('BorutaFeatures_R_Tentative_Unclustered_', ann))
				generate_taxa_heatmap(data.obj, taxa.levels=taxa.level, taxa=taxa.names,  meta.info=resp.name, width=12, data.type='B', Colv=F, dendrogram='row', sam.ord=order(response),
						margins=c(5, 15), ann=paste0('BorutaFeatures_B_Tentative_Unclustered_', ann))
			}

			if (is.factor(response)) {		
				generate_taxa_boxplot(data.obj, grp.name=resp.name, taxa.levels=taxa.level, taxa.name=taxa.names, ann=paste0('BorutaFeatures_Tentative_', ann))
				generate_taxa_boxplot(data.obj, grp.name=resp.name, taxa.levels=taxa.level, taxa.name=taxa.names, scale='binary', ann=paste0('BorutaFeatures_Tentative_', ann))
				generate_taxa_barplot(data.obj, grp.name=resp.name, taxa.levels=taxa.level, taxa.name=taxa.names, ann=paste0('BorutaFeatures_Tentative_', ann))
				if (length(taxa.names) > 1) {
					generate_taxa_barplot_aggregate(data.obj, grp.name=resp.name, taxa.levels=taxa.level, taxa.name=taxa.names, ann=paste0('BorutaFeatures_Tentative_', ann))
					generate_taxa_boxplot_aggregate(data.obj, grp.name=resp.name, taxa.levels=taxa.level, taxa.name=taxa.names, ann=paste0('BorutaFeatures_Tentative_', ann))
					build.decision.tree(data.obj,  resp.name=resp.name, aug.var=aug.var, taxa.level=taxa.level, binary=binary, taxa=taxa.names, ann=paste0('BorutaFeatures_Tentative_', ann)) 
				}
				
				gen <- data.obj$abund.list[[taxa.level]]
				gen <- t(t(gen) / colSums(gen))
				dat <- t(gen[taxa.names, ,drop=FALSE])
  			    colnames(dat) <- paste0('V', 1:ncol(dat))
				response2 <- factor(-as.numeric(response)+2)
				
				mylr <- function(formula, train, test){
					model <- randomForest(formula, data=train)
					x <- predict(model, newdata=test, type='prob')[, 2]
				}
				
				ACC <- Daim(response2 ~., model=mylr, data=as.data.frame(dat), labpos="1",
						control=Daim.control(method="boot", number=100), cutoff="0.632+")
				pdf(paste0('BorutaFeatures_Tentative_ROC_', taxa.level, '_0.632+', ann, '.pdf'), height=6, width=6)
				plot(ACC, main='Boruta taxa', method='0.632+', lwd=2)	
				abline(0, 1, col='black')
				x <- ACC
				legend("bottomright", legend = paste("AUC:", 
								formatC(Daim::auc(x$roc$sens632p, x$roc$spec632p), 
										digits = max(3, getOption("digits") - 3))),
						inset = 0.01)
				dev.off()	
				
			} else {
				data.obj$meta.dat[, paste0(resp.name, '_b')] <- factor(data.obj$meta.dat[, resp.name] < median(data.obj$meta.dat[, resp.name]))
				levels(data.obj$meta.dat[, paste0(resp.name, '_b')]) <- c('High', 'Low')
				generate_taxa_boxplot(data.obj, grp.name=paste0(resp.name, '_b'), taxa.levels=taxa.level, taxa.name=taxa.names, ann=paste0('BorutaFeatures_Tentative_', ann))
				generate_taxa_boxplot(data.obj, grp.name=paste0(resp.name, '_b'), taxa.levels=taxa.level, taxa.name=taxa.names, scale='binary', ann=paste0('BorutaFeatures_Tentative_', ann))
				generate_taxa_barplot(data.obj, grp.name=paste0(resp.name, '_b'), taxa.levels=taxa.level, taxa.name=taxa.names, ann=paste0('BorutaFeatures_Tentative_', ann))
				if (length(taxa.names) > 1) {
					generate_taxa_barplot_aggregate(data.obj, grp.name=paste0(resp.name, '_b'), taxa.levels=taxa.level, taxa.name=taxa.names, ann=paste0('BorutaFeatures_Tentative_', ann))
					generate_taxa_boxplot_aggregate(data.obj, grp.name=paste0(resp.name, '_b'), taxa.levels=taxa.level, taxa.name=taxa.names, ann=paste0('BorutaFeatures_Tentative_', ann))
				}
			}
		}
	}	
}

col.func <- colorRampPalette(c("blue", "cyan", "red", "yellow"))
#col.fun2 <- colorpanel(9, 'yellow', 'red')

# Rev: 2017_02_19 key alignment modified, rowsep, colsep bug
# Rev: 2017_12_19 row colors fixed
generate_taxa_heatmap <- function (data.obj, taxa.levels='Genus', taxa='All', meta.info, sam.ord=NULL, data.type='P',  prev=0.1, minp=0.002, 
		row.col.dat='Phyla', phy.no=4, sepwidth=0.01, colsep=NULL, rowsep=NULL, sepcolor='black',
		white='white', colFnsC=NULL, colFnsF=NULL, Rowv=T, Colv=T, dendrogram='both', margins=c(5, 15), in.grid=F,  is.labCol=T, cexCol=1, cexRow=NULL,
		omas=c(1, 1, 1, 8), width=12, height=6, ann='All', return.obj=FALSE, ...) {
	
	colsep0 <- colsep
	rowsep0 <- rowsep
	df <- data.obj$meta.dat

	# Determine the col/rowside color
	if (is.null(colFnsC)) {
		# colFnsC <- c(colorRampPalette(c('black', 'yellow', 'red'), colorRampPalette(c('black', 'green')), colorRampPalette(c('black', 'blue'))))
		# https://moderndata.plot.ly/create-colorful-graphs-in-r-with-rcolorbrewer-and-plotly/
		colFnsC <- c(colorRampPalette(colors = brewer.pal(9,"RdBu")), 
				colorRampPalette(colors = brewer.pal(9,"PRGn")), colorRampPalette(colors = brewer.pal(9,"RdYlBu")),  
		        colorRampPalette(colors = brewer.pal(9,"RdGy")), colorRampPalette(colors = brewer.pal(9,"PuOr")))
	} 
	if (is.null(colFnsF)) {
#		rainbow3 <- function(x) {
#			rainbow(x + 2)[1:x]
#		}
		jet3 <- function(x) {
			jet(x + 2)[1:x]
		}
#		colFnsF <- c(rainbow3, jet3)
#		colFnsF <- c(colorRampPalette(colors = brewer.pal(8, "Set1")), colorRampPalette(colors = brewer.pal(7, "Set2")), 
#				colorRampPalette(colors = brewer.pal(7,"Dark2")), colorRampPalette(colors = jet(8)))
		colFnsF <- function (x) {
			if (x <= 6) {
				return(brewer.pal(7, "Set2")[1:x])
			} else {
				return(colorRampPalette(colors = jet(8))(x))
			}
		}
		colFnsF <- c(colFnsF)
	}
	
	
	if ('Species' %in% taxa.levels & !('Species' %in% names(data.obj$abund.list))) {
		data.obj$abund.list[['Species']] <- data.obj$otu.tab
		rownames(data.obj$abund.list[['Species']]) <- paste0("A", substr(rownames(data.obj$otu.tab), 1, 6), ":", 
				data.obj$otu.name[, 'Phylum'], ";", data.obj$otu.name[, 'Genus'])
	}
	for (LOI in taxa.levels) {
		cat(LOI, "\n")
		
		if (LOI == 'All') {
			if (taxa[1] == 'All') {
				stop("Please specify the taxa names that will be included in the heatmap!\n")
			} 
			prop <- NULL
			for (LOI2 in names(data.obj$abund.list)) {
				ct <- data.obj$abund.list[[LOI2]]
				prop0 <- t(t(ct) / colSums(ct))
				prop <- rbind(prop, prop0[intersect(rownames(prop0), taxa), , drop=FALSE])	
	
			}
			colnames(prop) <- colnames(prop0)
			if (nrow(prop) != length(taxa)) {
				warnings('Some taxa not found in abundance lists! Please check the names!\n')
			}
			
  		} else {
			ct <- data.obj$abund.list[[LOI]]
			prop <- t(t(ct) / colSums(ct))
			
			if (taxa[1] != 'All') {
				prop <- prop[taxa, , drop=FALSE]
			} else {
				prop <- prop[rowMaxs(prop) > minp & rowSums(prop!=0) > prev*ncol(prop), , drop=FALSE]	
			}			
		}

		# Sort row and column
		if (is.null(sam.ord)) {
			prop <- prop[order(rownames(prop)), , drop=FALSE]
		} else {
			prop <- prop[order(rownames(prop)), sam.ord, drop=FALSE]
		}
		
		if (is.labCol) {
			labCol <- colnames(prop)
		}  else {
			labCol <- ''
		}
		# Deal with zeros
		if (data.type == 'B') {
			col.scheme <- c("lightyellow", "red")
			prop[, ] <- as.numeric(prop != 0)
			breaks <- c(-0.01, 0.01, 1.1)
		} 
		if (data.type == 'P' | data.type == 'logP'){
			#col.scheme <- c(white, colFunc(50))		
			col.scheme = c(white, brewer.pal(11, "Spectral"))
	        # col.scheme = c(white, colorRampPalette(c("blue", "yellow", "red"))(11))
			ind.temp <- prop != 0
			minp <- min(prop[prop!=0])/1.1
			prop[prop==0] <- minp
			prop <- log10(prop)
		#	breaks <- c(log10(minp)-0.01, seq(log10(minp)+0.01, 0, len=51))	
	        breaks <- c(log10(minp)-0.01, seq(log10(minp)+0.01, 0, len=12))
		}
		
		if (data.type == 'sqrtP'){
			#col.scheme <- c(white, colFunc(50))		
			col.scheme <-  c("#FFFFCC", "#FFEDA0", "#FED976", "#FEB24C", "#FD8D3C", "#FC4E2A", "#E31A1C", "#BD0026", "#800026")
			# col.scheme = c(white, colorRampPalette(c("blue", "yellow", "red"))(11))
			prop <- sqrt(prop)
			breaks <- c(-0.01, seq(min(prop[prop != 0]) * 0.99, max(prop), len=9))
		}
		if (data.type == 'R'){
			col.scheme <- c(white, colorRampPalette(rev(brewer.pal(9, "RdYlBu")))(ncol(prop)-1))
			#col.scheme <- c('white', colorRampPalette(c("green", "black", "red"))(ncol(prop)-1))
	
			prop <- t(apply(prop, 1, function(x) {
								temp <- rank(x[x!=0])
								s <- (ncol(prop) - 1) / (max(temp) - min(temp))
								temp <- 1 + (temp - min(temp)) * s
								x[x!=0] <- temp
								x
								}))
			breaks <- seq(0, ncol(prop), len=ncol(prop)+1)
		}
		
		if (nrow(prop) > 150) {
			labRow <- ''
			cexRow <- 1
		} else {
			labRow <- rownames(prop)
			if (is.null(cexRow)) {
				cexRow <- ifelse(0.5 * 60 / nrow(prop) > 1, 1, 0.5 * 60 / nrow(prop))
			}

		}
		
		if (is.null(colsep0)) {
			if (in.grid == T) {
				colsep <- c(0:ncol(prop))  
			} else {
				colsep <- c(0, ncol(prop))  
			}
		} else {
			colsep <- colsep0
		}
		
		if (is.null(rowsep0)) {
			if (in.grid == T) {
				rowsep <- c(0:nrow(prop))
			} else {
				rowsep <- c(0, nrow(prop))
			}
		} else {
			rowsep <- rowsep0
		}
		
		key.list <- list()
		colsidecol <- NULL
		i <- 0
		j <- 0
		for (keyID in meta.info) {
			if (is.null(sam.ord)) {
				x <- df[, keyID]
			} else {
				x <- df[sam.ord, keyID]
			}		

			if (is.factor(x) | is.character(x)) {
				x <- factor(x)
				key.list[[keyID]] <- list(breaks=levels(x), colors=(colFnsF[i+1][[1]])(nlevels(x)), base=NA, col.na=NA, right=F, include.lowest=F)	
				i <- (i + 1) %% length(colFnsF)
				colsidecol <- cbind(colsidecol, key.list[[keyID]]$colors[x])
			} else {
				key.list[[keyID]] <- makecmap(x, n=5, colFn=colFnsC[j+1][[1]])
				j <- (j + 1) %% length(colFnsC)
				colsidecol <- cbind(colsidecol, cmap(x, key.list[[keyID]]))
			}
		}
		colnames(colsidecol) <- meta.info
		
		# Rev: 2016_09_13
		colsidecol[is.na(colsidecol)] <- 'white'
		
		# add aunbdance key 
		if (data.type == 'B') {
			prop.cmap <- list(breaks=c("Absence", "Presence"), colors=c("lightyellow", "red"), base=NA, col.na=NA, right=F, include.lowest=F) 
			KeyName <- 'Abundance'
		} 
#		if (data.type == 'P'){
#			prop.cmap <- makecmap(prop[ind.temp], n = 5, colFn = colFunc)
#		}
#		if (data.type == 'R'){
#			prop.cmap <- makecmap(as.vector(prop), n = 5, colFn = colFunc)
#		}
		
		if (data.type %in% c('P', 'logP')){
			KeyName <- 'log(Proportion)'	
		}
		if (data.type %in% c('sqrtP')){
			KeyName <- 'sqrt(Proportion)'	
		}
		if (data.type == 'R'){
			KeyName <- 'Rank'
		}
			
		# add row col key
        # Strong assumption of the structure of 'row' names
        if (row.col.dat == 'Phyla') {
			if (LOI %in% c('Class', 'Order', 'Family', 'Genus', 'Species')) {
				if (LOI == 'Species') {
					phy <- sapply(strsplit(rownames(prop), ":"), function(x) x[2])
					phy <- sapply(strsplit(phy, ";"), function(x) x[1])
				} else {
					phy <- sapply(strsplit(rownames(prop), ";"), function(x) x[1])
				}
				
				if (sum(is.na(phy)) == 0) {
					temp <- sort(table(phy), decr=T)
					if (length(temp) > phy.no) {
						rare.phy <- names(temp)[-(1:phy.no)]
						phy[phy %in% rare.phy] <- 'Other'
						phy <- factor(phy, levels=c(names(temp)[(1:phy.no)], 'Other'))
					} else {
						phy <- factor(phy)
					}
					rowsidecol<- rainbow(nlevels(phy))[phy]
					rowsidecol <- rbind(rowsidecol, rowsidecol)
					rownames(rowsidecol) <- c('', '')
					phy.cmap <- list(breaks=levels(phy), colors=rainbow(nlevels(phy)), base=NA, col.na=NA, right=F, include.lowest=F) 
				} else {
					rowsidecol <- NULL
				}

			} else {
				rowsidecol <- NULL
			}
		} else {
			rowsidecol <- NULL
		}
		
		pdf(paste0('Taxa_Heatmap_', LOI, '_', ann, '.pdf'), width=width, height=height)
		par(oma = omas)

#		if (data.type == 'R' | data.type == 'B') {
#			dist2 <- dist
#		}
#		if (data.type == 'P') {
#			# Better clustering of taxa
##			dist2 <- function(x) {    
##				as.dist((1-cor(t(x)))/2)
##			}
#	       dist2 <- dist
#		}
#
#		# Rev: 2016_09_13 handle zero sd cases
#        if (sum(rowSds(prop) == 0) != 0 | sum(colSds(prop) == 0) != 0)  {
#			dist2 <- dist
#			warning('Zero sd produced! Euclidean distance is used instead!\n')
#		}
        hclust2 <- function (d) {
			return(hclust(d, method = 'ward.D'))
		}
		# Pearson correlation distance
		obj <- heatmap.3(prop, 
				Rowv=Rowv, 
				Colv=Colv, 
#				distfun = dist2,
		        hclustfun = hclust2,
				dendrogram=dendrogram,
				scale='none',
				col=col.scheme, 
				breaks=breaks, 
				symbreaks=F,
				trace='none',
				margins= margins, 
				colsep = colsep,  
				rowsep = rowsep,  
				sepcolor= sepcolor, 
				sepwidth=c(sepwidth, sepwidth),
				ColSideColors=colsidecol,
				RowSideColors=rowsidecol,
				cexRow=cexRow,
				labRow=labRow,
				labCol=labCol,
				cexCol=cexCol,
				key=(data.type != 'B'), density.info='none', symkey=F, KeyValueName=KeyName,	
				NumColSideColors= 0.5 *length(meta.info),
				NumRowSideColors= 0.5,
				...
		)

		par(cex=0.75)
		par(oma=c(0, 0, 1, 0)) 
		
		if (!is.null(rowsidecol) & row.col.dat == 'Phyla') {
			y.cord <- (1/(length(meta.info)+2)) * (0:((length(meta.info)+2) - 1))
			vkey2(phy.cmap, 'Phylum', x=0, y=-0.2, stretch=1.2)

		}

		y.cord <- (1/(length(meta.info))) * (0:(length(meta.info) - 1))
		k <- 1
		xs <- c(0.95, 1)
		for (keyID in meta.info) {
			x <- df[, keyID]
			if (is.factor(x) | is.character(x)) {
				x <- factor(x)
				vkey2(key.list[[keyID]], keyID, x=xs[(k-1) %% 2 + 1], y=y.cord[k], stretch=1.2)
			} else {
				vkey(key.list[[keyID]], keyID, x=xs[(k-1) %% 2 + 1], y=y.cord[k], stretch=1.2)
			}
			k <- k + 1
		}	
		
		if (data.type == 'B') {
			vkey2(prop.cmap, KeyName,  x=xs[(k-1) %% 2 + 1], y=1, stretch=1.2)		
		} 
#		if (data.type == 'P'){
#			vkey(prop.cmap, 'log10(Proportion)', y=1, stretch=1.2)
#		}	
#		if (data.type == 'R'){
#			vkey(prop.cmap, 'Rank', y=1, stretch=1.2)
#		}	
		dev.off()	
	}
	if (return.obj == TRUE) {
		return(obj)
	}
	
}

# New: 2017_03_02  General heatmap without taxa
# data.obj$data, data.obj$meta.dat
# Rev: 2017_11_20, Add 'LogC', taxa.as.row
generate_heatmap <- function (data.obj,  meta.info, sam.ord=NULL, data.type='P',
		row.col.dat=NULL,  sepwidth=0.01, colsep=NULL, rowsep=NULL, taxa.as.row = TRUE,
		colFnsC=NULL, colFnsF=NULL, Rowv=T, Colv=T, dendrogram='both', margins=c(5, 15),
		in.grid=F, sepcolor='black', is.labCol=T, cexCol=1, cexRow=NULL,
		omas=c(1, 1, 1, 8), width=12, height=6, ann='All', return.obj=FALSE, pdf=TRUE, ...) {
	
	colsep0 <- colsep
	rowsep0 <- rowsep
	df <- data.obj$meta.dat
	
	# Determine the col/rowside color
	# Determine the col/rowside color
	if (is.null(colFnsC)) {
		# colFnsC <- c(colorRampPalette(c('black', 'yellow', 'red'), colorRampPalette(c('black', 'green')), colorRampPalette(c('black', 'blue'))))
		# https://moderndata.plot.ly/create-colorful-graphs-in-r-with-rcolorbrewer-and-plotly/
		colFunsC <- c(colorRampPalette(colors = brewer.pal(9,"RdBu")), 
				colorRampPalette(colors = brewer.pal(9,"PRGn")), colorRampPalette(colors = brewer.pal(9,"RdYlBu")),  
				colorRampPalette(colors = brewer.pal(9,"RdGy")), colorRampPalette(colors = brewer.pal(9,"PuOr")))
	} 
	if (is.null(colFnsF)) {

		colFnsF <- function (x) {
			if (x <= 6) {
				return(brewer.pal(7, "Set2")[1:x])
			} else {
				return(colorRampPalette(colors = jet(8))(x))
			}
		}
		colFnsF <- c(colFnsF)
	}
	prop <- data.obj$data
	
	# Sort row and column
	if (!is.null(sam.ord)) {
		prop <- prop[, sam.ord, drop=FALSE]
	}
	
	if (is.labCol) {
		labCol <- colnames(prop)
	}  else {
		labCol <- ''
	}
	if (data.type == 'LogC') {
		col.scheme <- c('white', colorpanel(9, 'aliceblue', 'lightblue', 'blue'))
		breaks <- c(-0.1, 0.1, 2, 4, 6, 8, 10, 12, 14, 16, 18)
	}
	# Deal with zeros
	if (data.type == 'B') {
		col.scheme <- c("lightyellow", "red")
		breaks <- c(-0.01, 0.01, 1.1)
	} 
	if (data.type == 'P'){
		#
		#col.scheme = brewer.pal(11, "Spectral")
	     col.scheme <- bluered(11)
		breaks <- c(seq(min(prop), max(prop), len=12))
	}
	if (data.type == 'R'){
		col.scheme <- c(white, colorRampPalette(rev(brewer.pal(9, "RdYlBu")))(ncol(prop)-1))
		breaks <- seq(0, ncol(prop), len=ncol(prop)+1)
	}
	
	if (nrow(prop) > 1500) {
		labRow <- ''
		cexRow <- 1
	} else {
		labRow <- rownames(prop)
		if (is.null(cexRow)) {
			cexRow <- ifelse(0.5 * 60 / nrow(prop) > 1, 1, 0.5 * 60 / nrow(prop))
		}
		
	}
	
	if (is.null(colsep0)) {
		if (in.grid == T) {
			colsep <- c(0:ncol(prop))  
		} else {
			colsep <- c(0, ncol(prop))  
		}
	} else {
		colsep <- colsep0
	}
	
	if (is.null(rowsep0)) {
		if (in.grid == T) {
			rowsep <- c(0:nrow(prop))
		} else {
			rowsep <- c(0, nrow(prop))
		}
	} else {
		rowsep <- rowsep0
	}
	
	key.list <- list()
	colsidecol <- NULL

	i <- 0
	j <- 0
	
	for (keyID in meta.info) {
		if (is.null(sam.ord)) {
			x <- df[, keyID]
		} else {
			x <- df[sam.ord, keyID]
		}		
		if (is.factor(x)) {
			key.list[[keyID]] <- list(breaks=levels(x), colors=(colFnsF[i+1][[1]])(nlevels(x)), base=NA, col.na=NA, right=F, include.lowest=F)	
			i <- (i + 1) %% length(colFnsF)
			colsidecol <- cbind(colsidecol, key.list[[keyID]]$colors[x])
		} else {
			key.list[[keyID]] <- makecmap(x, n=5, colFn=colFnsC[j+1][[1]])
			j <- (j + 1) %% length(colFnsC)
			colsidecol <- cbind(colsidecol, cmap(x, key.list[[keyID]]))
		}
	}
	colnames(colsidecol) <- meta.info
	
	# Rev: 2016_09_13
	colsidecol[is.na(colsidecol)] <- 'white'
	
	# add aunbdance key 
	if (data.type == 'B') {
		prop.cmap <- list(breaks=c("0", "1"), colors=c("lightyellow", "red"), base=NA, col.na=NA, right=F, include.lowest=F) 
		KeyName <- 'Value'
	} 
	
	if (data.type == 'P'){
		KeyName <- 'Value'	
	}
	if (data.type == 'R'){
		KeyName <- 'Rank'
	}
	
	if (data.type == 'LogC'){
		KeyName <- 'Log2(count+1)'
	}
	
	# add row col key
	if (!is.null(row.col.dat)) {
		
		phy <- df[, row.col.dat]
		phy <- factor(phy)
		
		rowsidecol<- rainbow(nlevels(phy))[phy]
		rowsidecol <- rbind(rowsidecol, rowsidecol)
		rownames(rowsidecol) <- c('', '')
		phy.cmap <- list(breaks=levels(phy), colors=rainbow(nlevels(phy)), base=NA, col.na=NA, right=F, include.lowest=F) 
	} else {
		rowsidecol <- NULL
	}
	if(pdf == TRUE) {
		pdf(paste0('Heatmap_', ann, '.pdf'), width=width, height=height)
	}
	
	par(oma = omas)
	
	
	# Pearson correlation distance
    if (taxa.as.row) {
		prop <- prop
	} else {
		prop <- t(prop)
	}
	obj <- heatmap.3(prop, 
			Rowv=Rowv, 
			Colv=Colv, 
#				distfun = dist2,
			dendrogram=dendrogram,
			scale='none',
			col=col.scheme, 
			breaks=breaks, 
			symbreaks=F,
			trace='none',
			margins= margins, 
			colsep = colsep,  
			rowsep = rowsep,  
			sepcolor= sepcolor, 
			sepwidth=c(sepwidth, sepwidth),
			ColSideColors=colsidecol,
			RowSideColors=rowsidecol,
			cexRow=cexRow,
			labRow=labRow,
			labCol=labCol,
			cexCol=cexCol,
			key=(data.type != 'B'), density.info='none', symkey=F, KeyValueName=KeyName,	
			NumColSideColors= 0.5 *length(meta.info),
			NumRowSideColors= 0.5,
			...
	)
	
	par(cex=0.75)
	par(oma=c(0, 0, 1, 0)) 
	
	if (!is.null(rowsidecol)) {
		y.cord <- (1/(length(meta.info)+2)) * (0:((length(meta.info)+2) - 1))
		vkey2(phy.cmap, rowsidecol, x=0, y=-0.2, stretch=1.2)
		
	}
	
	y.cord <- (1/(length(meta.info))) * (0:(length(meta.info) - 1))
	k <- 1
	xs <- c(0.95, 1)
	for (keyID in meta.info) {
		x <- df[, keyID]
		if (is.factor(x)) {
			vkey2(key.list[[keyID]], keyID, x=xs[(k-1) %% 2 + 1], y=y.cord[k], stretch=1.2)
		} else {
			vkey(key.list[[keyID]], keyID, x=xs[(k-1) %% 2 + 1], y=y.cord[k], stretch=1.2)
		}
		k <- k + 1
	}	
	
	if (data.type == 'B') {
		vkey2(prop.cmap, KeyName, x=xs[(k-1) %% 2 + 1], y=1, stretch=1.2)		
	} 
	
	if (pdf == TRUE) {
		dev.off()	
	}
	
	
	if (return.obj == TRUE) {
		return(obj)
	}
}

lighter <- function(color, factor = 0.2) {
	## converts color to hsv, multiplies v by factor, returns colors as hexcode
	x = rgb2hsv(col2rgb(color))
	v = pmax(pmin(x[3, ] + factor, 1), 0)
	hsv(h = x[1, ], s = x[2, ], v = v)
}

# Rev: 2016_06_13
# Still need to be revised: Multiple groups, the auto order should look similar for differnt groups;
# The legends do not work
# Rev: 2017_04_28 add col.map so the color scheme can be the same for different data sets
# Rev: 2017_11_09 add label for individual bar plot and change ordering 
# Rev: 2018_03_15 add par(lwd..)
# Rev: 2018_05_31 add return col.map and aggregate the taxa not in col.map into 'Other' Class
# Rev: 2018_06_07 many colors
generate_stacked_barplot <- function(data.obj, grp.name=NULL, taxa.levels=c('Phylum', 'Family', 'Genus'), agg.cutoff=0.005, 
		border=TRUE, order.auto=FALSE, order.method='abund', order.taxa=FALSE, cex.names=0.5, cex.top.lab = 0.75, separate=FALSE, cex.names2=1, indiv=TRUE, aggre=TRUE,
		hei1=6, wid1=9, hei2=6, wid2=9, margin=10, ann='', pdf=TRUE, col.map = NULL, many.colors=FALSE, ...) {
	if (is.null(grp.name)) {
		grp <- rep(1, nrow(data.obj$meta.dat))
	} else {
		grp <- factor(data.obj$meta.dat[, grp.name])
	}
	
	name.list <- list()
	col.list <- list()
	

	lwd.o <- par('lwd')
	# rearrange the order of taxa
	if (order.taxa) {
		for (taxa.level in taxa.levels) {
			abund0 <- data.obj$abund.list[[taxa.level]]
			abund0 <- t(t(abund0) / colSums(abund0))
			data.obj$abund.list[[taxa.level]] <- data.obj$abund.list[[taxa.level]][rev(order(rowMeans(abund0))), ]
		}
	}
	
	# create color mapping
	prop.list <- list()
	for (taxa.level in taxa.levels) {
		abund0 <- data.obj$abund.list[[taxa.level]]
		abund0 <- t(t(abund0) / colSums(abund0))
		
		abund1 <- abund0[rowMeans(abund0) >= agg.cutoff, , drop=F]
		abund2 <- abund0[rowMeans(abund0) < agg.cutoff, , drop=F]
		
		prop <- rbind(abund1, Other=colSums(abund2))
		colnames(prop) <- colnames(abund0)
#		name.list[[taxa.level]] <- rownames(abund1)
		prop.list[[taxa.level]] <- prop
		
		#rand.col <- c(sample(rainbow(nrow(prop)*2), nrow(prop)-1), 'gray')
		# Rev: 2017_04_28
		if (is.null(col.map[[taxa.level]])) {
			if (many.colors) {
				basic <- brewer.pal(12, "Paired")
				rand.col <- c(rep_len(c(lighter(basic, -0.2), lighter(basic, -0.1), basic, lighter(basic, 0.1),  lighter(basic, 0.2)), nrow(prop) - 1), 'gray')
			} else {
				rand.col <- c(rep_len(brewer.pal(12, "Paired"), nrow(prop) - 1), 'gray')
			}
			
			# rand.col <- c(brewer.pal(nrow(prop) - 1, "Paired"), 'gray')
			names(rand.col) <- rownames(prop)
			col.list[[taxa.level]] <- rand.col
		} else {
			# Rev: 2018_05_30
			if (sum(!(rownames(prop) %in% names(col.map[[taxa.level]]) ))) {
				warning('Color mapping does not contain all the taxa! Unmapped taxa will be aggreated into "Other" category!\n')
				umapped.taxa <- setdiff(rownames(prop), names(col.map[[taxa.level]]))
				Other2 <- colSums(prop[umapped.taxa, , drop=FALSE])
				prop <- prop[setdiff(rownames(prop), umapped.taxa), , drop=FALSE]
				if ('Other' %in% rownames(prop)) {
					prop['Other', ] <- prop['Other', ] + Other2
				} else {
					prop <- rbind(prop, Other = Other2)
					colnames(prop) <- colnames(data.obj$abund.list[[taxa.level]])
				}
				#		name.list[[taxa.level]] <- rownames(prop)
				prop.list[[taxa.level]] <- prop
			} 
			col.list[[taxa.level]] <- col.map[[taxa.level]]
		}
		
	}	
	
	
	if (indiv == TRUE) {
		if (pdf == TRUE)
			pdf(paste0("Taxa_Stacked_Barplot_Overall_Compo_", ann, ".pdf"), height=hei1, width=wid1)
		
		if (border == FALSE) {
			lty.o <- par("lty")
			par(lty = 0)
		}
		
		mar.o <- par(mar=par('mar') + c(0, margin, 0, 0))
		
		for (taxa.level in taxa.levels) {
#			abund0 <- data.obj$abund.list[[taxa.level]]
#			abund0 <- t(t(abund0) / colSums(abund0))
#			
			##			abund1 <- abund0[rowMeans(abund0) >= agg.cutoff, , drop=F]
			##			abund2 <- abund0[rowMeans(abund0) < agg.cutoff, , drop=F]
#			
#			abund1 <- abund0[name.list[[taxa.level]], , drop=FALSE]
#			abund2 <- 1 - colSums(abund1)
#			
#			prop <- rbind(abund1, Other=abund2)
#			colnames(prop) <- colnames(abund0)
			
			prop <- prop.list[[taxa.level]]
			
			#rand.col <- c(sample(rainbow(nrow(prop)*2), nrow(prop)-1), 'gray')
			#col.list[[taxa.level]] <- rand.col
			
			cex.legend = ifelse (nrow(prop) > 35, 35/nrow(prop)*0.75, 0.75)
			
			# Rev: 2016_09_13, better ordering within group based on single linkage
			# Rev: 2017_11_10, ordering rule the same across group
			if (order.auto) {
				
				temp <- rev(order(rowMeans(prop)))
				
				prop <- do.call(cbind, tapply(1:length(grp), factor(grp), function(i){
									if (length(i) >= 2) {
										prop.sub <- prop[, i, drop=FALSE]
										if (order.method == 'single') {
											ord <- hclust(vegdist(t(prop.sub)), method='single')$order
										} else {
											prop.dummy <- prop.sub
											prop.dummy[prop.dummy < 0.05] <- 0
											if (length(temp) >=3) {
												ord <- (order(-prop.dummy[temp[1], ], -prop.dummy[temp[2], ], -prop.dummy[temp[3], ]))
											} else {
												ord <- (order(-prop.dummy[temp[1], ]))
											}
										}
										# temp <- rev(order(rowMeans(prop.sub)))
										prop.sub <- prop.sub[, ord, drop=FALSE]
										return(prop.sub)
									} else {
										return(prop[, i, drop=FALSE])
									}
								}))
			} else {
				prop <- prop[, order(grp), drop=FALSE]
			}
			
			grp2 <- sort(grp)
			if (border == FALSE) {
				if (is.null(grp.name)) {
					par(lwd = 0.25)
					barplot(prop, col=col.list[[taxa.level]][rownames(prop)], ylab='Proportion', las=2, legend.text=rownames(prop), cex.names=cex.names, space=0,
							args.legend=list(x='left', bty='n',  cex=cex.legend, inset=c(-0.5, 0)), main=taxa.level, ...)
				}  else {
					
					par(lwd = 0.25)
					coord <- barplot(prop, ylim = c(0, 1.05), col=col.list[[taxa.level]][rownames(prop)], ylab='Proportion', las=2, legend.text=rownames(prop), cex.names=cex.names, space=0,
							args.legend=list(x='left', bty='n',  cex=cex.legend, inset=c(-0.5, 0)), main=taxa.level, ...)
					
					coord.text <- tapply(coord, grp2, mean)
					coord.st <- tapply(coord, grp2, max)[-(length(unique(grp2)))]
					coord.end <- tapply(coord, grp2, min)[-1]
					coord.line <- (coord.st +  coord.end) / 2
					
					text.names <- names(coord.text)
					
					
					for (i in 1 : length(coord.line)) {
						abline(v = coord.line[i], lty = 1, lwd = 0.5)	
					}
					for (i in 1 : length(coord.text)) {
						if (i %% 2 == 0) {
							pos <- 3
						} else {
							pos <- 3
						}
						text(coord.text[i], 1, text.names[i], pos = pos, cex = cex.top.lab)
					}
					
				}
			} else {
				if (is.null(grp.name)) {
					par(lwd = 0.25)
					barplot(prop, col=col.list[[taxa.level]][rownames(prop)], ylab='Proportion', las=2, legend.text=rownames(prop), cex.names=cex.names,
							args.legend=list(x='left', bty='n',  cex=cex.legend, inset=c(-0.5, 0)), main=taxa.level, ...)
				} else {
					par(lwd = 0.25)
					coord <- barplot(prop, ylim = c(0, 1.05), col=col.list[[taxa.level]][rownames(prop)], ylab='Proportion', las=2, legend.text=rownames(prop), cex.names=cex.names,
							args.legend=list(x='left', bty='n',  cex=cex.legend, inset=c(-0.5, 0)), main=taxa.level, ...)
					
					coord.text <- tapply(coord, grp2, mean)
					coord.st <- tapply(coord, grp2, max)[-(length(unique(grp2)))]
					coord.end <- tapply(coord, grp2, min)[-1]
					coord.line <- (coord.st +  coord.end) / 2
					
					text.names <- names(coord.text)
					for (i in 1 : length(coord.line)) {
						abline(v = coord.line[i], lty = 1, lwd = 0.5)	
					}
					for (i in 1 : length(coord.text)) {
						if (i %% 2 == 0) {
							pos <- 3
						} else {
							pos <- 3
						}
						text(coord.text[i], 1, text.names[i], pos = pos, cex = cex.top.lab)
					}
				}
				
				
			}
			
		}
		if (border == FALSE) {
			par(lty = lty.o)
		}
		
		par(mar = mar.o)
		if (pdf == TRUE)
			dev.off()
		
	}
	
	# Generate averaged over stack barplot
	
	if (!is.null(grp.name) & aggre == TRUE) {
		if (separate != TRUE) {
			if (pdf == TRUE)
				pdf(paste0("Taxa_Stacked_Barplot_Grouped_Compo_", ann, "_combine.pdf"), height=hei2, width=wid2)
			mar.o <- par(mar=par('mar') + c(0, margin/length(taxa.levels), 0, 0))
			mfrow.o <- par(mfrow=c(1, length(taxa.levels)))
			cex.legend <- 10
			for (taxa.level in taxa.levels) {
#				abund0 <- data.obj$abund.list[[taxa.level]]
#				abund0 <- t(t(abund0) / colSums(abund0))
#			
#				
#			    temp <- aggregate(t(abund0), by=list(grp), mean)
#				abund0 <- as.matrix(temp[, -1])
#				rownames(abund0) <- temp[, 1]
#				abund0 <- t(abund0)
#				
#				abund1 <- abund0[name.list[[taxa.level]], , drop=FALSE]
#				abund2 <- 1 - colSums(abund1)
#				
#				prop <- rbind(abund1, Other=abund2)
#				colnames(prop) <- colnames(abund0)
				
				temp <- aggregate(t(prop.list[[taxa.level]]), by=list(grp), mean)
				prop <- as.matrix(temp[, -1])
				rownames(prop) <- temp[, 1]
				prop <- t(prop)
				
				newsize <- ifelse (nrow(prop) > 35, 35/nrow(prop)*0.75, 0.75)
				cex.legend <- ifelse(cex.legend < newsize, cex.legend, newsize) 
				#prop <- prop[, order(grp)]
				par(lwd = 0.25)
				barplot(prop,  col=col.list[[taxa.level]][rownames(prop)], ylab='Proportion', las=2, cex.names=cex.names2, main=taxa.level, ...)
				#		legend.text=rownames(prop), args.legend=list(x='left', bty='n',  cex=cex.legend, inset=c(-2.2, 0)))
				
			}
			
			par(mar=c(0, 0, 0, 0))
			oma.o <- par(oma=c(0, 0, 0, 0))
			for (taxa.level in taxa.levels) {
#				abund0 <- data.obj$abund.list[[taxa.level]]
#				abund0 <- t(t(abund0) / colSums(abund0))
#				
#				abund0 <- t(apply(abund0, 1, function(x) {
#									tapply(x, grp, mean)
#								}))
#				
#				abund1 <- abund0[name.list[[taxa.level]], , drop=FALSE]
#				abund2 <- 1 - colSums(abund1)
#				
#				prop <- rbind(abund1, Other=abund2)
#				colnames(prop) <- colnames(abund0)
				
				
				#	cex.legend = ifelse (nrow(prop) > 35, 35/nrow(prop)*0.75, 0.75)
				plot(1, type="n", axes=FALSE, xlab="", ylab="")
				# Rev: 2016_09_10
				legend('left', legend=rev(rownames(prop.list[[taxa.level]])), bty='n',
						fill=rev(col.list[[taxa.level]][rownames(prop.list[[taxa.level]])]), cex=cex.legend)
				
			}
			par(mar=mar.o)
			par(oma=oma.o)
			par(mfrow=mfrow.o)
			if (pdf == TRUE)
				dev.off()
		} else {
			if (pdf == TRUE)
				pdf(paste0("Taxa_Stacked_Barplot_Grouped_Compo_", ann, "_Separate.pdf"), height=hei2, width=wid2)
			
			mar.o <- par(mar=par('mar') + c(0, margin, 0, 0))
			for (taxa.level in taxa.levels) {
#				abund0 <- data.obj$abund.list[[taxa.level]]
#				abund0 <- t(t(abund0) / colSums(abund0))
#				
#				abund0 <- t(apply(abund0, 1, function(x) {
#									tapply(x, grp, mean)
#								}))
#				
#				abund1 <- abund0[name.list[[taxa.level]], , drop=FALSE]
#				abund2 <- 1 - colSums(abund1)
#				
#				prop <- rbind(abund1, Other=abund2)
#				colnames(prop) <- colnames(abund0)
				temp <- aggregate(t(prop.list[[taxa.level]]), by=list(grp), mean)
				prop <- as.matrix(temp[, -1])
				rownames(prop) <- temp[, 1]
				prop <- t(prop)
				
				cex.legend <- ifelse (nrow(prop) > 35, 35/nrow(prop)*0.75, 0.75)
				par(lwd = 0.25)
				barplot(prop, col=col.list[[taxa.level]][rownames(prop)], ylab='Proportion', las=2, cex.names=cex.names2, main=taxa.level,
						legend.text=rownames(prop), args.legend=list(x='left', bty='n',  cex=cex.legend, inset=c(-0.5, 0)), ...)
				
			}
			par(mar=mar.o)
			if (pdf == TRUE)
				dev.off()
			
		}
		
	}
	
	par(lwd = lwd.o)
	cat('Completed!\n')
	return(invisible(list(col.map=col.list)))
}

build.decision.tree <- function(data.obj,  resp.name, taxa.level='Species', binary=FALSE, taxa, aug.var=NULL, ann='All') {
	ann <- paste(taxa.level, ann, sep="_")
	response <- data.obj$meta.dat[, resp.name]
	
	ct <- data.obj$abund.list[[taxa.level]]
	prop <- t(t(ct) / colSums(ct))
	prop <- prop[taxa, , drop=F] 	
	if (binary == TRUE) {
		prop <- (prop != 0)
	}
	
	dat <- as.data.frame(t(prop))
	# Rev: 2017_02_17 Add additional variables from meta dat
	if (!is.null(aug.var)) {
		dat <- cbind(dat, data.obj$meta.dat[, aug.var])
	}
	
	dat <- data.frame(dat, response)
	try(
		if (is.factor(response)) {
			fit <- rpart(response ~ ., method="class", data=dat)
			post(fit, file = paste0("Taxa_Unpruned_Classification_tree_", ann, ".ps"), title = "Unpruned Classification Tree")
			pfit<- prune(fit, cp= fit$cptable[which.min(fit$cptable[,"xerror"]),"CP"])
			post(pfit, file = paste0("Taxa_Pruned_Classification_", ann, ".ps"), title = "Pruned Classification Tree")
			
		} else {
			fit <- rpart(response ~ ., method="anova", data=dat)
			post(fit, file = paste0("Taxa_Unpruned_Regression_tree_", ann, ".ps"), title = "Unpruned Regression Tree")
			pfit<- prune(fit, cp= fit$cptable[which.min(fit$cptable[,"xerror"]),"CP"])
			post(pfit, file = paste0("Taxa_Pruned_Regression_tree_", ann, ".ps"), title = "Pruned RegressionTree")
		}
	)	
}

bootstrap.pwr <- function(pcs, formula, dat, ns=NULL, perm.no=199, iter.no=100) {
	if (is.null(ns)) {
		ns <- nrow(dat)*seq(1, 4, len=8)
	}
	pvs <- numeric(length(ns))
	names(pvs) <- paste(ns)
	for (n in ns) {
		cat('.')
		temp <- sapply(1:iter.no, function(i) {
			bt.ind <- sample(1:nrow(dat), n, repl=T)
			dat.bt <- dat[bt.ind, ]
			dist.bt <- dist(pcs[bt.ind, ])
			aov.tab <- adonis(as.formula(paste('dist.bt', formula)), dat=dat.bt, permutations=perm.no)$aov.tab
	        pv <- aov.tab[nrow(aov.tab)-2, ncol(aov.tab)]
		})
        pvs[paste(n)] <- mean(temp <= 0.05)
	}

	return(pvs)
}


perform_power_analysis <- function (data.obj, dist.obj, dist.names=c('UniFrac', 'GUniFrac', 'WUniFrac', 'BC'), formula=NULL,  
		grp.name=NULL, adj.name=NULL, ann='', ...) {
	if (is.null(formula)) {
		if (is.null(adj.name)) {
			formula <- paste('~', grp.name)
		} else {
			formula <- 	paste('~', paste(adj.name, collapse='+'), '+', grp.name)		
		}
	}	 
	df <- data.obj$meta.dat
    pvm <- NULL
	for (dist.name in dist.names) {
		cat('*')
		dist.mat <- dist.obj[[dist.name]]
		pcs <- cmdscale(dist.mat, k=nrow(dist.mat)-1)
		pvs <- bootstrap.pwr(pcs, formula, df, ...)
		pvm <- rbind(pvm, pvs)
	}
	colnames(pvm) <- names(pvs)
	rownames(pvm) <- dist.names
	
	pvdf <- melt(pvm)
	colnames(pvdf) <- c('Distance_type', 'Sample_size', 'Value')
	pdf(paste0("Power_curve_bootstrap_", ann, '.pdf')) 
	g.obj <- ggplot(pvdf, aes(x=Sample_size, y=Value)) +
				geom_point() +
				geom_line() +
				ylab('Power') +
				facet_wrap(~ Distance_type, ncol=2) +
				theme_bw()
	print(g.obj)
	dev.off()
	
	return(pvdf)
}

# More robust identification
k.nonoverlap.se <- function (tab, SE.factor=1) {
	max.v <- which.max(tab[, 'gap']) 
	
	for (i in (max.v-1):1) {
		if (tab[i, 'gap'] + SE.factor * tab[i, 'SE.sim'] < tab[i+1, 'gap'] - SE.factor * tab[i+1, 'SE.sim']) {
			break
		} 
	}
	
	return(i+1)
}


perform_cluster_analysis <- function (data.obj, dist.obj, dist.name=c('UniFrac'), k.best=NULL, method='pam', stat='gap', 
		grp.name=NULL, adj.name=NULL, subject=NULL, ann='', seed=1234) {
	
	df <- data.obj$meta.dat
	if (!is.null(grp.name)) {
		grp <- df[, grp.name]
	}
	if (!is.null(adj.name)) {
		adj <- df[, adj.name]
	}
	cat(dist.name, ' distance ...\n')
	mat <- dist.obj[[dist.name]]
	
	if (is.null(k.best)) {
		pc.obj <- cmdscale(as.dist(mat), k=ncol(mat) - 1, eig=T)
		eig <- pc.obj$eig
		eig <- eig[eig > 0]
		pvar <- eig / sum(eig)
		pc <- pc.obj$points
		
		cat('Assess cluster number by gap statistics ...\n')
		
		set.seed(seed)
		gs <-  gapstat_ord(pc, axes=1:ncol(pc), verbose=FALSE)
		plot_clusgap(gs)
		ggsave(paste0('cluster_assess_gap_statistic_', dist.name, ann, '.pdf') , width=6, height=6)
		
		
#		print(gs, method="Tibs2001SEmax")
#		print(gs, method="firstSEmax")
		
		tab <- gs$Tab
		write.csv(tab, paste0('gap_stat_', dist.name, '.csv'))
		
		k.best.gap <- k.nonoverlap.se(tab)
		
		cat('Gap statistic finds ', k.best.gap, ' clusters.\n')
		
		
		cat('Assess cluster number by average silhouette width ...\n')
		asw <- numeric(20)
		for (k in 2:20){
			asw[k] <- pam(as.dist(mat), k)$silinfo$avg.width
		}
		
		k.best.asw <- which.max(asw)
		cat("silhouette-optimal number of clusters:", k.best.asw, "\n")
		pdf(paste0('cluster_assess_asw_statistic_', dist.name, ann, '.pdf'), width=6, height=6)
		plot(1:20, asw, type= "h", main = "pam() clustering assessment",
				xlab= "k (# clusters)", ylab = "average silhouette width")
		axis(1, k.best.asw, paste("best",k.best.asw, sep="\n"), col = "red", col.axis = "red")
		dev.off()
		
		cat('ASW statistic finds ', k.best.asw, ' clusters.\n')
		
		if (stat == 'gap') {
			k.best <- k.best.gap
		} else {
			if (stat == 'asw') {
				k.best <- k.best.asw
			}
		}
		
	}
	
	if (k.best == 1) {
		cat('No robust cluster structure found!\n')
	} else {
		pam.obj <- pam(as.dist(mat), k=k.best)
		pam.class <- factor(pam.obj$clustering)
		write.csv(pam.class, paste0('Cluster.membership', dist.name, '.csv'))
		
		df$Cluster <- pam.class
		data.obj$meta.dat <- df
		if (is.null(grp.name)) {
			generate_ordination(data.obj, dist.obj, dist.name, grp.name='Cluster', ann=paste0('Cluster', dist.name, ann))
		} else {
			generate_ordination(data.obj, dist.obj, dist.name, grp.name='Cluster', strata=grp.name, ann=paste0('Cluster', dist.name, ann))
		}
		
		# Define cluster characteristics
	   diff.obj <- perform_differential_analysis(data.obj, grp.name='Cluster', 
			   taxa.levels=c('Genus'),
			   method='kruskal', mt.method='fdr', 
			   cutoff=0.01, prev=0.1, minp=0.002, ann='Cluster')
	   
	   visualize_differential_analysis(data.obj, diff.obj, grp.name='Cluster', taxa.levels=c('Genus'), indivplot=FALSE,
			   mt.method='fdr', cutoff=0.01, ann='Cluster')
		
		try(
				if (!is.null(grp.name)) {
					if (is.null(adj.name)) {
						form <- as.formula(paste('yy ~', grp.name))
					} else {
						form <- as.formula(paste('yy ~', paste(adj.name, collapse='+'), '+', grp.name))		
					}
					# Enrichment analysis - logistic regression - 1 vs other
					cat('Testing for association with the clusters - 1 vs other ...\n')
					sink(paste0('Cluster_association_test', dist.name, ann, '.txt'))
					if (is.null(subject)) {
						cat('Generalized linear model (logistic regression) is performed.\n')
						
						for (clus in levels(df$Cluster)[1:(nlevels(df$Cluster))]) {	
							cat('Test for enrichment in cluster', clus, '\n')
							y <- rep(0, length(df$Cluster)) 
							y[df$Cluster == clus] <- 1
							df$yy <- y
							prmatrix(summary(glm(form, data=df, family=binomial))$coefficients)	
						}
					} else {
						cat('Generalized linear mixed effects model (logistic regression) is performed.\n')
						for (clus in levels(df$Cluster)[1:(nlevels(df$Cluster))]) {
							cat('Test for enrichment in cluster', clus, '\n')
							y <- rep(0, length(df$Cluster)) 
							y[df$Cluster == clus] <- 1
							df$yy <- y
							prmatrix(summary(glmmPQL(form, data=df, random = as.formula(paste0('~ 1|', subject)), family=binomial, verbose=F))$tTable)
							
						}
					}
					sink()
				}
		)
		
	}
}


##########
B2M <- function(x) {
	x[x==0] <- min(x[x!=0])
	x[x==1] <- max(x[x!=1])
	log(x / (1-x))
}


fastDist <- function(X) {
	temp <- colSums(X^2)  
	D <- outer(temp, temp, "+") - 2 * t(X) %*% X
	diag(D) <- 0
	sqrt(D)
}

fastLM <- function(Y, M) {
	Y <- as.matrix(Y)
	XXI <- solve(t(M) %*% M)
	dof <- ncol(Y) - ncol(M)
	est <- XXI %*% t(M) %*% t(Y)
	resid <- t(Y) - M %*% est
	sigma <- sqrt(colSums(resid^2)/dof)
	Pvec <- 2*pt(-abs(t(est/(sqrt(diag(XXI))))/sigma), dof)
	return(Pvec)
}

matrix.paste0 <- function (m.list) {
	p <- length(m.list)
	
	m <- max(unlist(sapply(m.list, function (x) nrow(x))))
	n <- max(unlist(sapply(m.list, function (x) ncol(x))))
	res <- NULL
	for (i in 1:p) {
		mat <- m.list[[i]]
		if (!is.matrix(mat)) {
			mat <- matrix(mat, m, n)
		} else {
			if (!is.null(rownames(mat))) {
				row.names <- rownames(mat)
			}
			if (!is.null(colnames(mat))) {
				col.names <- colnames(mat)
			}
			
		}
		res <- paste0(res, mat)
	}
	return(matrix(res, m, n, dimnames=list(row.names, col.names)))
}
#
#normalize.func <- function (x) {
#	names <- paste(x)
#	tab <- table(x)
#	tab.name <- names(tab)
#	tab.x <- qqnorm(as.numeric(tab.name), plot.it = F)$x
#	names(tab.x) <- tab.name
#	as.numeric(tab.x[names])
#}

# Typer I error 1
calculateK <- function (G) {
	n <- nrow(G)
	m <- mean(diag(G))
	v <- var(G[lower.tri(G)])
	sigma <- v / m
	k <- m / sigma
	se <- 1.96 * sqrt(2 / n)
	list(K=k, K.lower = (sqrt(k) - se)^2, K.upper=(sqrt(k) + se)^2, sigma=sigma)
}

fPERMANOVA <- function (formula, data=NULL, contr.unordered = "contr.sum", contr.ordered = "contr.poly") {
	
	Terms <- terms(formula, data = data)
	lhs <- formula[[2]]
	lhs <- eval(lhs, data, parent.frame())
	
	formula[[2]] <- NULL
	rhs.frame <- model.frame(formula, data, drop.unused.levels = TRUE)
	op.c <- options()$contrasts
	options(contrasts = c(contr.unordered, contr.ordered))
	rhs <- model.matrix(formula, rhs.frame)
	options(contrasts = op.c)
	grps <- attr(rhs, "assign")
	
	# The first group includes the intercept, nterms count the intercept
	u.grps <- unique(grps)
	nterms <- length(u.grps)
	
	Z <- rhs[, grps %in% u.grps[1:(nterms-1)], drop=F]
	XZ <- rhs[, grps %in% u.grps[1:(nterms)], drop=F]
	
	n <- nrow(XZ)
	HZ <- Z %*% solve(t(Z) %*% (Z)) %*% t(Z)
	HXZ <- XZ %*% solve(t(XZ) %*% (XZ)) %*% t(XZ)
	HX <- HXZ - HZ
	HIX <- diag(n) - HXZ
	
	if (class(lhs) == 'dist') {
		D <- -as.matrix(lhs)^2 / 2
		
	} else {
		D <- -lhs^2 / 2
	}
	
	G <- mean(D) + D - rowMeans(D) - matrix(rep(1, n), ncol=1) %*% colMeans(D)
	G <- G / n
	obj <- calculateK(G)
	
	K <- obj$K
	
	sigma <- obj$sigma
	
	df1 <- ncol(XZ) - ncol(Z)
	df2 <- n - ncol(XZ)
	
	MSS <- sum(G * HX)
	RSS <- sum(G * HIX)
	TSS <- sum(diag(G))
#	RSS <- TSS - MSS
	
	f.stat <- (MSS / df1) / (RSS / df2)
	
#	p.value1 <- pnorm(f.stat, mean=1, sd=sqrt(2 / (K * df1)), lower.tail=F)
	p.value2 <- pchisq(f.stat * K * df1, df = K * df1, lower.tail=F)
	
	SumsOfSqs <- c(MSS, RSS, TSS)
	
	tab <- data.frame(Df = c(df1, df2, n - 1), SumsOfSqs = n * SumsOfSqs, 
			MeanSqs = c(n * MSS/df1, n * RSS/df2, NA), F.Model = c(f.stat, 
					NA, NA), R2 = c(MSS/TSS, NA, NA), 
			"Pr(>F)" = c(p.value2, NA, NA))
	
	rownames(tab) <- c("Model(Adjusted)", "Residuals", "Total")
	colnames(tab)[ncol(tab)] <- c("Pr(>F)")
	class(tab) <- c("anova", class(tab))
	attr(tab, "heading") <- c("F stat and P value of the last term is adjusted by previous terms!\n")
	
	out <- list(aov.tab = tab, K=K, sigma=sigma, call = match.call())
	out
}

# Determine the optimal depth to filter the samples
optim_dep <- function (data.obj,  ID.ctrl,  ID.other = NULL, taxa.level = 'Species', ann = '') {
	ID <- rownames(data.obj$meta.dat)
	if (is.null(ID.other)) {
		ID.other <- setdiff(ID, ID.ctrl)
	}
	
	dep <- colSums(data.obj$otu.tab)
	gen <- data.obj$abund.list[[taxa.level]]
	gen <- t(gen) / colSums(gen)
	
	dist.mat <- as.matrix(vegdist(gen))
	
	dist.mat <- dist.mat[ID.other, ID.ctrl]
	dep <- dep[ID.other]
	ord <- order(dep)
	dep <- dep[ord]
	dist.mat <- dist.mat[ord, ]
#	data <- data.frame(distance=as.vector(t(dist.mat)), depth=rep(log10(dep), each = ncol(dist.mat)))
	data <- data.frame(distance=rowMeans(dist.mat), depth=log10(dep))
	
	pdf(paste0('Distance2CtrlvsDepth.', taxa.level, '.', ann, '.pdf'), width = 6, height = 5)
	obj <- ggplot(data, aes(x = depth, y = distance)) +
			#	geom_boxplot() +
			geom_smooth() +
			geom_jitter() +
			geom_vline(xintercept=log10(2000), col='red') +
			xlab('Log10(depth)') +
			theme_bw()
	print(obj)
	dev.off()
}


# Determine the influential taxa - Need to test
contaminant_detection <- function (data.obj, ID.ctrl, ID.other = NULL, taxa.level = 'Species', ann = '') {
	ID <- rownames(data.obj$meta.dat)
	if (is.null(ID.other)) {
		ID.other <- setdiff(ID, ID.ctrl)
	}

	dep <- colSums(data.obj$otu.tab)
	gen <- data.obj$abund.list[[taxa.level]]
	gen <- t(gen) / colSums(gen)
	
	func <- function (gen, ID.other, ID.ctrl) {
		n.ctrl <- length(ID.ctrl)
		n.other <- length(ID.other)
		dist.mat <- as.matrix(vegdist(gen))
		dist1 <- rowMeans(dist.mat[ID.other, ID.ctrl])
		#dist2 <-  rowMeans(dist.mat[ID.other, ID.other]) * n.other / (n.other - 1)
		
		# mean(dist1) / mean(dist2)
		mean(dist1)
	}
	
	r0 <- func(gen, ID.other, ID.ctrl)
	r.vec <- numeric(ncol(gen))
	names(r.vec) <- colnames(gen)
	for (i in 1 : ncol(gen)) {
		if (i %% 10 == 0) cat('.')
#		gen2 <- gen[, -i]
#		gen2 <- gen2 / rowSums(gen2)
		gen2 <- gen
		gen2[, i] <- sample(gen2[, i])
		r.vec[i] <- func(gen2, ID.other, ID.ctrl)
	}
	return(list(r0=r0, r.vec=r.vec))
}

# New: 2018_07_13
generate_count_heatmap <- function (data.obj, ann='CountHeatmaps', width = 6, height = 20, 
		taxa.level = 'OTU', cutoff = 10, occurence = 2,
		breaks = c(-0.1, 0.1, 1, 2, 3, 4, 5, 6, 7,  8, 9, 10, 12, 14, 18),
		col = c('white', colorpanel(13, 'aliceblue', 'lightblue', 'blue')), 
		margins = c(10, 5),
		cexRow = 0.2, 
		cexCol = 0.4,
		...) {
	if (taxa.level %in% c('Species', 'OTU')) {
		otu.tab <- data.obj$otu.tab 
	} else {
		otu.tab <- data.obj$abund.list[[taxa.level]]
	}
	
	otu.tab <- otu.tab[rowSums(otu.tab) > cutoff, ]
	otu.tab <- otu.tab[rowSums(otu.tab != 0) > occurence, ]
	
	pdf(paste0(ann, '.', taxa.level, '.pdf'), width = width, height=height)
	heatmap.2(log2(otu.tab+1), scale = 'none', col = col,
			trace = 'none', breaks = breaks, key.xlab= 'log2(count + 1)', 
			density.info='none', margins = margins, cexRow = cexRow, cexCol =cexCol, ...)
	dev.off()
}


